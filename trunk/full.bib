@book{wheeler1995,
  title={Iterative estimation of rotation and translation using the quaternion},
  author={Wheeler, M.D. and Ikeuchi, K.},
  year={1995},
  publisher={School of Computer Science, Carnegie Mellon University}
}
@book{rasmussen2006gaussian,
  title={Gaussian processes for machine learning},
  author={Rasmussen, C.E. and Williams, C.K.I.},
  volume={1},
  year={2006},
  publisher={MIT press Cambridge, MA}
}
@article{petersen2008matrix,
  title={The matrix cookbook},
  author={Petersen, K.B. and Pedersen, M.S.},
  journal={Technical University of Denmark},
  pages={7--15},
  year={2008}
}  

@inproceedings{munoz2009contextual,
  title={Contextual classification with functional max-margin markov networks},
  author={Munoz, D. and Bagnell, J.A. and Vandapel, N. and Hebert, M.},
  booktitle={Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on},
  pages={975--982},
  year={2009},
  organization={IEEE}
}

@inproceedings{biber2003normal,
  title={The normal distributions transform: A new approach to laser scan matching},
  author={Biber, P. and Stra{\ss}er, W.},
  booktitle={Intelligent Robots and Systems, 2003.(IROS 2003). Proceedings. 2003 IEEE/RSJ International Conference on},
  volume={3},
  pages={2743--2748},
  year={2003},
  organization={IEEE}
}
  
@inproceedings{rusinkiewicz2001efficient,
  title={Efficient variants of the ICP algorithm},
  author={Rusinkiewicz, S. and Levoy, M.},
  booktitle={3-D Digital Imaging and Modeling, 2001. Proceedings. Third International Conference on},
  pages={145--152},
  year={2001},
  organization={IEEE}
}  

@inproceedings{jian2005robust,
  title={A robust algorithm for point set registration using mixture of gaussians},
  author={Jian, B. and Vemuri, B.C.},
  booktitle={Computer Vision, 2005. ICCV 2005. Tenth IEEE International Conference on},
  volume={2},
  pages={1246--1251},
  year={2005},
  organization={IEEE}
}

@article{tsin2004correlation,
  title={A correlation-based approach to robust point set registration},
  author={Tsin, Y. and Kanade, T.},
  journal={Computer Vision-ECCV 2004},
  pages={558--569},
  year={2004},
  publisher={Springer}
}

@article{plagemann2008nonstationary,
  title={Nonstationary Gaussian process regression using point estimates of local smoothness},
  author={Plagemann, C. and Kersting, K. and Burgard, W.},
  journal={Machine Learning and Knowledge Discovery in Databases},
  pages={204--219},
  year={2008},
  publisher={Springer}
}


@techreport{nilsson_mobile_1969,
	title = {A Mobile Automaton: An Application of Artificial Intelligence Techniques},
	lccn = {0327},
	shorttitle = {A Mobile Automaton},
	url = {http://stinet.dtic.mil/oai/oai?&verb=getRecord&metadataPrefix=html&identifier=ADA459660},
	abstract = {A research project applying artificial intelligence techniques to the development of integrated robot systems is described. The experimental facility consists of an {SDS-940} computer and associated programs controlling a wheeled vehicle that carries a {TV} camera and other sensors. The primary emphasis is on the development of a system of programs for processing sensory data from the vehicle, for storing relevant information about the environment, and for planning the sequence of motor actions necessary to accomplish tasks in the environment. A typical task performed by our present system requires the robot vehicle to rearrange (by pushing) simple objects in its environment. A novel feature of our approach is the use of a formal theorem-proving system to plan the execution of high-level functions as a sequence of other, perhaps lower level, functions. The execution of these in turn requires additional planning at lower levels. The main theme of the research is the integration of the necessary planning systems, models of the world and sensory processing systems into an efficient whole capable of performing a wide range of tasks in a real environment.},
	author = {Nils J Nilsson},
	month = jan,
	year = {1969},
	keywords = {ancient++, {*ARTIFICIAL} {INTELLIGENCE,} {CYBERNETICS,} {DETECTORS,} {ELECTRICAL} {AND} {ELECTRONIC} {EQUIPMENT,} {INTEGRATED} {SYSTEMS,} {MILITARY} {OPERATIONS,} {STRATEGY} {AND} {TACTICS,} {MODELS,} Planning, {*PROBLEM} {SOLVING,} quadtree, {*Robots,} {SCENARIOS,} {THEOREMS,} {VEHICLES}},
	annote = {{{\textless}p{\textgreater}This} paper indeed describes a quadtree-like map. The map starts at 4x4 and if a cell is described as partially full, it is further ubsdivided until a maxmum depth of three levels. This level rep about 12 inches.{\textless}/p{\textgreater}
{{\textless}p{\textgreater}The} planning routine {(PL)} takes the map and puts anchor points at each corner of each obstacle. The shortest path then is a graph through some subset of these points. P.14 has a nice figure. Routes through unknown space are governed by a parameter k. If k=1, unk space is treated as empty, otherwise, some cost is associated with it.{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Important} to note: map only gets updated via vision at the beginning of a journey or when it hits an obstacle. Vision tells where clear floor space exists by identifying floor and then mapping that into a three-dimensional space given the height and angle of the camera.{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Uses} theorem-proving methods in {LISP} (ick) to do more complex planning tasks.{\textless}/p{\textgreater}}
},

@techreport{coles_application_1969,
	title = {Application of Intelligent Automata to Reconnaissance.},
	lccn = {0021},
	url = {http://stinet.dtic.mil/oai/oai?&verb=getRecord&metadataPrefix=html&identifier=AD0868871},
	abstract = {Research in the application of techniques of artificial intelligence to the control of a mobile automaton in a realistic environment is described. The main emphasis is on experimentation with a previously-developed system of hardware and software, and on research in several related areas of artificial intelligence where new efforts have been necessary to increase the capabilities of the automaton. Major areas discussed include the use of formal theorem-proving techniques of first-order logic in solving problems for the automaton; symbolic information structures for modeling the automaton's environment; results in visual scene analysis, including a decision-tree approach and the use of regional as well as local analysis; and an outline for the design of a problem-solving system based on higher-order logic. {(Author)}},
	author = {L. Stephen Coles and Charles A Rosen and Bertram Raphael and {ThomasD} Garvey and Richard O Duda},
	month = nov,
	year = {1969},
	keywords = {{ADAPTIVE} {CONTROL} {SYSTEMS,} ancient++, {(*ARTIFICIAL} {INTELLIGENCE,} {(*AUTOMATA,} {AUTOMATA),} {BIONICS,} {COMPUTER} {PROGRAMMING,} {DATA} {STORAGE} {SYSTEMS.,} {DECISION} {MAKING,} {DETECTORS,} {LEARNING} {MACHINES,} list model, {MATHEMATICAL} {LOGIC,} {MOBILE),} occupancy grid, {PATTERN} {RECOGNITION,} {PREDICATE} {CALCULUS,} {PROBLEM} {SOLVING,} {PROJECTIVE} {GEOMETRY,} {RANGE} {FINDING,} {*ROBOTS.,} {TELEVISION} {EQUIPMENT}},
	annote = {{\textless}p{\textgreater}http://www.ai.sri.com/shakey/ \&lt;-- good picture here{\textless}/p{\textgreater}
{{\textless}p{\textgreater}This} is a really big paper (164 pages) which goes very in-depth{\textless}/p{\textgreater}
{\textless}p{\textgreater}"push the box that is on the platform onto the floor" takes 90 seconds to parse, feasilbility proof takes 20 minutes. (note that it has to push a ramp in place to get to the platform). Picture taking and pushing involves another 15 minutes, so over .5 hours. Though still may fail due to poor vision and stepper motor error.{\textless}/p{\textgreater}
{\textless}p{\textgreater}p.33 sounds like a software engineering nightmare: bugs, making routines pass variables, memory problems. Others: one group measured in degrees, not radians; one group had their coord sys 90 out of phase. Worst of all: {LISP} would pass 51.000 to the {FORTRAN} system, which would only accept it if it was 51.00.{\textless}/p{\textgreater}
{\textless}p{\textgreater}p.34 has some entertaining "pragmatic difficulties" \#3: edges on the ramp still do not show up clearly for proper identification, even though care was taken to paint adjoining faces with highly contrasting colors. Solution: Bring brushes and paint from home, paint certain edges white, tape black paper computer tape on other edges, add more fluorescent lights to the ceiling fixtures. Time: two days{\textless}/p{\textgreater}
{{\textless}p{\textgreater}"In} conclusion ,{\textless}br /{\textgreater}we are clearly on{\textless}br /{\textgreater}that elusive quality called " intelligence "{\textless}br /{\textgreater}building and programming at{\textless}br {/{\textgreater}SRI.} We{\textless}br /{\textgreater}the threshold of exhibiting{\textless}br /{\textgreater}by the machines we are{\textless}br /{\textgreater}have a long way to go before we{\textless}br /{\textgreater}realize practical applications or are taken seriously by the public in{\textless}br /{\textgreater}this ende.avor.{\textless}br {/{\textgreater}(People} generally reserve the word " stupid " for other{\textless}br /{\textgreater}people or systems that exhibit only a{\textless}br /{\textgreater}lit {tIe} bit of i ute lllgence.{\textless}br {/{\textgreater}Nevertheless} , the completion of this experiment in our judgment{\textless}br /{\textgreater}represent a significant stepping stone in the direction of this{\textless}br /{\textgreater}for intelligence.{\textless}br /{\textgreater}quest"{\textless}/p{\textgreater}
{{\textless}p{\textgreater}"The} grid model is described in the First Intorim Report of this{\textless}br /{\textgreater}pr0jcct 3 and in the Third Interim Report of the preceding project.{\textless}br {/{\textgreater}Section} {II} of Ref . 3 touches - on the {LISP} model briefly."{\textless}/p{\textgreater}
{{\textless}p{\textgreater}They} say the grid model wasn't good enough because the resolution wasn't good enough to specify the alignment of a box for pushing. They think that the obejct oriented approach is betters, specifying only x,y,theta, because bookkeeping is easier when an obj needs to moved.{\textless}/p{\textgreater}
{{\textless}p{\textgreater}In} the list model, space is organized in "space parcels," which are natural rectangularf subdivisons of space. Walls are then repr implicitly as the boundary of space parcels. They also use a coarse grid still for obstacles..{\textless}/p{\textgreater}}
},

@article{finkel_quad_1974,
	title = {Quad trees a data structure for retrieval on composite keys},
	volume = {4},
	issn = {0001-5903},
	lccn = {0787},
	url = {http://www.springerlink.com/content/x7147683u3241843/},
	doi = {10.1007/BF00288933},
	abstract = {The quad tree is a data structure appropriate for storing information to be retrieved on composite keys. We discuss the specific case of two-dimensional retrieval, although the structure is easily generalised to arbitrary dimensions. Algorithms are given both for staightforward insertion and for a type of balanced insertion into quad trees. Empirical analyses show that the average time for insertion is logarithmic with the tree size. An algorithm for retrieval within regions is presented along with data from empirical studies which imply that searching is reasonably efficient. We define an optimized tree and present an algorithm to accomplish optimization in n log n time. Searching is guaranteed to be fast in optimized trees. Remaining problems include those of deletion from quad trees and merging of quad trees, which seem to be inherently difficult operations.},
	number = {1},
	journal = {Acta Informatica},
	author = {R. A. Finkel and J. L. Bentley},
	year = {1974},
	keywords = {ancient++, quadtree},
	pages = {1--9},
	annote = {{\textless}p{\textgreater}first mention of quadtrees...{\textless}/p{\textgreater}
{\textless}p{\textgreater}tntech access won't let me get at the pdf...{\textless}/p{\textgreater}}
},

@phdthesis{kuipers_representing_1977,
	title = {Representing Knowledge of Large-scale Space},
	lccn = {0082},
	url = {http://portal.acm.org/citation.cfm?id=889473},
	abstract = {This dissertation presents a model of the knowledge a person has about the spatial structure of a large-scale environment: the "cognitive map." The functions of the cognitive map are to assimilate new information about the environment, to represent the current position, and to answer route-finding and relative-position problems. This model (called the {TOUR} model) analyzes the cognitive map in terms of symbolic descriptions of the environment and operations on those descriptions. Knowledge about a particular environment is represented in terms of route descriptions, a topological network of paths and places, multiple frames of reference for relative positions, dividing boundaries, and a structure of containing regions. The current position is described by the {"You} Are Here" pointer, which acts as a working memory and a focus of attention. Operations on the cognitive map are performed by inference rules which act to transfer information among different descriptions and the {"You} Are Here"...},
	school = {Massachusetts Institute of Technology},
	author = {Benjamin Kuipers},
	year = {1977},
	keywords = {ancient++, cognitive, cognitive map, mapping, navigation, tour},
	annote = {{{\textless}p{\textgreater}Describes} "cognitive map" (the first? see other note on {this).Student} of Marvin Minsky. Not the first! {\textless}span class="citation {Journal"{\textgreater}Tolman} {E.C.} {(July} 1948). {"Cognitive} maps in rats and men"{\textless}/span{\textgreater}{\textless}/p{\textgreater}
{{\textless}p{\textgreater}TOUR} model. Part "patchwork", part "street theory". Patchwork is basically described as a group of hierarchically related cartesian maps, which the street model is a topological network.{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Note} that this thesis is pure {AI,} with ideas stemming from human behavior . An application is made to robotics as a thought experiment (and it is implemented on a computer), but is several years later until concrete robotics applications are seen (see note \#1).{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Some} really prescient quotes that foreshadow {SLAM} throughout the paper (p. 5 starting with {"The} typical operation..."){\textless}/p{\textgreater}
{{\textless}p{\textgreater}Some} related work (more psychology than {AI...)} comes from Piaget and Papert, who came up with constructionism (learning is making), and the idea that learning involves internalized models about the world (including mapping-- "map in your head"). Papert was responsible for the educational "turtle robots", but they did no mapping. The main invention were control commands that were relative to the robot (move forward, turn right 90); kids could visualize such a system in their heads better than commands from a global reference frame.{\textless}/p{\textgreater}},
	annote = {{\textless}p{\textgreater}http://www.eecs.umich.edu/{\textasciitilde}kuipers/bio.html{\textless}/p{\textgreater}
{{\textless}p{\textgreater}In} the late 1980s, Kuipers and his student {Yung-Tai} Byun tackled the problem of extending the ideas of the {TOUR} Model to apply to robots. Specifically, for a robot implementation, it was no longer possible to abstract away the issues of continuous sensory input, continuous motor output, and motion in a continuous world.  Kuipers and Byun [6,7] developed the critical concept of "distinctive place" (or "distinctive state" when heading is included).  A distinctive state is the stable fixed-point of a hill-climbing control law, to which the robot converges from any point in a local basin of attraction.  The local basins of attraction are connected by distinctive edges, which are stable attractors of trajectory-following control laws.  These attractors define the elements of the topological map, and ground them as discrete abstractions of continuous behaviors of control laws in the continuous environment.{\textless}/p{\textgreater}
{{\textless}p{\textgreater}The} Spatial Semantic Hierarchy [8] describes this collection of representations for large-scale space, grounded in the properties of continuous control laws.  It has been extended to the Hybrid Spatial Semantic Hierarchy [9,10] by using well-developed {SLAM} methods [11] to build local metrical maps, extracting the topological properties of local place neighborhoods to build the topological map [9], and then using the topological map as a skeleton for building a global metrical map [10].  The original paper [6] was honored in 2007 as one of the two most influential papers from the 1988 National Conference on Artificial Intelligence.{\textless}/p{\textgreater}
{{\textless}h2{\textgreater}Learning} from uninterpreted sensors and effectors{\textless}/h2{\textgreater}
{{\textless}p{\textgreater}In} virtually all work in artificial intelligence or robotics, the human researcher or programmer provides knowledge of the agent's sensors and effectors, and assumptions about the nature of the environment.  Kuipers and his students have been investigating the problem of how a learning agent can begin with an uninterpreted sense vector and motor vector, and no knowledge of its environment, and construct a useful model of its interaction with its world [18].{\textless}/p{\textgreater}
{{\textless}p{\textgreater}In} a recent essay [19], he describes the intellectual history of his work on spatial knowledge, from the cognitive map, to the Spatial Semantic Hierarchy, to foundational learning of high-level concepts of objects and actions based on low-level experience with sensor inputs and motor outputs.{\textless}/p{\textgreater}
{\textless}p{\textgreater}[1]   B. J. Kuipers.  1977. {\textless}a href="/../../../../zotero.jar\%21/content/zotero/tinymce/note.html"{\textgreater} {{\textless}strong{\textgreater}Representing} Knowledge of {Large-Scale} Space{\textless}/strong{\textgreater}{\textless}/a{\textgreater}.  Doctoral dissertation, Mathematics Department, Massachusetts Institute of Technology, Cambridge, Massachusetts, June 1977.{\textless}/p{\textgreater}
{\textless}p{\textgreater}[2]   B. J. Kuipers.  1978.   {\textless}a href="/../../../../zotero.jar\%21/content/zotero/tinymce/note.html"{\textgreater} {{\textless}strong{\textgreater}Modeling} spatial knowledge{\textless}/strong{\textgreater}{\textless}/a{\textgreater}. {{\textless}em{\textgreater}Cognitive} Science{\textless}/em{\textgreater} {\textless}strong{\textgreater}2{\textless}/strong{\textgreater}: 129-153, 1978.{\textless}/p{\textgreater}
{\textless}p{\textgreater}[3]  K. Lynch, {\textless}a href="/../../../../zotero.jar\%21/content/zotero/tinymce/note.html"{\textgreater} {{\textless}em{\textgreater}The} Image of the City{\textless}/em{\textgreater}{\textless}/a{\textgreater}.  {MIT} Press, 1960. {(ISBN:} 0262620014){\textless}/p{\textgreater}
{\textless}p{\textgreater}[4]  J. Piaget and B. Inhelder,  {\textless}a href="/../../../../zotero.jar\%21/content/zotero/tinymce/note.html"{\textgreater} {{\textless}em{\textgreater}The} Child's Conception of Space{\textless}/em{\textgreater}{\textless}/a{\textgreater}. Norton, 1967.  {(ISBN:}  0393004082){\textless}/p{\textgreater}
{\textless}p{\textgreater}[5] A. W. Siegel and S. H. White, 1975.  The development of spatial representations of large-scale environments.  In H. W. Reese {(Ed.),} {{\textless}em{\textgreater}Advances} in Child Development and Behavior, vol. 10{\textless}/em{\textgreater}, Academic Press, 1975, pp. 9-55.{\textless}/p{\textgreater}
{\textless}p{\textgreater}[6] B. J. Kuipers \&amp; {Y.-T.} Byun.  1988.  {\textless}strong{\textgreater}{\textless}a href="/../../../../zotero.jar\%21/content/zotero/tinymce/note.html"{\textgreater} A robust qualitative method for spatial learning in unknown environments.{\textless}/a{\textgreater}{\textless}/strong{\textgreater} In {{\textless}em{\textgreater}Proceedings} of the National Conference on Artificial Intelligence {(AAAI-88){\textless}/em{\textgreater}.}  Los Altos, {CA:} Morgan Kaufman, 1988.{\textless}/p{\textgreater}
{\textless}p{\textgreater}[7]  B. J. Kuipers \&amp; {Y.-T.} Byun.  1991.  {\textless}a href="/../../../../zotero.jar\%21/content/zotero/tinymce/note.html"{\textgreater} {{\textless}strong{\textgreater}A} robot exploration and mapping strategy based on a semantic hierarchy of spatial representations.{\textless}/strong{\textgreater}{\textless}/a{\textgreater} {{\textless}em{\textgreater}Journal} of Robotics and Autonomous Systems{\textless}/em{\textgreater}, {\textless}strong{\textgreater}8{\textless}/strong{\textgreater}: 47-63, 1991.{\textless}/p{\textgreater}
{\textless}p{\textgreater}[8]  B. Kuipers.  2000.   {\textless}a href="/../../../../zotero.jar\%21/content/zotero/tinymce/note.html"{\textgreater} {{\textless}strong{\textgreater}The} Spatial Semantic Hierarchy{\textless}/strong{\textgreater}{\textless}/a{\textgreater}.  {\textless}cite{\textgreater} Artificial Intelligence{\textless}/cite{\textgreater} {\textless}strong{\textgreater}119{\textless}/strong{\textgreater}:  191-233.{\textless}/p{\textgreater}
{\textless}p{\textgreater}[9]  B. Kuipers, J. Modayil, P. Beeson, M. {MacMahon,} and F. Savelli.  2004.  {\textless}a href="/../../../../zotero.jar\%21/content/zotero/tinymce/note.html"{\textgreater} {{\textless}strong{\textgreater}Local} metrical and global topological maps in the hybrid Spatial Semantic Hierarchy{\textless}/strong{\textgreater}{\textless}/a{\textgreater}. {{\textless}cite{\textgreater}IEEE} International Conference on Robotics and Automation {(ICRA-04){\textless}/cite{\textgreater}.{\textless}/p{\textgreater}}
{\textless}p{\textgreater}[10] J. Modayil, P. Beeson and B. Kuipers.  2004. {\textless}a href="/../../../../zotero.jar\%21/content/zotero/tinymce/note.html"{\textgreater} {{\textless}strong{\textgreater}Using} the topological skeleton for  scalable global metrical map-building{\textless}/strong{\textgreater}{\textless}/a{\textgreater}. {{\textless}cite{\textgreater}IEEE/RSJ} International Conference on  Intelligent Robots and Systems {(IROS-04){\textless}/cite{\textgreater}.{\textless}/p{\textgreater}}
{\textless}p{\textgreater}[11] S. Thrun, W. Burgard, and D. Fox, {\textless}a href="/../../../../zotero.jar\%21/content/zotero/tinymce/note.html"{\textgreater} {{\textless}em{\textgreater}Probabilistic} Robotics{\textless}/em{\textgreater}{\textless}/a{\textgreater}, {MIT} Press, 2005.  {(ISBN:} 0262201623){\textless}/p{\textgreater}
{\textless}p{\textgreater}[12]  B. J. Kuipers and J. P. Kassirer. 1984. {\textless}strong{\textgreater}{\textless}a href="/../../../../zotero.jar\%21/content/zotero/tinymce/note.html"{\textgreater} Causal reasoning in medicine: analysis of a protocol.{\textless}/a{\textgreater}{\textless}/strong{\textgreater} {{\textless}em{\textgreater}Cognitive} Science{\textless}/em{\textgreater} {\textless}strong{\textgreater}8{\textless}/strong{\textgreater}: 363-385, 1984.{\textless}/p{\textgreater}
{\textless}p{\textgreater}[13] B. J. Kuipers. 1984.  {\textless}strong{\textgreater}{\textless}a href="/../../../../zotero.jar\%21/content/zotero/tinymce/note.html"{\textgreater} Commonsense reasoning about causality: deriving behavior from structure.{\textless}/a{\textgreater}{\textless}/strong{\textgreater} {{\textless}em{\textgreater}Artificial} Intelligence{\textless}/em{\textgreater} {\textless}strong{\textgreater}24{\textless}/strong{\textgreater}: 169-203, 1984.{\textless}/p{\textgreater}
{\textless}p{\textgreater}[14]  B. J. Kuipers. 1986.  {\textless}strong{\textgreater}{\textless}a href="/../../../../zotero.jar\%21/content/zotero/tinymce/note.html"{\textgreater} Qualitative simulation.{\textless}/a{\textgreater}{\textless}/strong{\textgreater} {{\textless}em{\textgreater}Artificial} Intelligence{\textless}/em{\textgreater} {\textless}strong{\textgreater}2{\textless}/strong{\textgreater}9: 289-338, 1986.{\textless}/p{\textgreater}
{\textless}p{\textgreater}[15] B. Kuipers, {\textless}a href="/../../../../zotero.jar\%21/content/zotero/tinymce/note.html"{\textgreater} {{\textless}em{\textgreater}Qualitative} Reasoning: Modeling and Simulation with Incomplete Knowledge{\textless}/em{\textgreater}{\textless}/a{\textgreater}.  {MIT} Press, 1994.  {(ISBN} {026211190X){\textless}/p{\textgreater}}
{\textless}p{\textgreater}[16] B. Shults and B. Kuipers. 1997.  {\textless}strong{\textgreater}{\textless}a href="/../../../../zotero.jar\%21/content/zotero/tinymce/note.html"{\textgreater} Proving properties of continuous systems: qualitative simulation and temporal logic{\textless}/a{\textgreater}{\textless}/strong{\textgreater}. {{\textless}cite{\textgreater}Artificial} Intelligence{\textless}/cite{\textgreater} {\textless}strong{\textgreater}92{\textless}/strong{\textgreater}: 91-129, 1997.{\textless}/p{\textgreater}
{\textless}p{\textgreater}[17]  B. J. Kuipers.  {\textless}strong{\textgreater}{\textless}a href="/../../../../zotero.jar\%21/content/zotero/tinymce/note.html"{\textgreater} Reasoning with qualitative models.{\textless}/a{\textgreater}{\textless}/strong{\textgreater} {{\textless}em{\textgreater}Artificial} Intelligence{\textless}/em{\textgreater} {\textless}strong{\textgreater}59{\textless}/strong{\textgreater}: 125-132, 1993. {\textless}br /{\textgreater} B. J. Kuipers.  {\textless}strong{\textgreater}{\textless}a href="/../../../../zotero.jar\%21/content/zotero/tinymce/note.html"{\textgreater} Qualitative simulation: then and now.{\textless}/a{\textgreater}{\textless}/strong{\textgreater} {{\textless}em{\textgreater}Artificial} Intelligence{\textless}/em{\textgreater} {\textless}strong{\textgreater}59{\textless}/strong{\textgreater}: 133-140, 1993.{\textless}/p{\textgreater}
{\textless}p{\textgreater}[18]  D. M. Pierce and B. Kuipers.  1997. {\textless}a href="/../../../../zotero.jar\%21/content/zotero/tinymce/note.html"{\textgreater} {{\textless}strong{\textgreater}Map} learning with uninterpreted sensors and effectors{\textless}/strong{\textgreater}{\textless}/a{\textgreater}. {{\textless}cite{\textgreater}Artificial} Intelligence{\textless}/cite{\textgreater} {\textless}strong{\textgreater}92{\textless}/strong{\textgreater}: 169-229, 1997.{\textless}/p{\textgreater}
{\textless}p{\textgreater}[19] B. Kuipers.  2008.  {\textless}a href="/../../../../zotero.jar\%21/content/zotero/tinymce/note.html"{\textgreater} {{\textless}strong{\textgreater}An} intellectual history of the Spatial Semantic Hierarchy{\textless}/strong{\textgreater}{\textless}/a{\textgreater}.  In M. Jefferies and A. {(W.-K.)} Yeap {(Eds.),} {{\textless}em{\textgreater}Robot} and Cognitive Approaches to Spatial Mapping{\textless}/em{\textgreater}. To appear, Springer Verlag, 2008.{\textless}/p{\textgreater}}
},

@inproceedings{miller_autonomous_1977,
	address = {Cambridge, {USA}},
	title = {Autonomous guidance and control of a roving robot},
	lccn = {0006},
	abstract = {{NASA} has embarked upon a Robotics Research Project at the Jet Propulsion Laboratory, the purpose of
which is to establish a technology base in robotics
and semi - autonomous control of unmanned machines or
vehicles to support lunar and planetary exploration.
The longterm objective of the robotics work at {JPL}
is to provide an integrated hardware/software system
which is capable of nearly autonomous performance.
The present design philosophy seeks to limit the need for human interaction to selection of goals and
similar higher level functions.
The Rover must then
analyze the scene for traversability, generate a
planned path to the goal, and follow that path,
avoiding any obstacles along the route.
We have achieved the capabilityof performing the scenario
just described in a simplified environment; a labor-atory with a flat surface, a limited number of
obstacles and constant illumination.
This paper
focuses upon the autonomous guidance and control
functions of the Rover which executes the planned
trajectory in an incompletely defined environment.},
	booktitle = {Proceedings of the 5th international joint conference on Artificial intelligence - Volume 2},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {J. A. Miller},
	year = {1977},
	keywords = {ancient++, jpl rover},
	pages = {759--760},
	annote = {{{\textless}p{\textgreater}JPL} Rover, one of the earliest bots (shakey is prob the oldest){\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}
{{\textless}p{\textgreater}This} is a 2 page "newsletter" essentially, with not much content{\textless}/p{\textgreater}}
},

@inproceedings{morevec_towards_1977,
	address = {Cambridge, {USA}},
	title = {Towards automatic visual obstacle avoidance},
	lccn = {0637},
	url = {http://portal.acm.org/citation.cfm?id=1622947},
	abstract = {This report describes ongoing research on a working system which
drives a vehicle through cluttered environments under computer
control, guided by images perceived through an onboard tv camera.  The
emphasis is on reliable and fast low level visual techniques which
determine the existence and location of objects in the world, but do
not identify them. Included are an interest operator for choosing
distinctive regions in images, a correlator for finding matching
regions in similar images, a camera solver which determines camera
displacement and distance to objects from stereo information {[Gennery,}
{D.B.,} this Proceedings] and an automatic geometric distortion
corrector for camera nonlinearities. Many of these use pictures
reduced in linear dimension by powers of 2 by summation of
pixels. Other operators are a high pass filter, a point noise remover,
a contrast normalizer, a vertical roll corrector, a picture comparator
and an operator for reducing pictures by other than powers of two.},
	booktitle = {Proceedings of the 5th international joint conference on Artificial intelligence - Volume 2},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Hans Morevec},
	year = {1977},
	keywords = {ancient++},
	pages = {584},
	annote = {{\textless}p{\textgreater}not much mapping, interesting though, using cameras to detect objects quickly...{\textless}/p{\textgreater}}
},

@article{kuipers_modeling_1978,
	title = {Modeling Spatial Knowledge},
	volume = {2},
	lccn = {0596},
	url = {http://dx.doi.org/10.1207/s15516709cog0202_3},
	abstract = {A person's cognitive map, or knowledge of large-scale space, is built up from observations gathered as he travels through the environment. It acts as a problem solver to find routes and relative positions, as well as describing the current location. The {TOUR} model captures the multiple representations that make up the cognitive map, the problem-solving strategies it uses, and the mechanisms for assimilating new information. The representations have rich collections of states of partial knowledge, which support many of the performance characteristics of common-sense knowledge.},
	number = {2},
	journal = {Cognitive Science: A Multidisciplinary Journal},
	author = {Benjamin Kuipers},
	year = {1978},
	keywords = {ancient++, cognitive map, knowledge, model, representation, spatial},
	pages = {129--153},
	annote = {{{\textless}p{\textgreater}TOUR} model is the first computational description of spatial knowledge. It was simulated on a {PDP-10} in Lisp. "takes as input simulated observations, assimilates them into its cognitive map representation, and solves route-finding and relative-position problems"{\textless}/p{\textgreater}
{{\textless}p{\textgreater}This} paper is a shorter version of his thesis.{\textless}/p{\textgreater}}
},

@inproceedings{giralt_multi-level_1979,
	address = {Tokyo, Japan},
	title = {A multi-level planning and navigation system for a mobile robot: a first approach to {HILARE}},
	isbn = {0-934613-47-8},
	lccn = {0107},
	abstract = {This paper describes the current state of {HILARE:} a modular progressively-built mobile robot aimed at general robotics research. The computer organization comprises of local mini and micro processors coupled with a remote time-shared system acting as a consulting facility. A multi-level decision-making system is presented with world models, inference rules, and algorithms particular to each level. The navigation planner uses a geometric model wherein 2-space is partitioned into polygonal areas based on perceptual and/or initial information. A cost function is proposed which provides support for optimal or E-optimal path finding.},
	booktitle = {Proceedings of the 6th international joint conference on Artificial intelligence - Volume 1},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Georges Giralt and Ralph Sobek and Raja Chatila},
	year = {1979},
	keywords = {ancient++},
	pages = {335--337},
	annote = {{\textless}p{\textgreater}can't get to pdf...{\textless}/p{\textgreater}}
},

@inproceedings{moravec_visual_1979,
	title = {Visual Mapping by a Robot Rover},
	lccn = {0184},
	url = {http://www.frc.ri.cmu.edu/~hpm/project.archive/robot.papers/1979/ij79.txt},
	abstract = {The Cart is a camera equipped rover, computer controlled over
a radio link.  This report describes a working program that has
successfully driven the cart through cluttered real world
environments, and has deduced the cart's motion, and built a map of
its surroundings, entirely from what the onboard {TV} camera saw.  The
program builds a sparse {3D} map of its surroundings, but makes no
attempt to classify the objects it sees, other than to label them as
obstacles or non-obstacles.  The method's success is largely due to
high redundancy and cross checking at several levels. The program is
now being extended into one that will drive the cart to a desired
destination, avoiding any obstacles that are encountered.},
	booktitle = {Proceedings of the 6th International Joint Conference on Artificial Intelligence},
	author = {Hans Moravec},
	year = {1979},
	keywords = {ancient++, computer-vision, corner-detection},
	pages = {599--601},
	annote = {{{\textless}p{\textgreater}Also} has a thesis based on this; his Stanford {PhD} took 10 years! (1970-1980). He was working on the Stanford {AI} lab cart while Kuipers was discussing topological robotic mapping.{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Interesting} to note Moravec's paradox:{\textless}/p{\textgreater}
{{\textless}p{\textgreater}http://en.wikipedia.org/wiki/Moravec\%27s\_paradox{\textless}/p{\textgreater}}
{\textless}p{\textgreater}, which basically states that efficient spatial movement (which needs mapping) is one of the hardest {AI} problems. (first, from mind children 1998?){\textless}/p{\textgreater}
{{\textless}p{\textgreater}Can't} find anything but text document... which is missing pictures, sadly.. interesting document, but slightly unreadable... maybe come back to later{\textless}/p{\textgreater}}
},

@article{bentley_data_1979,
	title = {Data Structures for Range Searching},
	volume = {11},
	issn = {0360-0300},
	lccn = {0505},
	url = {http://dx.doi.org/10.1145/356789.356797},
	number = {4},
	journal = {{ACM} Comput. Surv.},
	author = {Jon Bentley and Jerome Friedman},
	month = dec,
	year = {1979},
	keywords = {algorithms, ancient++, geometries, range search},
	pages = {397--409},
	annote = {{\textless}p{\textgreater}http://www.slac.stanford.edu/pubs/slacpubs/2000/slac-pub-2189.pdf{\textless}/p{\textgreater}
{\textless}p{\textgreater}bentley from {CMU{\textless}/p{\textgreater}}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}},
	annote = {{{\textless}p{\textgreater}Talks} about thinking of a database with records as points in space (k columns = k dimension). Then the range search has to extract a hyperrectanguler region in k-dim space.{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Talks} about a lot of data structures which may be pertinent to mapping...{\textless}/p{\textgreater}}
},

@article{bentley_efficient_1980,
	title = {Efficient worst-case data structures for range searching},
	volume = {13},
	issn = {0001-5903},
	lccn = {0150},
	url = {http://dx.doi.org/10.1007/BF00263991},
	abstract = {In this paper we investigate the worst-case complexity of range searching: preprocess N points in k-space such that range queries can be answered quickly. A range query asks for all points with each coordinate in some range of values, and arises in many problems in statistics and data bases. We develop three different structures for range searching in this paper. The first structure has absolutely optimal query time (which we prove), but has very high preprocessing and storage costs. The second structure we present has logarithmic query time and {O(N1+2)} preprocessing and storage costs, for any fixed ?{\textgreater}0. Finally we give a structure with linear storage, {O(N} ln N) preprocessing and {O(N?)} query time.},
	number = {2},
	journal = {Acta Informatica},
	author = {{JL} Bentley and {HA} Maurer},
	month = feb,
	year = {1980},
	keywords = {range search},
	pages = {155--168},
	annote = {{\textless}p{\textgreater}access restricted... even with tntech{\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}}
},

@misc{hans_p._moravec_three_1980,
	title = {Three Dimensional Modelling and Graphics with Multiprocessors},
	url = {http://www.frc.ri.cmu.edu/~hpm/project.archive/general.articles/1981/tridee},
	abstract = {any current approaches to modelling of activity in three-space
can be classed {"Object} Oriented".  The modelled world is represented as
a list of the entities in it, with position being one of the
attributes.  This is good for simple situations where the number of
possible interactions is modest.  As the number and complexity of the
objects grows many things become increasingly difficult.  The cost of
detecting a collision, for instance, rises as the square of the number.

Other representations are possible.  The ones that will be
described here are {"Space} Oriented".  A volume is modelled
(conceptually) as a three dimensional array of cells, with each cell
representing a small volume of space, and with adjacent cells
representing adjacent volumes.  Each cell contains information about the
objects or portions of objects in it.  Collision detection involves
examining each cell for the presence of more than one object, a process
which is largely independent of the number of objects.  There is a large
fixed cost for a given spatial resolution and modelled volume size, but
the cost grows only very slowly with complexity in the objects.},
	author = {Hans P. Moravec},
	month = feb,
	year = {1980},
	keywords = {ancient},
	howpublished = {http://www.frc.ri.cmu.edu/{\textasciitilde}hpm/project.archive/general.articles/1981/tridee},
	annote = {{{\textless}p{\textgreater}Talks} about {Oct-Tree...} one of first mention?{\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Makes} distinction between object-oriented and space-oriented... with space oriented being a {3D} array of cells{\textless}/p{\textgreater}
{\textless}p{\textgreater}speaking of octrees:{\textless}/p{\textgreater}
{\textless}p{\textgreater}he notes that you could leave a rough description of the subtrees beneath it{\textless}/p{\textgreater}
{\textless}p{\textgreater}not realted to mapping, but talks mostly about the conversion from object-oriented to octree, and graphics related operations...{\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}}
},

@article{samet_region_1980,
	title = {Region representation: Quadtrees from binary arrays},
	volume = {13},
	lccn = {0095},
	url = {http://dx.doi.org/10.1016/0146-664X(80)90118-5},
	abstract = {An algorithm is presented for constructing a quadtree from the array representation of a binary image. The algorithm examines each pixel in the image once and only once. In addition, as the tree is constructed, only maximal sized nodes are ever created. Thus the algorithm never requires temporary nodes. The execution time of the algorithm is equal to the number of pixels in the image. The amount of space, in addition to that necessary for the final quadtree, is proportional to the log of the image diameter.},
	number = {1},
	journal = {Computer Graphics and Image Processing},
	author = {Hanan Samet},
	month = may,
	year = {1980},
	keywords = {ancient, octree, quadtree},
	pages = {88--93},
	annote = {{\textless}p{\textgreater}restricted...{\textless}/p{\textgreater}
{{\textless}p{\textgreater}http://www.sciencedirect.com/science?\_ob=ArticleURL\&amp;\_udi=B7GXF-4CV95HN-6\&amp;\_user=10\&amp;\_coverDate=05\%2F31\%2F1980\&amp;\_rdoc=1\&amp;\_fmt=high\&amp;\_orig=search\&amp;\_origin=search\&amp;\_sort=d\&amp;\_docanchor=\&amp;view=c\&amp;\_rerunOrigin=scholar.google\&amp;\_acct=C000050221\&amp;\_version=1\&amp;\_urlVersion=0\&amp;\_userid=10\&amp;md5=6b32eb8d43380e042c1023503b12bbdf\&amp;searchtype=a{\textless}/p{\textgreater}}
{\textless}p{\textgreater}even with tntech{\textless}/p{\textgreater}}
},

@techreport{moravec_obstacle_1980,
	title = {Obstacle Avoidance and Navigation in the Real World by a Seeing Robot Rover.},
	lccn = {0403},
	url = {http://stinet.dtic.mil/oai/oai?&verb=getRecord&metadataPrefix=html&identifier=ADA092604},
	abstract = {The Stanford {AI} Lab cart is a card-table sized mobile robot controlled remotely through a radio link, and equipped with a {TV} camera and transmitter. A computer has been programmed to drive the cart through cluttered indoor and outdoor spaces, gaining its knowledge of the world entirely from images broadcast by the onboard {TV} system. The cart uses several kinds of stereo to locate objects around it in {3D} and to deduce its own motion. It plans an obstacle avoiding path to a desired destination on the basis of a model built with this information. The plan changes as the cart perceives new obstacles on its journey. The system is reliable for short runs, but slow. The cart moves one meter every ten to fifteen minutes, in lurches. After rolling a meter it stops, takes some pictures and thinks about them for a long time. Then it plans a new path, executes a little of it, and pauses again. The program has successfully driven the cart through several 20 meter indoor courses (each taking about five hours) complex enough to necessitate three or four avoiding swerves. A less successful outdoor run, in which the cart skirted two obstacles but collided with a third, was also done. Harsh lighting (very bright surfaces next to very dark shadows) giving poor pictures and movement of shadows during the cart's creeping progress were major reasons for the poorer outdoor performance. The action portions of these runs were filmed by computer controlled cameras. {(Author)}},
	author = {Hans P Moravec},
	month = sep,
	year = {1980},
	keywords = {ancient, {*ARTIFICIAL} {INTELLIGENCE,} {BRIGHTNESS,} {*COLLISION} {AVOIDANCE,} {COMPUTER} {APPLICATIONS,} {CONTROL} {SYSTEMS,} {LONG} {RANGE(TIME),} {*NAVIGATION} {COMPUTERS,} {*OPTICAL} {DETECTION,} {OPTICAL} {DETECTION} {AND} {DETECTORS,} {RADIO} {LINKS,} {*REMOTE} {CONTROL,} {SHADOWS,} stereo, {TELEVISION} {CAMERAS.,} {TELEVISION} {SYSTEMS,} {THESES,} {THREE} {DIMENSIONAL}},
	annote = {{{\textless}p{\textgreater}This} paper has the pictures from older documents!{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Really} interesting because it casually documents the process as well as the algorithms.{\textless}/p{\textgreater}
{{\textless}p{\textgreater}The} main idea is as follows:{\textless}/p{\textgreater}
{\textless}p{\textgreater}1. take 9 successive pictures, identify "interest points," plan path{\textless}/p{\textgreater}
{\textless}p{\textgreater}2. lurch forward about 1 meter{\textless}/p{\textgreater}
{\textless}p{\textgreater}3. take 9 more pictures, try to correlate new interest points with old to deduce real motion, update map as new points are found.{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Note} that there is no ranger, so obstacles are only detected through the interest points.{\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}
{{\textless}p{\textgreater}There} are some really good pictures here of the first maps, along with an obstacle course{\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Map} details: everything is modeled as a cluster of points, each features can be thought of as a fuzzy ellipsoid (simplified actually as spheres), where dimensions reflect uncertainty. Conceptually, a sphere the size of the cart is added to each obstacle sphere, and the path is found by planning point movement.{\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}
{\textless}p{\textgreater}http://www.frc.ri.cmu.edu/{\textasciitilde}hpm/project.archive/robot.papers/1975.cart/1980.html.thesis/p12.html{\textless}/p{\textgreater}
{\textless}p{\textgreater}{\textasciicircum}-- details related work, but looks mostly like stereovision stuff{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Interesting} to note that he got the idea doing stereovision from motion by seeing that his pet lizard could catch prey by only looking at it with one eye.{\textless}/p{\textgreater}}
},

@inproceedings{moravec_rover_1981,
	address = {Vancouver, {BC,} Canada},
	title = {Rover visual obstacle avoidance},
	lccn = {0144},
	abstract = {The Stanford {AI} Lab cart is a remotely controlled {TV} equipped mobile 
robot. A computer program has driven the cart through cluttered spaces, 
gaining its knowledge of the world entirely from images broadcast by the 
onboard {TV} system.

The cart uses several kinds of stereo to locate objects around it in {3D}
and to deduce its own motion. It plans an obstacle avoiding path to a
desired destination on the basis of a model built with this information.
The plan changes as the cart perceives new obstacles on its journey.

The system is reliable for short runs, but slow. The cart moves one
meter every ten to fifteen minutes, in lurches. After rolling a meter it
stops, takes some pictures and thinks about them for a long time. Then it
plans a new path, executes a little of it. and pauses again.

It has successfully driven the cart through several 20 meter courses
(each taking about five hours) complex enough to necessitate three or
four avoiding swerves. Some weaknesses and possible improvements were
suggested by these and other, less successful, runs.},
	booktitle = {Proceedings of the 7th international joint conference on Artificial intelligence - Volume 2},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Hans P. Moravec},
	year = {1981},
	keywords = {ancient},
	pages = {785--790},
	annote = {{\textless}p{\textgreater}not really any new content when compared to his thesis, more of a post-mortem report, not too technical, mostly talks about the failiings of the robot{\textless}/p{\textgreater}}
},

@inproceedings{moravec_3d_1981,
	address = {New York, {NY,} {USA}},
	series = {{SIGGRAPH} '81},
	title = {{3D} graphics and the wave theory},
	isbn = {0-89791-045-1},
	lccn = {0039},
	location = {Dallas, Texas, United States},
	doi = {10.1145/800224.806817},
	abstract = {A continuing trend in computer representation of three dimensional synthetic scenes is the ever more accurate modelling of complex illumination effects. Such effects provide cues necessary for a convincing illusion of reality. The best current methods simulate multiple specular reflections and refractions, but handle at most one scattering bounce per light ray. They cannot accurately simulate diffuse light sources, nor indirect lighting via scattering media, without prohibitive increases in the already very large computing costs. Conventional methods depend implicitly on a particle model; light propagates in straight and conceptually infinitely thin rays. This paper argues that a wave model has important computational advantages for the complex situations. In this approach, light is represented by wave fronts which are stored as two dimensional arrays of complex numbers. The propagation of such a front can be simulated by a linear transformation. Several advantages accrue. Propagations in a direction orthogonal to the plane of a front are convolutions which can be done by {FFT} in O(n log n) time rather than the n 2 time for a similar operation using rays. A typical speedup is about 10,000. The wavelength of the illumination sets a resolution limit which prevents unnecessary computation of elements smaller than will be visible. The generated wavefronts contain multiplicities of views of the scene, which can be individually extracted by passing them through different simulated lenses. Lastly the wavefront calculations are ideally suited for implementation on available array processors, which provide more cost effective calculation for this task than general purpose computers. The wave method eliminates the aliasing problem; the wavefronts are inherently spatially filtered, but substitutes diffraction effects and depth of focus limitations in its stead.},
	booktitle = {{ACM} {SIGGRAPH} Computer Graphics},
	publisher = {{ACM}},
	author = {Hans P Moravec},
	year = {1981},
	note = {{ACM} {ID:} 806817},
	keywords = {design, human factors, intensity, color, photometry, and thresholding},
	pages = {289�296},
	annote = {{\textless}p{\textgreater}interesting, uses octree to do some fft stuff for illumination...{\textless}/p{\textgreater}}
},

@inproceedings{ohatila_path_1982,
	title = {Path planning and environment learning in a mobile robot system},
	lccn = {0076},
	abstract = {(missing)},
	booktitle = {{ECAI-82:} conference proceedings},
	author = {R. Ohatila},
	year = {1982},
	keywords = {ancient},
	pages = {211},
	annote = {{\textless}p{\textgreater}no pdf{\textless}/p{\textgreater}}
},

@article{meagher_geometric_1982,
	title = {Geometric modeling using octree encoding},
	volume = {19},
	lccn = {0546},
	url = {http://dx.doi.org/10.1016/0146-664X(82)90104-6},
	abstract = {A geometric modeling technique called Octree Encoding is presented. Arbitrary {3-D} objects can be represented to any specified resolution in a hierarchical 8-ary tree structure or "octree" Objects may be concave or convex, have holes (including interior holes), consist of disjoint parts, and possess sculptured (i.e., "free-form") surfaces. The memory required for representation and manipulation is on the order of the surface area of the object. A complexity metric is proposed based on the number of nodes in an object's tree representation. Efficient (linear time) algorithms have been developed for the Boolean operations (union, intersection and difference), geometric operations (translation, scaling and rotation), N-dimensional interference detection, and display from any point in space with hidden surfaces removed. The algorithms require neither floating-point operations, integer multiplications, nor integer divisions. In addition, many independent sets of very simple calculations are typically generated, allowing implementation over many inexpensive high-bandwidth processors operating in parallel. Real time analysis and manipulation of highly complex situations thus becomes possible.},
	number = {2},
	journal = {Computer Graphics and Image Processing},
	author = {Donald Meagher},
	month = jun,
	year = {1982},
	keywords = {ancient, octree},
	pages = {129--147},
	annote = {{\textless}p{\textgreater}cited by 500+{\textless}/p{\textgreater}},
	annote = {{\textless}p{\textgreater}no access, elsevier, even with tntech{\textless}/p{\textgreater}}
},

@article{gargantini_effective_1982,
	title = {An effective way to represent quadtrees},
	volume = {25},
	issn = {0001-0782},
	lccn = {0505},
	abstract = {A quadtree may be represented without pointers by encoding each black node with a quaternary integer whose digits reflect successive quadrant subdivisions. We refer to the sorted array of black nodes as the �linear quadtree� and show that it introduces a saving of at least 66 percent of the computer storage required by regular quadtrees. Some algorithms using linear quadtrees are presented, namely, (i) encoding a pixel from a 2n � 2{\textgreater}n array (or screen) into its quaternary code; (ii) finding adjacent nodes; (iii) determining the color of a node; (iv) superposing two images. It is shown that algorithms (i)-(iii) can be executed in logarithmic time, while superposition can be carried out in linear time with respect to the total number of black nodes. The paper also shows that the dynamic capability of a quadtree can be effectively simulated.},
	journal = {Communications of the {ACM}},
	author = {Irene Gargantini},
	month = dec,
	year = {1982},
	note = {{ACM} {ID:} 358741},
	keywords = {algorithms, ancient, compression, digital images, image encoding, quadtree, star},
	pages = {905�910},
	annote = {{{\textless}p{\textgreater}In} this paper, Gargantini (?) discusses a modification of the quadtree to remove all pointers. To replace the pointers, he uses a quaternary code that identifies, per digit, the quadrant that a given pixel belongs. The coding turns out to be quite elegant, since we can move through neighboring regions with simple rules that involve modulus and addition. X's denote "condensed" regions of space.{\textless}/p{\textgreater}
{\textless}p{\textgreater}this particular implementation is a little limited: {2D,} 2{\textasciicircum}n by 2{\textasciicircum}n pixels, black and white only (which actually might be fine for lidar hits).{\textless}/p{\textgreater}}
},

@article{moravec_stanford_1983,
	title = {The Stanford Cart and the {CMU} Rover},
	volume = {71},
	issn = {0018-9219},
	lccn = {0310},
	doi = {10.1109/PROC.1983.12684},
	abstract = {The Stanford Cart was a remotely controlled {TV-equipped} mobile robot. A computer program was written which drove the Cart through cluttered spaces, gaining its knowledge of the world entirely from images broadcast by an on-board {TV} system. The {CMU} Rover is a more capable, and neatly operational, robot being built to develop and extend the Stanford work and to explore new directions. The Cart used several kinds of stereopsis to locate objects around it in three dimensions and to deduce its own motion. It planned an obstacle-avoiding path to a desired destination on the basis of a model built with this information. The plan changed as the Cart perceived new obstacles on its journey. The system was reliable for short runs, but slow. The Cart moved 1 m every 10 to 15 min, in lurches. After rolling a meter it stopped, took some pictures, and thought about them for a long time. Then it planned a new path, executed a little of it, and paused again. It successfully drove the Cart through several 20-m courses (each taking about 5 h) complex enough to necessitate three or four avoiding swerves; it failed in other trials in revealing ways. The Rover system has been designed with maximum mechanical and control system flexibility to support a wide range of research in perception and control. It features an omnidirectional steering system, a dozen on-board processors for essential real-time tasks, and a large remote computer to be helped by a high-speed digitizing/data playback unit and a high-performance array processor. Distributed high-level control software similar in organization to the Hearsay {II} speech-understanding system and the beginnings of a vision library are being readied. By analogy with the evolution of natural intelligence, we believe that incrementally solving the control and perception problems of an autonomous mobile mechanism is one of the best ways of arriving at general artificial intelligence.},
	number = {7},
	journal = {Proceedings of the {IEEE}},
	author = {{H.P.} Moravec},
	year = {1983},
	keywords = {ancient},
	pages = {872--884},
	annote = {{\textless}p{\textgreater}no access, even in ieee explore with tntech login{\textless}/p{\textgreater}
{\textless}p{\textgreater}though I found in the book here:{\textless}/p{\textgreater}
{{\textless}p{\textgreater}http://books.google.com/books?hl=en\&amp;lr=\&amp;id=LfTPdnYLQ-AC\&amp;oi=fnd\&amp;pg=PA1\&amp;dq=The+Stanford+Cart+and+the+CMU+Rover\&amp;ots=xsHDIjO9tA\&amp;sig=uForzkGtxruaHWhlPE49mzFodS4\#v=onepage\&amp;q=The\%20Stanford\%20Cart\%20and\%20the\%20CMU\%20Rover\&amp;f=false{\textless}/p{\textgreater}}
{{\textless}p{\textgreater}CART/CMU} Rover pubs (p.22):{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Visual} Mapping by a Robot Rover 79{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Robot} Rover Visual Navigation 81{\textless}/p{\textgreater}
{{\textless}p{\textgreater}The} {CMU} Rover 82{\textless}/p{\textgreater}
{\textless}p{\textgreater}(this one) 1983{\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}}
},

@article{yau_hierarchical_1983,
	title = {A hierarchical data structure for multidimensional digital images},
	volume = {26},
	issn = {0001-0782},
	lccn = {0089},
	url = {http://dx.doi.org/10.1145/358150.358158},
	abstract = {A tree data structure for representing multidimensional digital binary images is described. The method is based on recursive subdivision of the d-dimensional space into 2d hyperoctants. An algorithm for constructing the tree of a d-dimensional binary image from the trees of its (d - 1 )-dimensional cross sections is given. The computational advantages of the data structure and the algorithm are demonstrated both theoretically and in application to a three-dimensional reconstruction of a human brain.},
	number = {7},
	journal = {Commun. {ACM}},
	author = {{Mann-May} Yau and Sargur Srihari},
	month = jul,
	year = {1983},
	keywords = {ancient, octree},
	pages = {504--515},
	annote = {{{\textless}p{\textgreater}Talks} about a hyper-octree. That is, a {4D} spatial tree, talks about benefits in terms of image processing...{\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}}
},

@misc{anderson_pyramid_1984,
	title = {Pyramid Methods in Image Processing},
	lccn = {0257},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.56.8646},
	abstract = {: The data structure used to represent image information can be critical to the successful completion of an image processing task. One structure that has attracted considerable attention is the image pyramid This consists of a set of lowpass or bandpass copies of an image, each representing pattern information of a different scale. Here we describe a variety of pyramid methods that we have developed for image data compression, enhancement, analysis and graphics. 1984 {RCA} Corporation Final manuscript received November 12, 1984 Reprint Re-29-6-5 that can perform most of the routine visual tasks that humans do effortlessly. It is becoming increasingly clear that the format used to represent image data can be as critical in image processing as the algorithms applied to the data. A digital image is initially encoded as an array of pixel intensities, but this raw format i s not suited to most tasks. Alternatively, an image may be represented by its Fourier transform, with operations applied...},
	author = {{CH} Anderson and {JR} Bergen and {PJ} Burt and {JM} Ogden},
	year = {1984},
	keywords = {ancient, image-processing, multi-scale, pyramid},
	annote = {{\textless}p{\textgreater}first pyramid methods paper...??{\textless}/p{\textgreater}
{\textless}p{\textgreater}this is more a compact way to represent an image at successive levels of detail...{\textless}/p{\textgreater}
{\textless}p{\textgreater}have more detailed notes on this paper: find them!{\textless}/p{\textgreater}}
},

@inproceedings{brooks_aspects_1984,
	title = {Aspects of mobile robot visual map making},
	lccn = {0047},
	abstract = {(missing)},
	booktitle = {Second Int. Symp. Robotics Research},
	author = {R. A Brooks},
	year = {1984},
	keywords = {ancient},
	pages = {287�293},
	annote = {{\textless}p{\textgreater}cannot find the pdf...{\textless}/p{\textgreater}}
},

@inproceedings{connolly_cumulative_1984,
	address = {Atlanta, {GA,} {USA}},
	title = {Cumulative generation of octree models from range data},
	lccn = {0046},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1087212},
	doi = {10.1109/ROBOT.1984.1087212},
	abstract = {This paper describes algorithms used to assimilate one or more range images into an octree model of the three dimensional space surrounding the subject of the range images. In addition, a software package for simulating a three dimensional sensor setup is described.},
	booktitle = {Proceedings. 1984 {IEEE} International Conference on Robotics and Automation},
	author = {C. Connolly},
	year = {1984},
	keywords = {ancient, octree},
	pages = {25--32},
	annote = {{\textless}p{\textgreater}can't find paper even with tntech stuff{\textless}/p{\textgreater}}
},

@article{guttman_r-trees:_1984,
	title = {R-trees: a dynamic index structure for spatial searching},
	volume = {14},
	issn = {0-89791-128-8},
	lccn = {5072},
	url = {http://dx.doi.org/10.1145/602259.602266},
	abstract = {In order to handle spatial data efficiently, as required in computer aided design and geo-data applications, a database system needs an index mechanism that will help it retrieve data items quickly according to their spatial locations However, traditional indexing methods are not well suited to data objects of non-zero size located m multi-dimensional spaces In this paper we describe a dynamic index structure called an R-tree which meets this need, and give algorithms for searching and updating it. We present the results of a series of tests which indicate that the structure performs well, and conclude that it is useful for current database systems in spatial applications},
	number = {2},
	journal = {{SIGMOD} Rec.},
	author = {Antonin Guttman},
	year = {1984},
	keywords = {ancient, r-tree, spatial-search},
	pages = {47--57},
	annote = {{\textless}p{\textgreater}1816 citations! (google says 5000+){\textless}/p{\textgreater}},
	annote = {{\textless}p{\textgreater}like a quad-tree, but with rectangular regions instead...{\textless}/p{\textgreater}
{\textless}p{\textgreater}intro has some interesting related work on cell methods for nearest neighbor, but couldn't find the pdf...{\textless}/p{\textgreater}}
},

@techreport{thorpe_path_1984,
	title = {Path Relaxation: Path Planning for a Mobile Robot.},
	lccn = {0098},
	shorttitle = {Path Relaxation},
	url = {http://stinet.dtic.mil/oai/oai?&verb=getRecord&metadataPrefix=html&identifier=ADA141779},
	abstract = {Path Relaxation is a method of planning safe paths around obstacles for mobile robots. It works in two steps: a global grid search that finds a rough path, followed by a local relaxation step that adjusts each node on the path to lower the overall path cost. The representation used by Path Relaxation allows an explicit tradeoff among length of path, clearance away from obstacles, and distance traveled through unmapped areas. {(Author)}},
	author = {C. E Thorpe},
	month = apr,
	year = {1984},
	keywords = {{*Algorithms,} ancient, {BIONICS,} {*COLLISION} {AVOIDANCE,} Global, Grids, Mobile, Obstacles, {*Path} planning, {*Paths,} Planning, Relaxation, {*Robots,} Safety, {THEORETICAL} {MATHEMATICS}},
	annote = {{{\textless}p{\textgreater}It} seems that back in the day path planning and mapping were indistinct entities.{\textless}/p{\textgreater}
{{\textless}p{\textgreater}The} map was made for the use of a particular planning algorithm. In 1984, the breakdown was in terms of a few types of mapping/planning paradigms;{\textless}/p{\textgreater}
{\textless}p{\textgreater}free space methods (voronoi diagrams){\textless}/p{\textgreater}
{\textless}p{\textgreater}vertex graphs (point to point connections if no obstacle in between them){\textless}/p{\textgreater}
{\textless}p{\textgreater}potential fields:{\textless}/p{\textgreater}
{\textless}p{\textgreater}regular grid: (occupancy grid){\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}
{{\textless}p{\textgreater}This} paper describes running A* over a grid. The "relaxation" is a fine-tuning step to optimize between short distance and safe path.{\textless}/p{\textgreater}}
},

@article{samet_quadtree_1984,
	title = {The Quadtree and Related Hierarchical Data Structures},
	volume = {16},
	issn = {0360-0300},
	lccn = {1426},
	url = {http://dx.doi.org/10.1145/356924.356930},
	abstract = {Note: {OCR} errors may be found in this Reference List extracted from the full text article. {ACM} has opted to expose the complete List rather than only correct and linked references.},
	number = {2},
	journal = {{ACM} Comput. Surv.},
	author = {Hanan Samet},
	month = jun,
	year = {1984},
	keywords = {ancient, quadtree, survey},
	pages = {187--260},
	annote = {{\textless}p{\textgreater}75 page survey on quadtrees and related data structures!!{\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}
{{\textless}p{\textgreater}INTRODUCTION{\textless}br} /{\textgreater}1. {OVERVIEW} {OF} {QUADTREES{\textless}br} /{\textgreater}2. {REGION} {DATA{\textless}br} /{\textgreater}2.1 {Neighbor-Finding} Techniques{\textless}br /{\textgreater}2.2 Alternative Ways to Represent Quadtrees{\textless}br /{\textgreater}2.3 Conversion{\textless}br /{\textgreater}2.4 Set Operations{\textless}br /{\textgreater}2.5 Transformations{\textless}br /{\textgreater}2.6 Areas and Moments{\textless}br /{\textgreater}2.7 Connected Component Labeling{\textless}br /{\textgreater}2.8 Perimeter{\textless}br /{\textgreater}2.9 Component Counting{\textless}br /{\textgreater}2.10 Space Requirements{\textless}br /{\textgreater}2.11 Skeletons and Medial Axis Transforms{\textless}br /{\textgreater}2.12 Pyramids{\textless}br /{\textgreater}2.13 Quadtree Approximation Methods{\textless}br /{\textgreater}2.14 Volume Data{\textless}br /{\textgreater}3. {POINT} {DATA{\textless}br} /{\textgreater}3.1 Point Quadtrees and k-d Trees{\textless}br /{\textgreater}3.2 {Region-Based} Qualities{\textless}br /{\textgreater}3.3 Comparison of Point Quadtrees{\textless}br /{\textgreater}and {Region-Based} Quadtrees{\textless}br /{\textgreater}3.4 {CIF} Quadtrees{\textless}br /{\textgreater}3.5 Bucket Methods{\textless}br /{\textgreater}4. {CURVILINEAR} {DATA{\textless}br} /{\textgreater}4.1 Strip Trees{\textless}br /{\textgreater}4.2 Methods Based on a Regular Decomposition{\textless}br /{\textgreater}4.3 Comparison{\textless}/p{\textgreater}}
},

@inproceedings{brooks_visual_1985,
	title = {Visual map making for a mobile robot},
	volume = {2},
	lccn = {0155},
	doi = {10.1109/ROBOT.1985.1087348},
	abstract = {Mobile robots sense their environment and receive error laden readings. They try to move a certain distance and direction, and do so only approximately. Rather than try to engineer these problems away it may be possible, and may be necessary, to develop map making and navigation algorithms which explicitly represent these uncertainties, but still provide robust performance. The key idea is to use a relational map, which is rubbery and stretchy, rather than try to place observations in a 2-d coordinate system.},
	booktitle = {Robotics and Automation. Proceedings. 1985 {IEEE} International Conference on},
	author = {R. Brooks},
	year = {1985},
	keywords = {ancient, star},
	pages = {824--829},
	annote = {{\textless}p{\textgreater}outside tntech subscription{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Mobile} robots sense their environment and receive error laden readings.  They try to move a certain distance and direction, and do so only  approximately. Rather than try to engineer these problems away it may be  possible, and may be necessary, to develop map making and navigation  algorithms which explicitly represent these uncertainties, but still  provide robust performance. The key idea is to use a relational map,  which is rubbery and stretchy, rather than try to place observations in a  2-d coordinate system.{\textless}/p{\textgreater}
{\textless}p{\textgreater}sounds promising!{\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}
{{\textless}p{\textgreater}"Brooks} 85 says mobile robots should not use global reference frame, that  local ref frames links via uncertainty transformations is better. Smith  and Cheeseman show that if you build in the uncertainty into the frame,  this distinction is unnecessary."{\textless}/p{\textgreater}}
},

@article{carlbom_hierarchical_1985,
	title = {A Hierarchical Data Structure for Representing the Spatial Decomposition of {3-D} Objects},
	volume = {5},
	lccn = {0098},
	url = {http://dx.doi.org/10.1109/MCG.1985.276454},
	abstract = {The polytree, a generalization of the octree data structure, retains most of the desirable features of the octree structure while offering several advantages.},
	number = {4},
	journal = {Computer Graphics and Applications, {IEEE}},
	author = {I Carlbom and I Chakravarty and D Vanderschel},
	year = {1985},
	keywords = {ancient, octree, polytree},
	pages = {24--31},
	annote = {{\textless}p{\textgreater}can't get to pdf...{\textless}/p{\textgreater}}
},

@inproceedings{chatila_position_1985,
	address = {St. Louis, {MO,} {USA}},
	title = {Position referencing and consistent world modeling for mobile robots},
	lccn = {0410},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1087373},
	doi = {10.1109/ROBOT.1985.1087373},
	abstract = {In order to understand its environment, a mobile robot should be able to model consistently this environment, and to locate itself correctly. One major difficulty to be solved is the inaccuracies introduced by the sensors. The approach proposed in this paper to cope with this problem relies on 1) defining general principles to deal with uncertainties : the use of a multisensory system, favo ring of the data collected by the more accurate sensor in a given situation, averaging of different but consistent measurements of the same entity weighted with their associated uncertainties, and 2) a methodology enabling a mobile robot to define its own reference landmarks while exploring its environment. These ideas are presented together with an example of their application on the mobile robot {HILARE.}},
	booktitle = {Proceedings. 1985 {IEEE} International Conference on Robotics and Automation},
	author = {R. Chatila and J. Laumond},
	year = {1985},
	keywords = {ancient, geometric},
	pages = {138--145},
	annote = {{{\textless}p{\textgreater}First} paper to use sets of polyhedra for describing geometry of environment, Chatila Laumond, repr {2D} maps as a collection of lines rather than grids, fleshed out in [6, 58, 61]{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Read} this briefly, should read again more closely when have time because didn't get the polyhedra and lines collection parts{\textless}br /{\textgreater}{\textless}br /{\textgreater}*[6] R. Biswas, B. Limketkai, S. Sanner, and S. Thrun. Towards object mapping in dynamic environments with mobile robots. Submitted for publication, 2002{\textless}br /{\textgreater}[58] Y. Liu, R. Emery, D. Chakrabarti, W. Burgard, and S. Thrun. Using {EM} to learn {3D} models with mobile robots. In Proceedings of the International Conference on Machine Learning {(ICML),} 2001{\textless}br /{\textgreater}[61] C. Martin and S. Thrun. Online acquisition of compact volumetric maps with mobile robots. In {IEEE} International Conference on Robotics and Automation {(ICRA),} Washington, {DC,} 2002. {ICRA.{\textless}/p{\textgreater}}}
},

@inproceedings{cheeseman_defense_1985,
	title = {In Defense of Probability},
	lccn = {0302},
	abstract = {In this paper, it is argued that probability theory, when
used correctly, is suffrcient for the task of reasoning under
uncertainty. Since numerous authors have rejected prob-
ability as inadequate for various reasons, the bulk of the
paper is aimed at refuting these claims and indicating the
scources of error. In particular, the definition of probability
as a measure of belief rather than a frequency ratio is advo-
cated, since a frequency interpretation of probability dras-
tically restricts the domain of applicability. Other sources
of error include the confusion between relative and abso-
lute probability, the distinction between probability and
the uncertainty of that probability. Also, the interaction
of logic and probability is discusses and it is argued that
many extensions of logic, such as "default logic" are better
understood in a probabilistic framework. The main claim
of this paper is that the numerous schemes for represent-
ing and reasoning about uncertainty that have appeared in
the {AI} literature are unnecessary�probability is all that is
needed.},
	booktitle = {Proc. 9th International Joint Conf. on Artificial Intelligence},
	publisher = {Morgan Kaufmann},
	author = {P Cheeseman},
	year = {1985},
	keywords = {ancient, bayesian, big},
	pages = {1002--1009},
	annote = {{{\textless}p{\textgreater}Super-interesting} paper by the guy who basically invented {SLAM,} basically arguing that probability is the future of {AI,} not logic/deduction systems, that the acceptance problems stem from an incorrect interpretation of probability itself (frequentist instead of the correct Bayesian){\textless}/p{\textgreater}}
},

@article{flynn_redundant_1985,
	title = {Redundant Sensors for Mobile Robot Navigation},
	lccn = {0031},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.18.2012},
	abstract = {Redundant sensors are needed on a mobile robot so that the accuracy with which it perceives its surroundings can be increased. Sonar and infrared sensors are used here in tandem, each compensating for deficiencies in the other. The robot combines the data from both sensors to build a representation which is more accurate than if either sensor were used alone. Another representation, the curvature primal sketch, is extracted from this perceived workspace and is used as the input to two path planning programs: one based on configuration space and one based on a generalized cone formulation of free space.},
	author = {Anita M Flynn},
	year = {1985},
	keywords = {ancient, survey, thesis},
	annote = {{\textless}p{\textgreater}did moravec work on shakey?{\textless}/p{\textgreater}
{\textless}p{\textgreater}there is a nice section on early robots in the related work sections here, which make it seem like shakey world view involved not only mapping, but what essentially are quadtrees, (nest 4x4 cells) (check out rosen 68 nilsson 69a?){\textless}/p{\textgreater}
{\textless}p{\textgreater}figure 2-3 points out the aliasing problem in that a grid cannot represent a skewed square (!).. also discusses the line model which it says didnt work out for them.{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Property} list model: object model, with lists of object represented by x,y,angle, size, shape, etc.{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Interestingly,} though shakey was revolutionary, it stalled funds in the area for a while (10 years?) [dreyfus 79] - what computers can't do ...{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Lesson} learned: low-level tasks impossible, high-level easy for computers {(Moravec's} paradox?){\textless}/p{\textgreater}
{\textless}p{\textgreater}[raphael 68] couldn't simulate this, because it is hard to design an algorithm to simulate adequately poor data{\textless}/p{\textgreater}
{\textless}p{\textgreater}[moravec 81b] keeps getting cited when pictures of robots pop up...{\textless}/p{\textgreater}
{{\textless}p{\textgreater}JPL} mars rover (70-73), never got untethered, but did large-sale mapping. grid lines in a absolute coord system, broken into chunks which could be stored as separate files, labels were simply "not traversable" or unknown. non-traversable regions were polygons and then lists of their vertices. Errors plagued it. Things that came from this work: manipulator, laser rangefinder, and the navigation system{\textless}/p{\textgreater}
{\textless}p{\textgreater}stanford cart (73-81) - interest operator looks at areas with maximum gradient of grey scale. cart successfully moved through 20 meter courses (5 hours each), but often failed..{\textless}/p{\textgreater}
{\textless}p{\textgreater}when moravec came to cmu, he used 24 sonar in a ring around the robot to make a probability map to represent empty, occupied, or unknown, each cell repr size square inches of floor space, and the values ranged [-1,1]. Neg were prob that empty, pos. meant occupied, 0 was unknown. [moravec 85] for great mapping picture{\textless}/p{\textgreater}
{\textless}p{\textgreater}hilare [77+], [giralt 77, laumond 83] obstalces as polyhedrons, repr as ordered list of segments, where each segment is repr by the cartesian coords of the leftmost point, an angle wrt reference axis, and length "traj within cells are straight line paths between entry and exit segments so that adjacent cells have common segments which are traversable by the robot, the pattern of connectivity can be repr as a graph"{\textless}/p{\textgreater}
{\textless}p{\textgreater}[chatila 85] map merges laser scans as the robot moves from one position to another. seems way too advanced!{\textless}/p{\textgreater}
{\textless}p{\textgreater}robart I: (80-82) - pretty cool, could find its own charger, could sense body heat, and talk. optical encoders gave four bits of steer angle (?), = 22 degrees of error, but software took care of it. in over 200 dockings, robart only failed once to hit its station within half an inch from the centerline of its front bumper. powered by one {12V} 20 A-h, providing 10 hours (charging took 14 hours){\textless}/p{\textgreater}
{\textless}p{\textgreater}robart {II:} (82+) subejct of this thesis, fig 4-1 shows a neat sonar plot of the room, also infrared later on. Simple rule-based approach to either take the value of the sonar, or the infrared, based on manually inspecting failure cases in both sensors.{\textless}/p{\textgreater}
{\textless}p{\textgreater}how does she deal with the raw range data (fine grid), first is the curvature primal sketch (brady 84), which "is convenient for merging separate views between robot moves", that can then be converted into a polygonal repr suitable for path planners (brooks 83, 85){\textless}/p{\textgreater}
{\textless}p{\textgreater}the curvature primal sketch fits (sp)lines to knot points where there is significant change in curvature (using gaussian filters similar to canny 83), to make corners ends and smooth joins. since the "knot points" are determined only by the relationship with their neightbors, so it becomes easier to do registration. Becuase even if the view changes dramatically at the global scale, certain local areas will stay close to the same location. fig 5-2 shoes a move two ft to right, still can find knot points{\textless}/p{\textgreater}
{\textless}p{\textgreater}"generalized cones" ?? [brooks 83]{\textless}/p{\textgreater}
{\textless}p{\textgreater}referencing hilare: local coord frames to cluster of data points that are line-fitted. Edges adjoining them are marked as fake. By looking at fake ad real, robot can hypotehsize about what it might see (uncovering), or what might become occluded. Having edged referenced to local coordinate frfames reduces uncrertainty in the building of the final map{\textless}/p{\textgreater}}
},

@misc{ogden_pyramid_1985,
	title = {Pyramid Based Computer Graphics},
	lccn = {0061},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.30.2405},
	abstract = {: This paper describes pyramid solutions to graphics
problems that have proven difficult in other image
representations. The "physics simulation" approach grows more
out of the physics and mathematical modelling traditions.
Greater realism can be achieved by using the physics simulation
approach but the complexity and computation time are vastly
increased over the multiresolution pyramid approaches
described here.
1985 {RCA} Corporation
Final manuscript received October 21, 1985
Reprint...},
	author = {J Ogden and E Adelson and J Bergen and P Burt},
	year = {1985},
	keywords = {ancient, extrapolation, pyramid}
},

@inproceedings{moravec_high_1985,
	title = {High resolution maps from wide angle sonar},
	volume = {2},
	lccn = {0913},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1087316},
	abstract = {We describe the use of multiple wide-angle sonar range measurements to map the surroundings of an autonomous mobile robot. A sonar range reading provides information concerning empty and occupied volumes in a cone (subtending 30 degrees in our case) in front of the sensor. The reading is modelled as probability profiles projected onto a rasterized map, where somewhere occupied and everywhere empty areas are represented. Range measurements from multiple points of view (taken from multiple sensors on the robot, and from the same sensors after robot moves) are systematically integrated in the map. Overlapping empty volumes re-inforce each other, and serve to condense the range of occupied volumes. The map definition improves as more readings are added. The final map shows regions probably occupied, probably unoccupied, and unknown areas. The method deals effectively with clutter, and can be used for motion planning and for extended landmark recognition. This system has been tested on the Neptune mobile robot at {CMU.}},
	booktitle = {Robotics and Automation. Proceedings. 1985 {IEEE} International Conference on},
	author = {H Moravec and A Elfes},
	month = jan,
	year = {1985},
	keywords = {ancient, mobile-robot, navigation, occupancy grid},
	pages = {116--121},
	annote = {{\textless}p{\textgreater}cited by 227{\textless}/p{\textgreater}
{\textless}p{\textgreater}one of first occupancy grid papers{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Note} that the forward sensor model is simply some "best-guess" curves (parabolas){\textless}/p{\textgreater}
{{\textless}p{\textgreater}Bayesian} not mentioned even once here{\textless}/p{\textgreater}
{\textless}p{\textgreater}p. 120 has some really interesting notes:{\textless}/p{\textgreater}
{\textless}p{\textgreater}- registration: naive is O(n{\textasciicircum}5), but typically only O(n) occupied cells. So they just enumerate the occupied cells of the first map, transform to the proper area and see if the corresponding cell is occupied in the second map. Then the reverse is done.{\textless}/p{\textgreater}
{\textless}p{\textgreater}- they use hierarchically reduced resolutions to speed up registration as well O(n) and \&lt;1 second on the Vax! Note that they had to blur maps significantly or aliasing from high spatial frequencies would make the scans unmatchable.{\textless}/p{\textgreater}
{\textless}p{\textgreater}-with the final process, maps with about 3k 6in cells made from 200 readings could be matches with an accuracy of 6 inches displacement,� 3 degrees of rotation in one second of vax time{\textless}/p{\textgreater}}
},

@techreport{kambhampati_multiresolution_1985,
	title = {Multiresolution Path Planning for Mobile Robots,},
	lccn = {0224},
	url = {http://stinet.dtic.mil/oai/oai?&verb=getRecord&metadataPrefix=html&identifier=ADA158630},
	abstract = {The problem of automatic collision-free path planning is central to mobile robot applications. This report presents an approach to automatic two dimensional path planning based on a quadtree representation. {(A} quadtree is a recursive decomposition of a {2-D} picture into uniformly colored sub i X 2 sub i blocks). The authors introduce hierarchical path searching methods, which make use of this multiresolution representation, to speed up the path planning process considerably. Finally, we discuss the applicability of this approach to mobile robot path planning. Additional keywords: Path planning algorithms; Computer vision.},
	author = {S. Kambhampati and L. S Davis},
	month = may,
	year = {1985},
	keywords = {algorithms, ancient, {COLLISION} {AVOIDANCE.,} Collision free paths, {COMPUTER} {HARDWARE,} {COMPUTER} {PROGRAMMING} {AND} {SOFTWARE,} {COMPUTER} {PROGRAMS,} {COMPUTERS,} Computer vision, {CYBERNETICS,} {DECOMPOSITION,} {HIERARCHIES,} {IMAGE} {PROCESSING,} Mobile, Multiresolution path planning, {OPTICAL} {DETECTION,} {PATHS,} {PATTERN} {RECOGNITION,} Planning, quadtree, {RECURSIVE} {FUNCTIONS,} {RESOLUTION,} {*Robots,} {*ROUTING,} {SEARCHING,} {TWO} {DIMENSIONAL,} {VISION}}
},

@article{brooks_robust_1986,
	title = {A robust layered control system for a mobile robot},
	volume = {2},
	issn = {0882-4967},
	lccn = {6686},
	doi = {10.1109/JRA.1986.1087032},
	abstract = {A new architecture for controlling mobile robots is described. Layers of control system are built to let the robot operate at increasing levels of competence. Layers are made up of asynchronous modules that communicate over low-bandwidth channels. Each module is an instance of a fairly simple computational machine. Higher-level layers can subsume the roles of lower levels by suppressing their outputs. However, lower levels continue to function as higher levels are added. The result is a robust and flexible robot control system. The system has been used to control a mobile robot wandering around unconstrained laboratory areas and computer machine rooms. Eventually it is intended to control a robot that wanders the office areas of our laboratory, building maps of its surroundings using an onboard arm to perform simple tasks.},
	number = {1},
	journal = {Robotics and Automation, {IEEE} Journal of},
	author = {R. Brooks},
	year = {1986},
	keywords = {ancient, Hierarchical systems, Robots, locomotion, Robustness, star},
	pages = {14--23},
	annote = {{{\textless}p{\textgreater}Introduced} layered intelligence: 6000+ references{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Brooks} 84 might be the first paper to introduce this:{\textless}/p{\textgreater}
{\textless}p{\textgreater}0. Avoid contact with objects{\textless}/p{\textgreater}
{\textless}p{\textgreater}1. Wander aimlessly{\textless}/p{\textgreater}
{\textless}p{\textgreater}2. Explore the world by making set points and heading for them{\textless}/p{\textgreater}
{\textless}p{\textgreater}3. Build map and plan routes from one place to another{\textless}/p{\textgreater}
{\textless}p{\textgreater}4. Be able to detect changes in a static environment{\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}}
},

@article{smith_representation_1986,
	title = {On the Representation and Estimation of Spatial Uncertainty},
	volume = {5},
	lccn = {0685},
	abstract = {This paper describes a general method for estimating the nominal relationship and expected error (covariance) between coordinate frames representing the relative locations of ob jects. The frames may be known only indirectly through a series of spatial relationships, each with its associated error, arising from diverse causes, including positioning errors, measurement errors, or tolerances in part dimensions. This estimation method can be used to answer such questions as whether a camera attached to a robot is likely to have a particular reference object in its field of view. The calculated estimates agree well with those from an independent Monte Carlo simulation. The method makes it possible to decide in advance whether an uncertain relationship is known accu rately enough for some task and, if not, how much of an improvement in locational knowledge a proposed sensor will provide. The method presented can be generalized to six degrees offreedom and provides a practical means of esti mating the relationships ( position and orientation) among objects, as well as estimating the uncertainty associated with the relationships.},
	number = {4},
	journal = {Int. J. Robot. Res.},
	author = {{RC} Smith and P Cheeseman},
	year = {1986},
	keywords = {ancient, robotics, slam},
	pages = {56--68},
	annote = {{\textless}p{\textgreater}first slam paper according to thrun survey...{\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}
{{\textless}p{\textgreater}http://en.wikipedia.org/wiki/Kalman\_filter} is a great resource for kalman filter basics{\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Brooks} 85 says mobile robots should not use global reference frame, that local ref frames links via uncertainty transformations is better. Smith and Cheeseman show that if you build in the uncertainty into the frame, this distinction is unnecessary.{\textless}/p{\textgreater}
{\textless}p{\textgreater}"visual map making for a mobile robot"{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Use} circuit diagrams and math tricks to prove difference merging procedures.{\textless}/p{\textgreater}}
},

@inproceedings{elfes_sensor_1987,
	title = {Sensor integration for robot navigation: Combining sonar and stereo range data in a grid-based representataion},
	lccn = {0028},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4049608},
	doi = {10.1109/CDC.1987.272800},
	abstract = {Multiple range sensors are essential in mobile robot navigation systems. This introduces the problem of integrating noisy range data from multiple sensors and multiple robot positions into a common description of the environment. We propose a cellular representation called the occupancy grid as a solution to this problem. In this paper, we use occupancy grids to combine range information from sonar and one-dimensional stereo into a two-dimensional map of the vicinity of a robot. Each cell in the map contains a probabilistic estimate of whether it is empty or occupied by an object in the environment. These estimates are obtained from sensor models that describe the uncertainty in the range data. A Bayesian estimation scheme is used to update the existing map with successive range profiles from each sensor. This representation is simple to manipulate, treats different sensors uniformly, and models uncertainty in the sensor data and in the robot position. It also provides a basis for motion planning and creation of higherlevel object descriptions.},
	booktitle = {26th {IEEE} Conference on Decision and Control},
	author = {Alberto Elfes and Larry Matthies},
	year = {1987},
	keywords = {ancient, occupancy grid},
	pages = {1802--1807}
},

@inproceedings{sellis_r+-tree:_1987,
	title = {The {R+-Tree:} A Dynamic Index for {Multi-Dimensional} Objects},
	lccn = {1292},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.3272},
	abstract = {The problem of indexing multidimensional objects is considered. First, a classification of existing methods is given along with a discussion of the major issues involved in multidimensional data indexing. Second, a variation to Guttman's R-trees {(R} -trees) that avoids overlapping rectangles in intermediate nodes of the tree is introduced. Algorithms for searching, updating, initial packing and reorganization of the structure are discussed in detail. Finally, we provide analytical results...},
	booktitle = {The {VLDB} Journal},
	author = {Timos Sellis and Nick Roussopoulos and Christos Faloutsos},
	year = {1987},
	keywords = {ancient, high\_dim\_index, r-tree},
	pages = {507--518}
},

@inproceedings{smith_estimating_1987,
	title = {Estimating uncertain spatial relationships in robotics},
	volume = {4},
	lccn = {0830},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1087846},
	abstract = {In this paper, we describe a representation for spatial information, called the
stochastic map, and associated procedures for building it, reading information
from it, and revising it incrementally as new information is obtained. The map
contains the estimates of relationships among objects in the map, and their un-
certainties, given all the available information. The procedures provide a general
solution to the problem of estimating uncertain relative spatial relationships.
The estimates are probabilistic in nature, an advance over the previous, very
conservative, worst-case approaches to the problem. Finally, the procedures are
developed in the context of state-estimation and filtering theory, which provides
a solid basis for numerous extensions.},
	booktitle = {Robotics and Automation. Proceedings. 1987 {IEEE} International Conference on},
	author = {R Smith and M Self and P Cheeseman},
	year = {1987},
	keywords = {ancient, localization, slam},
	pages = {850},
	annote = {{\textless}p{\textgreater}conference version of one of the first slam papers...{\textless}/p{\textgreater}}
},

@inproceedings{smith_stochastic_1987,
	title = {A Stochastic Map for Uncertain Spatial Relationships},
	lccn = {0279},
	abstract = {In this paper we will describe a representation for spatial relationships which makes explicit their inherent uncertainty.
We will show ways to manipulate them to obtain estimates of relationships and associated uncertainties not explicitly
given, and show how decisions to sense or act can be made a priori based on those estimates. We will show how new
constraint information, usually obtained by measurement, can be used to update the world model of relationships
consistently, and in some situations, optimally. The framework we describe relies only on well-known state estimation
methods.},
	author = {{RC} Smith and M Self and P Cheeseman},
	year = {1987},
	keywords = {ancient, robotics, slam, star},
	pages = {421--429},
	annote = {{{\textless}p{\textgreater}A} Martial paper from 1986 is shown!{\textless}/p{\textgreater}
{{\textless}p{\textgreater}One} of the first {SLAM} papers.{\textless}/p{\textgreater}}
},

@article{elfes_sonar-based_1987,
	title = {Sonar-based real-world mapping and navigation},
	volume = {3},
	issn = {0882-4967},
	lccn = {0987},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1087096},
	doi = {10.1109/JRA.1987.1087096},
	abstract = {A sonar-based mapping and navigation system developed for an autonomous mobile robot operating in unknown and unstructured environments is described. The system uses sonar range data to build a multileveled description of the robot's surroundings. Sonar readings are interpreted using probability profiles to determine empty and occupied areas. Range measurements from multiple points of view are integrated into a sensor-level sonar map, using a robust method that combines the sensor information in such a way as to cope with uncertainties and errors in the data. The resulting two-dimensional maps are used for path planning and navigation. From these sonar maps, multiple representations are developed for various kinds of problem-solving activities. Several dimensions of representation are defined: the abstraction axis, the geographical axis, and the resolution axis. The sonar mapping procedures have been implemented as part of an autonomous mobile robot navigation system called Dolphin. The major modules of this system are described and related to the various mapping representations used. Results from actual runs are presented, and further research is mentioned. The system is also situated within the wider context of developing an advanced software architecture for autonomous mobile robots.},
	number = {3},
	journal = {{IEEE} Journal on Robotics and Automation},
	author = {A. Elfes},
	year = {1987},
	keywords = {ancient, occupancy grid},
	pages = {249--265},
	annote = {{\textless}p{\textgreater}one of earliest occupancy grid algorithms{\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}}
},

@article{kuipers_navigation_1988,
	title = {Navigation and mapping in large-scale space},
	volume = {9},
	lccn = {0290},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.13.3035},
	abstract = {In a large*scale space, structure is at a sig-nificantly larger scale than the observa-tions available at an instant. To learn the structure of a large-scale space from observations, the observer must build a cognitive map of the environment by integrat-ing observations over an extended period of time, inferring spatial structure from perceptions and the effects of actions. The cognitive map representation of large-scale space must account for a mapping, or learning structure from observations, and navigation, or creating and executing a plan to travel from one place to another. Approaches to date tend to be fragile either because they don't build maps; or because they assume nonlocal observations, such as those available in preexist-ing maps or global coordinate systems, including active landmark beacons and geo-iocating satellites. We propose that robust navigation and mapping systems for large.scale space can be developed by adhering to a natural, four-level semantic hierarchy of descriptions for representation, planning, and execution of plans in large-scale space. The four levels are sensorimotor interac-tion, procedural behaviors, topological mapping, and metric mapping. Effective systems represent the environment, rela-tive to sensors, at all four levels and formulate robust system behavior by moving fiexibly between representational levels at run time. We demonstrate our claims in three implemented models: Tour, the Qualnav system simulator, and the {NX} robot.},
	journal = {{AI} Magazine},
	author = {Benjamin Kuipers and Tod Levitt},
	year = {1988},
	keywords = {ancient, cognitive map, mapping, topological},
	pages = {25--43}
},

@inproceedings{matthies_integration_1988,
	address = {Philadelphia, {PA,} {USA}},
	title = {Integration of sonar and stereo range data using a grid-based representation},
	lccn = {0117},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=12145},
	doi = {10.1109/ROBOT.1988.12145},
	abstract = {The authors use occupancy grids to combine range information from sonar and one-dimensional stereo into a two-dimensional map of the vicinity of a robot. Each cell in the map contains a probabilistic estimate of whether it is empty or occupied by an object in the environment. These estimates are obtained from sensor models that describe the uncertainty in the range data. A Bayesian estimation scheme is applied to update the current map using successive range readings from each sensor. The occupancy grid representation is simple to manipulate, treats different sensors uniformly, and models uncertainty in the sensor data and in the robot position. It also provides a basis for motion planning and creation of more abstract object descriptions},
	booktitle = {Proceedings. 1988 {IEEE} International Conference on Robotics and Automation},
	author = {L. Matthies and A. Elfes},
	year = {1988},
	keywords = {ancient, occupancy grid, star},
	pages = {727--733}
},

@article{moravec_sensor_1988,
	title = {Sensor fusion in certainty grids for mobile robots},
	volume = {9},
	lccn = {0749},
	abstract = {A numeric representation of uncertain and incomplete sensor knowledge called certainty grids was used successfully in several recent mobile robot control programs developed at the {Carnegie-Mellon} University Mobile Robot Laboratory {(MRL).} Certainty grids have proven to be a powerful and efficient unifying solution for sensor fusion, motion planning, landmark identification, and many other central problems. {MRL} had good early success with ad hoc formulas for updating grid cells with new information. A new Bayesian statistical foundation for the operations promises further improvement. {MRL} proposes to build a software framework running on processors onboard the new Uranus mobile robot that will maintain a probabilistic, geometric map of the robot's surroundings as it moves. The certainty grid representation will allow this map to be incrementally updated in a uniform way based on information coming from various sources, including sonar, stereo vision, proximity, and contact sensors. The approach can correctly model the fuzziness of each reading and, at the same time, combine multiple measurements to produce sharper map features; it can also deal correctly with uncertainties in the robot's motion. The map will be used by planning programs to choose clear paths, identify locations (by correlating maps), identify well-known and insufficiently sensed terrain, and perhaps identify objects by shape. The certainty grid representation can be extended in the time dimension and used to detect and track moving objects. Even the simplest versions of the idea allow us to fairly straightforwardly program the robot for tasks that have hitherto been out of reach. {MRL} looks forward to a program that can explore a region and return to its starting place, using map "snapshots" from its outbound journey to find its way back, even in the presence of disturbances of its motion and occasional changes in the terrain.},
	journal = {{AI} Magazine},
	author = {{HP} Moravec},
	year = {1988},
	keywords = {ancient, hippo-import, occupancy grid},
	pages = {61--74},
	annote = {{\textless}p{\textgreater}one of the first papers for occupancy grids, cited by 220{\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}
{\textless}p{\textgreater}according to google 747 citations{\textless}/p{\textgreater}}
},

@inproceedings{stewart_model-based_1988,
	title = {A model-based approach to {3-D} imaging and mapping underwater},
	lccn = {0117},
	abstract = {(none found)},
	booktitle = {Proceedings of the... International Conference on Offshore Mechanics and Arctic Engineering},
	author = {W. K. Stewart},
	year = {1988},
	keywords = {3d, ancient},
	pages = {61},
	annote = {{\textless}p{\textgreater}first 3d map according to early work in occ grids by elfes and matthies{\textless}/p{\textgreater}}
},

@article{thorpe_vision_1988,
	title = {Vision and navigation for the {Carnegie-Mellon} Navlab},
	volume = {10},
	issn = {01628828},
	lccn = {0458},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=3900},
	doi = {10.1109/34.3900},
	abstract = {A distributed architecture articulated around the {CODGER} (communication database with geometric reasoning) knowledge database is described for a mobile robot system that includes both perception and navigation tools. Results are described for vision and navigation tests using a mobile testbed that integrates perception and navigation capabilities that are based on two types of vision algorithms: color vision for road following, and {3-D} vision for obstacle detection and avoidance. The perception modules are integrated into a system that allows the vehicle to drive continuously in an actual outdoor environment. The resulting system is able to navigate continuously on roads while avoiding obstacles},
	number = {3},
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {C. Thorpe and {M.H.} Hebert and T. Kanade and {S.A.} Shafer},
	year = {1988},
	keywords = {ancient, navlab},
	pages = {362--373},
	annote = {{\textless}p{\textgreater}laser into buckets{\textless}/p{\textgreater}}
},

@article{bajcsy_active_1988,
	title = {Active perception},
	volume = {76},
	issn = {00189219},
	lccn = {1064},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5968},
	doi = {10.1109/5.5968},
	abstract = {Active perception (active vision specifically) is defined as a study of modeling and control strategies for perception. Local methods are distinguished from global models by their extent of application in space and time. The local models represent procedures and parameters such as optical distortions of the lens, focal lens, spatial resolution, bandpass filter, etc, The global models, on the other hand, characterize the overall performance and make predictions on how the individual modules interact. The control strategies are formulated as a search of such sequences of steps that would minimize a loss function while still seeking the most information. Examples are shown as the existence proof of the proposed theory on obtaining range from focus and stereo/vergence on {2-D} segmentation of an image and {3-D} shape parameterization},
	number = {8},
	journal = {Proceedings of the {IEEE}},
	author = {R. Bajcsy},
	month = aug,
	year = {1988},
	keywords = {ancient, shape},
	pages = {966--1005}
},

@article{ayache_building_1988,
	title = {Building, Registrating, and Fusing Noisy Visual Maps},
	volume = {7},
	lccn = {0167},
	url = {http://ijr.sagepub.com/content/7/6/45.abstract},
	doi = {10.1177/027836498800700605},
	abstract = {This paper deals with the problem of building three-dimen sional descriptions (we call them visual maps) of the environ ment of a mobile robot using passive vision. These maps are local (i.e., attached to specific frames of reference). Since noise is present, they incorporate information about the ge ometry of the environment and about the uncertainty of the parameters defining the geometry. This geometric uncertainty is directly related to its source (i.e., sensor uncertainty). We show how visual maps corresponding to different positions of the robot can be registered to compute a better estimate of its displacement between the various viewpoint positions, as suming an otherwise static environment. We use these esti mates to fuse the different visual maps and reduce locally the uncertainty of the geometric primitives which have found correspondents in other maps. We propose to perform these three tasks (building, registrating, and fusing visual maps) within the general framework of extended Kalman filtering, which allows efficient combination of measurements in the presence of noise.},
	number = {6},
	journal = {The International Journal of Robotics Research},
	author = {Nicholas Ayache and Olivier D. Faugeras},
	month = dec,
	year = {1988},
	keywords = {ancient, registration, slam},
	pages = {45 --65}
},

@article{ayache_maintaining_1989,
	title = {Maintaining representations of the environment of a mobile robot},
	volume = {5},
	issn = {{1042-296X}},
	lccn = {0429},
	doi = {10.1109/70.88101},
	abstract = {A description is given of current ideas related to the problem of
building and updating three-dimensional representations of the
environment of a mobile robot that uses passive vision as its main
sensory modality. The authors attempt to represent both geometry and
uncertainty. The authors motivate their approach by defining the
problems they are trying to solve and then give some simple didactic
examples. They then present a tool they think is extremely well adapted
to solving most of these problems: the extended Kalman filter {(EKF).} The
authors discuss the notions of minimal geometric representations for
three-dimensional lines, planes, and rigid motions. They show how the
{EKF} and the representations can be combined to provide solutions for
some of the problems. A number of experimental results on real data are
given},
	number = {6},
	journal = {Robotics and Automation, {IEEE} Transactions on},
	author = {N. Ayache and {O.D.} Faugeras},
	year = {1989},
	keywords = {ancient, Computer vision, ekf, environmental representation, extended Kalman filter, geometry, Kalman filters, mobile robot, Mobile robots, passive vision, sensory modality, slam-precursor, three-dimensional representations, uncertainty},
	pages = {804--819}
},

@phdthesis{elfes_occupancy_1989,
	address = {Pittsburgh, {PA,} {USA}},
	title = {Occupancy grids: a probabilistic framework for robot perception and navigation},
	lccn = {0326},
	abstract = {(thesis)},
	school = {Carnegie Mellon University},
	author = {Alberto Elfes},
	year = {1989},
	note = {{AAI9006205}},
	keywords = {ancient, occupancy grid, star},
	annote = {{\textless}p{\textgreater}cited by 322{\textless}/p{\textgreater}}
},

@inproceedings{herbet_terrain_1989,
	address = {Scottsdale, {AZ,} {USA}},
	title = {Terrain mapping for a roving planetary explorer},
	lccn = {0077},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=100111},
	doi = {10.1109/ROBOT.1989.100111},
	abstract = {The authors are prototyping a legged vehicle, the Ambler, for an exploratory mission on another planet, conceivably Mars, where it is to traverse uncharted areas and collect material samples. They describe how the rover can construct from range imagery a geometric terrain representation, i.e., elevation map that includes uncertainty, unknown areas, and local features. First, they present an algorithm for constructing an elevation map from a single range image. By virtue of working in spherical-polar space, the algorithm is independent of the desired map resolution and the orientation of the sensor, unlike algorithms that work in Cartesian space. Secondly, the authors present a two-stage matching technique (feature matching followed by iconic matching) that identifies the transformation T corresponding to the vehicle displacement between two viewing positions. Thirdly, to support legged locomotion over rough terrain, they describe methods for evaluating regions of the constructed elevation maps as footholds},
	booktitle = {Proceedings, 1989 International Conference on Robotics and Automation},
	author = {M. Herbet and C. Caillas and E. Krotkov and {I.S.} Kweon and T. Kanade},
	year = {1989},
	keywords = {ancient, mapping, polar space},
	pages = {997--1002}
},

@inproceedings{malkin_lognets:_1990,
	series = {{AAAI'90}},
	title = {{LOGnets:} a hybrid graph spatial representation for robot navigation},
	isbn = {{0-262-51057-X}},
	lccn = {0014},
	location = {Boston, Massachusetts},
	url = {http://portal.acm.org/citation.cfm?id=1865609.1865656},
	abstract = {In this article we present a novel, hybrid graph spatial representation for robot navigation. This representation enables our mobile robot to build a model of its surroundings which it can then use for navigation. The models or maps that use this representation are hybrid graphs, the nodes being analogical local maps of landmark locations in the robot's environment, the arcs being the actions the robot executes to travel between the locations. This representation yields a reliable navigation tool, one which ensures that the robot can re-orient itself to recover from errors in path execution and encounters with unexpected obstacles. The {LOGnet} approach also meshes with human's natural approach of mapping with landmarks, instead of using angular and translational data.},
	booktitle = {Proceedings of the eighth National conference on Artificial intelligence - Volume 2},
	publisher = {{AAAI} Press},
	author = {Peter K Malkin and Sanjaya Addanki},
	year = {1990},
	keywords = {old, topological},
	pages = {1045�1050}
},

@incollection{hayward_experimental_1990,
	series = {Lecture Notes in Control and Information Sciences},
	title = {An experimental system for incremental environment modelling by an autonomous mobile robot},
	volume = {139},
	lccn = {0084},
	url = {http://dx.doi.org/10.1007/BFb0042528},
	abstract = {Incremental map-making is a necessary function of an autonomous mobile robot. Sensor data are always imprecise, and in the case of a mobile robot, sensor location is itself imprecise and even sometimes false (e.g. in case of slippage). We show how sensors data inaccuracies can be processed to produce a consistent environment model and an as precise as possible robot positioning. The experimental system (a mobile robot with a laser range finder and odometry) is presented and the theoretical approach is applied on actual data.},
	booktitle = {Experimental Robotics I},
	publisher = {Springer Berlin / Heidelberg},
	author = {Vincent Hayward and Oussama Khatib and Philippe Moutarlier and Raja Chatila},
	year = {1990},
	keywords = {mapping, old},
	pages = {327--346}
},

@misc{samet_applications_1990,
	title = {Applications of Spatial Data Structures},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.73.6935},
	abstract = {An overview is presented of the use of spatial data structures in spatial databases. The focus is on hierarchical data structures, including a number of variants of quadtrees, which sort the data with respect to the space occupied by it. Such techniques are known as spatial indexing methods. Hierarchical data structures are based on the principle of recursive decomposition. They are attractive because they are compact and depending on the nature of the data they save space as well as time and also facilitate operations such as search. Examples are given of the use of these data structures in the representation of di erent data types such as regions, points, rectangles, lines, and volumes.},
	author = {Hanan Samet},
	year = {1990},
	keywords = {index, multidimensional, old, quadtree},
	howpublished = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.73.6935},
	annote = {{{\textless}p{\textgreater}http://www.umiacs.umd.edu/{\textasciitilde}hjs/pubs/SametSSD89.pdf{\textless}/p{\textgreater}}}
},

@book{samet_design_1990,
	title = {The design and analysis of spatial data structures},
	isbn = {0201502550},
	lccn = {2745},
	url = {http://portal.acm.org/citation.cfm?id=77589},
	abstract = {(book)},
	publisher = {{Addison-Wesley} Longman Publishing Co., Inc.},
	author = {Hanan Samet},
	year = {1990},
	keywords = {algorithms, book, geometries, octree, old, survey},
	annote = {{\textless}p{\textgreater}cited by 737!{\textless}/p{\textgreater}}
},

@incollection{buchmann_hierarchical_1990,
	series = {Lecture Notes in Computer Science},
	title = {Hierarchical spatial data structures},
	volume = {409},
	lccn = {0018},
	url = {http://dx.doi.org/10.1007/3-540-52208-5_28},
	abstract = {An overview is presented of the use of hierarchical spatial data structures such as the quadtree. They are based on the principle of recursive decomposition. The focus is on the representation of data used in image databases. The emphasis is on two-dimensional regions, points, rectangles, and lines.},
	booktitle = {Design and Implementation of Large Spatial Databases},
	publisher = {Springer Berlin / Heidelberg},
	author = {Alejandro Buchmann and Oliver G�nther and Terence Smith and {Yuan-Fang} Wang and Hanan Samet},
	year = {1990},
	keywords = {octree, old, quadtree},
	pages = {191--212}
},

@incollection{smith_estimating_1990,
	title = {Estimating uncertain spatial relationships in robotics},
	volume = {4},
	lccn = {0830},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1087846},
	abstract = {In this paper, we describe a representation for spatial information, called the
stochastic map, and associated procedures for building it, reading information
from it, and revising it incrementally as new information is obtained. The map
contains the estimates of relationships among objects in the map, and their un-
certainties, given all the available information. The procedures provide a general
solution to the problem of estimating uncertain relative spatial relationships.
The estimates are probabilistic in nature, an advance over the previous, very
conservative, worst-case approaches to the problem. Finally, the procedures are
developed in the context of state-estimation and filtering theory, which provides
a solid basis for numerous extensions.},
	booktitle = {Autonomous Robot Vehicles},
	author = {Randall Smith and Matthew Self and Peter Cheeseman and {IJ} Cox and {IJ} Wilfong},
	year = {1990},
	keywords = {ancient, slam},
	pages = {167--193},
	annote = {{\textless}p{\textgreater}this is one of the big slam papers in thrun's survey... very nicely laid out in a plain and expansive style{\textless}/p{\textgreater}}
},

@article{beckmann_r*-tree:_1990,
	title = {The R*-tree: an efficient and robust access method for points and rectangles},
	volume = {19},
	issn = {0-89791-365-5},
	lccn = {0004},
	url = {http://dx.doi.org/10.1145/93597.98741},
	abstract = {The R-tree, one of the most popular access methods for rectangles, is based on the heuristic optimization of the area of the enclosing rectangle in each inner node. By running numerous experiments in a standardized testbed under highly varying data, queries and operations, we were able to design the R * -tree which incorporates a combined optimization of area, margin and overlap of each enclosing rectangle in the directory. Using our standardized testbed in an exhaustive performance comparison, it turned out that the R * -tree clearly outperforms the existing R-tree variants. Guttman's linear and quadratic R-tree and Greene's variant of the R-tree. This superiority of the R * -tree holds for different types of queries and operations, such as map overlay, for both rectangles and multidimensional points in all experiments. From a practical point of view the R * -tree is very attractive because of the following two reasons 1 it efficiently supports point and spatial data at the same time and 2 its implementation cost is only slightly higher than that of other R-trees.},
	number = {2},
	journal = {{SIGMOD} Rec.},
	author = {Norbert Beckmann and Hans Kriegel and Ralf Schneider and Bernhard Seeger},
	month = jun,
	year = {1990},
	keywords = {high\_dim\_index, r-tree},
	pages = {322--331},
	annote = {{\textless}p{\textgreater}788 citations!{\textless}/p{\textgreater}}
},

@article{brooks_elephants_1990,
	title = {Elephants don't play chess},
	volume = {6},
	issn = {0921-8890},
	lccn = {0949},
	url = {http://www.sciencedirect.com.ezproxy.tntech.edu/science/article/B6V16-4KBW026-3/2/74b8c886a9a70bafb76ceb38d69d76a8},
	doi = {10.1016/S0921-8890(05)80025-9},
	abstract = {There is an alternative route to Artificial Intelligence that diverges from the directions pursued under that banner for the last thirty some years. The traditional approach has emphasized the abstract manipulation of symbols, whose grounding in physical reality has rarely been achieved. We explore a research methodology which emphasizes ongoing physical interaction with the environment as the primary source of constraint on the design of intelligent systems. We show how this methodology has recently had significant successes on a par with the most successful classical efforts. We outline plausible future work along these lines which can lead to vastly more ambitious systems.},
	number = {1-2},
	journal = {Robotics and Autonomous Systems},
	author = {Rodney A. Brooks},
	month = jun,
	year = {1990},
	keywords = {Artificial Intelligence, influential, Mobile robots, old, Planning, Situated activity, Subsumption architecture},
	pages = {3--15}
},

@article{borenstein_vector_1991,
	title = {The vector field histogram-fast obstacle avoidance for mobile robots},
	volume = {7},
	issn = {{1042-296X}},
	lccn = {1078},
	doi = {10.1109/70.88137},
	abstract = {A real-time obstacle avoidance method for mobile robots which has
been developed and implemented is described. This method, named the
vector field histogram {(VFH),} permits the detection of unknown obstacles
and avoids collisions while simultaneously steering the mobile robot
toward the target. The {VFH} method uses a two-dimensional Cartesian
histogram grid as a world model. This world model is updated
continuously with range data sampled by onboard range sensors. The {VFH}
method subsequently uses a two-stage data-reduction process to compute
the desired control commands for the vehicle. Experimental results from
a mobile robot traversing densely cluttered obstacle courses in smooth
and continuous motion and at an average speed of 0.6-0.7 m/s are shown.
A comparison of the {VFN} method to earlier methods is given},
	number = {3},
	journal = {Robotics and Automation, {IEEE} Transactions on},
	author = {J. Borenstein and Y. Koren},
	year = {1991},
	keywords = {{2D} Cartesian histogram, collision avoidance, data-reduction, Mobile robots, obstacle avoidance, occupancy grid, old, planning (artificial intelligence), position control, star, vector field histogram, world model},
	pages = {278--288}
},

@misc{globus_octree_1991,
	title = {Octree optimization},
	lccn = {0016},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.22.6342},
	abstract = {A number of algorithms search large {3D} arrays (computation space) for features
of interest. Marching cubes isosurface generation described by Lorenson
and Cline
1
is an example. The speed of these algorithms is dependent
on the time necessary to find the features of interest in the data and to compute
their graphic representation. Efficiently searching for these features is
the topic of this paper.
I describe an optimizing search using octrees to divide computation space.
When the tree is...},
	author = {A Globus},
	year = {1991},
	keywords = {octree, old}
},

@article{kuipers_robot_1991,
	title = {A robot exploration and mapping strategy based on a semantic hierarchy of spatial representations},
	volume = {8},
	lccn = {0655},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.24.3238},
	abstract = {semantic hierarchy of spatial representations. Journal of Robotics and Autonomous Systems 8:},
	journal = {Journal of Robotics and Autonomous Systems},
	author = {Benjamin Kuipers and {Yung-Tai} Byun},
	year = {1991},
	keywords = {cognitive map, localization, old, slam},
	pages = {47--63},
	annote = {{\textless}p{\textgreater}357 citations!{\textless}/p{\textgreater}}
},

@inproceedings{leonard_simultaneous_1991,
	address = {Osaka, Japan},
	title = {Simultaneous map building and localization for an autonomous mobile robot},
	lccn = {0373},
	url = {http://dx.doi.org/10.1109/IROS.1991.174711},
	abstract = {Discusses a significant open problem in mobile robotics:
simultaneous map building and localization, which the authors define as
long-term globally referenced position estimation without a priori
information. This problem is difficult because of the following paradox:
to move precisely, a mobile robot must have an accurate environment map;
however, to build an accurate map, the mobile robot's sensing locations
must be known precisely. In this way, simultaneous map building and
localization can be seen to present a question of `which came first, the
chicken or the egg?' {(The} map or the motion?) When using ultrasonic
sensing, to overcome this issue the authors equip the vehicle with
multiple servo-mounted sonar sensors, to provide a means in which a
subset of environment features can be precisely learned from the robot's
initial location and subsequently tracked to provide precise positioning},
	booktitle = {Intelligent Robots and Systems '91. {'Intelligence} for Mechanical Systems, Proceedings {IROS} '91. {IEEE/RSJ} International Workshop on},
	author = {{JJ} Leonard and {HF} {Durrant-Whyte}},
	year = {1991},
	keywords = {localization, old, slam},
	pages = {1442--1447}
},

@inproceedings{linn_survey_1991,
	address = {Orlando, {FL,} {USA}},
	title = {Survey of multisensor data fusion systems},
	volume = {1470},
	lccn = {0021},
	url = {http://scitation.aip.org/getabs/servlet/GetabsServlet?prog=normal&id=PSISDG001470000001000013000001&idtype=cvips&gifs=yes},
	abstract = {Multisensor data fusion integrates data from multiple sensors (and types of sensors) to perform inferences which are more accurate and specific than those from processing single-sensor data. Levels of inference range from target detection and identification to higher level situation assessment and threat assessment. This paper provides a survey of more than 50 data fusion systems and summarizes their application, development environment, system status and key techniques. The techniques are mapped to a taxonomy previously developed by Hall and Linn (1990); these include positional fusion techniques, such as association and estimation, and identity fusion methods, including statistical methods, nonparametric methods, and cognitive techniques (e.g. templating, knowledge-based systems, and fuzzy reasoning). An assessment of the state of fusion system development is provided.},
	booktitle = {Data Structures and Target Classification},
	publisher = {{SPIE}},
	author = {Robert Linn and David Hall and James Llinas and Vibeke Libby},
	year = {1991},
	keywords = {data, data fusion, fusion, nc2if, old, survey},
	pages = {13--29}
},

@misc{moravec_hans_learning_1991,
	title = {Learning Sensor Models for Evidence Grids},
	url = {http://www.frc.ri.cmu.edu/~hpm/project.archive/robot.papers/1987.learning/1991.sensor.model.html},
	abstract = {Evidence grids (which we have previously called occupancy grids, probability grids and certainty grids: the newer term evidence grids better captures the intent and the implementation of the method) are a probabilistic, finite-element representation of robot spatial knowledge. The grids allow the efficient accumulation of small amounts of information from individual sensor readings into increasingly accurate and confident maps of a robot's surroundings. Our first experiments using the method to interpret measurements from a ring of 24 Polaroid sonar transducers carried on board an autonomously navigating mobile robot were surprisingly successful, compared with our previous experiences with stereo-vision based programs that mapped points on objects as error distributions in space. These older programs enabled a robot to map and traverse cluttered 30 meter obstacle courses, succeeding about three times in four attempts {[Moravec80].} By contrast the grid method accomplished a similar task with a vanishingly small failure rate {[Moravec85,Elfes89].} We then applied the grid approach to stereo-vision-derived range data from a {TV} equipped robot, also with good success {[Serey86].} A subsequent experiment integrated sonar and vision data, generating maps with correct features not found in those from either sensor alone {[Matthies87].}

    These encouraging early results were obtained using ad-hoc statistical models and methods. We then developed a Bayesian statistical foundation for grid updates. A key result of this derivation was a combining formula (replacing several formulas in the old formulation) for integrating two independently derived maps of the same area, or for adding a new reading to a developing map. When used to add a new reading to an evidence grid, the combining formula requires that the reading itself be represented as such a grid, containing only the independent information provided by that particular reading. A sensor (for instance a sonar sensor) may return one of a set of possible values (one for each range) when a reading is taken. Each different value requires its own grid. The set of grids for all possible values returned during a reading we call a sensor model. Each In the early formulation we constructed a sensor model from an ad-hoc interpretation of the technical specifications of our sonar sensors. This worked well in our first experiments, where the data, mostly sonar in a cluttered lab, was very benign, meaning that the ranges reported by the sensors usually corresponded to the location of objects in the field of view. The only uncertainties were in lateral position of the object, and range uncertainty, both of which we were able to model well enough by an ad-hoc function. In fact, the maps built during robot runs were very insensitive to small adjustments in out sensor model.

    The situation is very different if the sources of uncertainty are more complicated. In data from a smooth-walled narrow corridor, the majority of the sonar rangings suffer specular reflection, returning ranges that are much farther than the nearest objects because they come via glancing bounces from walls that the sonar sees as perfect mirrors. In principle the evidence grid method should be able to slowly accumulate partial information (evidence) from such data as long as there exists any correlation between the readings we get and what's out there--but only if the sensor model accurately represents the information contained in a reading. Our ad-hoc models of sonar sensors turned out to be totally ineffective in highly specular environments. Our initial cluttered laboratory environment, with its many reflective surface patches in different orientations, had been unusually benign, from the sonar sensing point of view.

    We were not up to the task of constructing a precision sensor model by hand, so we looked for a way to determine (learn) it automatically from accumulated robot sense data. We experimented with two learning approaches. In an earlier approach the evidence maps for individual ranges are estimated directly by observing the frequencies of occupancy from a large sample of readings made in known positions in known surroundings. This has problems--it needs a huge amount of data, is sensitive to quirks in the training sample, gives a statistically noisy and unnecessarily blurry result, and does not in any way compensate for the fact that individual readings don't give entirely independent information, (as we dangerously assume in the basic formulation). The new, more successful, approach shapes the individual evidence maps with a parameterized closed-form formula. The parameters of this formula are adjusted, in a hill-climbing process, so that the map built by the functions with data from a robot test run is as good as possible. Using this approach with a 9-parameter function a program using several weeks of Sparc1+ workstation search time (and several days more on a {MASPAR} parallel computer) was able to produce a crisp, correct map of the difficult 4ft specular hallway outside my office, from data that produces an unrecognizable splatter when used with a naive sensor model that works fine in benign circumstances.},
	author = {Moravec, Hans and Blackwell, Mike},
	month = sep,
	year = {1991},
	keywords = {occupancy grid, old, sensor model},
	howpublished = {http://www.frc.ri.cmu.edu/{\textasciitilde}hpm/project.archive/robot.papers/1987.learning/1991.sensor.model.html}
},

@article{besl_method_1992,
	title = {A method for registration of {3-D} shapes},
	volume = {14},
	issn = {0162-8828},
	lccn = {5285},
	doi = {10.1109/34.121791},
	abstract = {The authors describe a general-purpose, representation-independent
method for the accurate and computationally efficient registration of
{3-D} shapes including free-form curves and surfaces. The method handles
the full six degrees of freedom and is based on the iterative closest
point {(ICP)} algorithm, which requires only a procedure to find the
closest point on a geometric entity to a given point. The {ICP} algorithm
always converges monotonically to the nearest local minimum of a
mean-square distance metric, and the rate of convergence is rapid during
the first few iterations. Therefore, given an adequate set of initial
rotations and translations for a particular class of objects with a
certain level of `shape complexity', one can globally minimize the
mean-square distance metric over all six degrees of freedom by testing
each initial registration. One important application of this method is
to register sensed data from unfixtured rigid objects with an ideal
geometric model, prior to shape inspection. Experimental results show
the capabilities of the registration algorithm on point sets, curves,
and surfaces},
	number = {2},
	journal = {Pattern Analysis and Machine Intelligence, {IEEE} Transactions on},
	author = {{P.J.} Besl and {H.D.} {McKay}},
	year = {1992},
	keywords = {{3D} shape registration, computational geometry, convergence, convergence of numerical methods, geometric entity, geometric model, iterative closest point, iterative methods, mean-square distance metric, optimisation, {PATTERN} {RECOGNITION,} picture processing, point set registration, registration},
	pages = {239--256},
	annote = {{\textless}p{\textgreater}first {ICP??{\textless}/p{\textgreater}}}
},

@inproceedings{kamel_parallel_1992,
	title = {Parallel R-trees},
	lccn = {0153},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.9813},
	abstract = {We consider the problem of exploiting parallelism to accelerate
the performance of spatial access methods and specifically,
R-trees [11]. Our goal is to design a server for spatial
data, so that to maximize the throughput of range queries.
This can be achieved by (a) maximizing parallelism for large
range queries, and (b) by engaging as few disks as possible
on point queries [22].
We propose a simple hardware architecture consisting of
one processor with several disks attached to it. On this...},
	author = {Ibrahim Kamel and Christos Faloutsos},
	year = {1992},
	keywords = {old, r-tree},
	pages = {195--204}
},

@article{leonard_dynamic_1992,
	title = {Dynamic Map Building for an Autonomous Mobile Robot},
	volume = {11},
	issn = {0278-3649},
	lccn = {0376},
	url = {http://ijr.sagepub.com/cgi/doi/10.1177/027836499201100402},
	doi = {10.1177/027836499201100402},
	abstract = {This article presents an algorithm for autonomous map building and maintenance for a mobile robot. We believe that mobile robot navigation can be treated as a problem of tracking ge ometric features that occur naturally in the environment. We represent each feature in the map by a location estimate (the feature state vector) and two distinct measures of uncertainty: a covariance matrix to represent uncertainty in feature loca tion, and a credibility measure to represent our belief in the validity of the feature. During each position update cycle, pre dicted measurements are generated for each geometric feature in the map and compared with actual sensor observations. Suc cessful matches cause a feature's credibility to be increased. Unpredicted observations are used to initialize new geometric features, while unobserved predictions result in a geometric feature's credibility being decreased. We describe experimental results obtained with the algorithm that demonstrate successful map building using real sonar data.},
	number = {4},
	journal = {The International Journal of Robotics Research},
	author = {J. J. Leonard and H. F. {Durrant-Whyte} and I. J. Cox},
	year = {1992},
	keywords = {old, slam},
	pages = {286--298}
},

@incollection{abel_hierarchical_1993,
	series = {Lecture Notes in Computer Science},
	title = {A hierarchical spatial index for cell complexes},
	volume = {692},
	lccn = {0009},
	url = {http://dx.doi.org/10.1007/3-540-56869-7_7},
	abstract = {A new hierachical spatial index for object representation schemes based on three-dimensional cell complexes is introduced. We consider a domain consisting of general n-dimensional spatial objects described by n-dimensional cell complexes. The new hierarchical spatial index, called a cellular n-tree, generalizes similar structures developed for planar maps, and is defined as a recursive subdivision of a universe containing the cell complex into regular blocks. Terminal blocks may be completely inside a cell or outside the complex, or may contain indices to sets of cells within the complex. We briefly review the properties of n-dimensional cell complexes, that we call cellular decompositions, and introduce a few basic atomic operators for building them in the three-dimensional case. We shortly describe algorithms for building a cellular octree from a {3D} cellular decomposition and for updating the cellular octree, when the cellular decomposition is modified by applying the atomic constructive operators introduced. Algorithms for solving point location and proximity queries on a cellular decomposition with a cellular octree superimposed are presented.},
	booktitle = {Advances in Spatial Databases},
	publisher = {Springer Berlin / Heidelberg},
	author = {David Abel and Beng Chin Ooi and Elisabetta Bruzzone and Leila De Floriani and Monica Pellegrinelli},
	year = {1993},
	keywords = {octree, old},
	pages = {105--122}
},

@inproceedings{kamel_packing_1993,
	title = {On packing R-trees},
	isbn = {0897916263},
	lccn = {0449},
	url = {http://dx.doi.org/10.1145/170088.170403},
	abstract = {We propose new R-tree packing techniques for static databases. Given a collection of rectangles, we sort them and we build the R-tree bottom-up. There are several ways to sort the rectangles; the innovation of this work is the use of fractals, and specifically the hilbert curve, to achieve better ordering of the rectangles and eventually better packing. We proposed and implemented several variations and performed experiments on synthetic, as well as real data {(TIGER} files from the {U.S.} Bureau of Census). The winning variation {(`2D-c')} was the one that sorts the rectangles according to the hilbert value of the center. This variation consistently outperforms the packing method of Roussopoulos and Leifker [24], as well as other R-tree variants. The performance gain of the our method seems to increase with the skeweness of the data distribution; specifically, on the (highly skewed) {TIGER} dataset, it achieves up to 58\% improvement in response time over the older packing algorithm and 36\% ov...},
	booktitle = {{CIKM} '93: Proceedings of the second international conference on Information and knowledge management},
	publisher = {{ACM}},
	author = {Ibrahim Kamel and Christos Faloutsos},
	year = {1993},
	keywords = {database, indexes, old, r-tree, theory},
	pages = {490--499}
},

@misc{pagel_toward_1993,
	title = {Toward an Analysis of Range Query Performance in Spatial Data Structures},
	lccn = {0013},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.5.2429},
	abstract = {In this paper, we motivate four different user defined window
query classes and derive a probabilistic model for eachof
them. For each model, wecharacterize the efficiency of
spatial data structures in terms of the expected number of
data bucket accesses needed to perform a {windowquery.Our}
analytical approach exhibits the performance phenomena
independent of data structure and implementation details
and whether the objects are points or non-point objects.
1},
	author = {B Pagel and H Six and H Toben and P Widmayer},
	year = {1993},
	keywords = {old, range search}
},

@inproceedings{warren_parallel_1993,
	title = {A parallel hashed {Oct-Tree} N-body algorithm},
	lccn = {0337},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.50.100},
	abstract = {We report on an efficient adaptive N-body method which we have recently designed and implemented. The algorithm computes the forces on an arbitrary distribution of bodies in a time which scales as N log N with the particle number. The accuracy of the force calculations is analytically bounded, and can be adjusted via a user defined parameter between a few percent relative accuracy, down to machine arithmetic accuracy. Instead of using pointers to indicate the topology of the tree, we identify...},
	booktitle = {Supercomputing},
	author = {Michael Warren and John Salmon},
	year = {1993},
	keywords = {octree, unrelated},
	pages = {12--21}
},

@misc{yianilos_data_1993,
	title = {Data structures and algorithms for nearest neighbor search in general metric spaces},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.4193},
	abstract = {We consider the computational problem of finding nearest neighbors in general metric spaces. Of particular interest are spaces that may not be conveniently embedded or approximated in Euclidian space, or where the dimensionality of a Euclidian representation is very high. Also relevant are high-dimensional Euclidian settings in which the distribution of data is in some sense of lower dimension and embedded in the space. The vp-tree (vantage point tree) is introduced in several forms, together with associated algorithms, as an improved method for these difficult search problems. Tree construction executes in O(n log(n)) time, and search is under certain circumstances and in the limit, O(log(n)) expected time. The theoretical basis for this approach is developed and the results of several experiments are reported. In Euclidian cases, kd-tree performance is compared.},
	author = {Peter Yianilos},
	year = {1993},
	keywords = {k-d-tree, metric, metric\_space, nearest\_neighbor, old, theory},
	howpublished = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.4193}
},

@article{szeliski_rapid_1993,
	title = {Rapid Octree Construction from Image Sequences},
	volume = {58},
	issn = {10499660},
	lccn = {0436},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1049966083710296},
	doi = {10.1006/ciun.1993.1029},
	abstract = {The construction of a three-dimensional object model from a set of images taken from different viewpoints is an important problem in computer vision. One of the simplest ways to do this is to use the silhouettes of the object (the binary classification of images into object and background) to construct a bounding volume for the object. To efficiently represent this volume, we use an octree, which represents the object as a tree of recursively subdivided cubes. We develop a new algorithm for computing the octree bounding volume from multiple silhouettes and apply it to an object rotating on a turntable in front of a stationary camera. The algorithm performs a limited amount of processing for each viewpoint and incrementally builds the volumetric model. The resulting algorithm requires less total computation than previous algorithms, runs in close to real-time, and builds a model whose resolution improves over time.},
	number = {1},
	journal = {{CVGIP:} Image Understanding},
	author = {Szeliski},
	year = {1993},
	keywords = {octree, old},
	pages = {23--32}
},

@inproceedings{arya_optimal_1994,
	title = {An Optimal Algorithm for Approximate Nearest Neighbor Searching in Fixed Dimensions},
	lccn = {1304},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.15.3125},
	abstract = {Consider a set S of n data points in real d-dimensional space, R d , where distances are measured using any Minkowski metric. In nearest neighbor searching we preprocess S into a data structure, so that given any query point q 2 R d , the closest point of S to q can be reported quickly. Given any positive real ffl, a data point p is a (1 + ffl)-approximate nearest neighbor of q if its distance from q is within a factor of (1 + ffl) of the distance to the true nearest neighbor. We show that it is possible to preprocess a set of n points in R d in O(dn log n) time and O(dn) space, so that given a query point q 2 R d , and ffl ? 0, a (1 + ffl)-approximate nearest neighbor of q can be computed in O(c d;ffl log n) time, where c d;ffl d d1 + 6d=ffle d is a factor depending only on dimension and ffl. In general, we show that given an integer k 1, (1 + ffl)-approximations to the k nearest neighbors of q can be computed in additional O(kd log n) time.},
	booktitle = {{ACM-SIAM} {SYMPOSIUM} {ON} {DISCRETE} {ALGORITHMS}},
	author = {Sunil Arya and David Mount and Nathan Netanyahu and Ruth Silverman and Angela Wu},
	year = {1994},
	keywords = {nearest\_neighbor, old},
	pages = {573--582}
},

@article{bachelder_mobile_1994,
	title = {Mobile robot visual mapping and localization: A view-based neurocomputational architecture that emulates hippocampal place learning},
	volume = {7},
	issn = {0893-6080},
	lccn = {0069},
	shorttitle = {Mobile robot visual mapping and localization},
	url = {http://www.sciencedirect.com/science/article/B6T08-4HHXWYS-F/2/b7ff3cbcfff064e68165969ce2cbe3d1},
	doi = {10.1016/S0893-6080(05)80160-1},
	abstract = {We propose a real-time, view-based neurocomputational architecture for unsupervised {2-D} mapping and localization within a {3-D} environment defined by a spatially distributed set of visual landmarks. This architecture emulates place learning by hippocampal place cells in rats, and draws from anatomy of the primate object {("What")} and spatial {("Where")} processing streams. It extends by analogy, principles for learning characteristic views of {3-D} objects (i.e., "aspects"), to learning characteristic views of environments (i.e., "places"). Places are defined by the identities and approximate poses (the What) of landmarks, as provided by visible landmark aspects. They are also defined by prototypical locations (the Where) within the landmark constellation, as indicated by the panoramic spatial distribution of landmark gaze directions. Combining these object and spatial definitions results in place nodes whose activity profiles define decision boundaries that parcel a {2-D} area of the environment into place regions. These profiles resemble the spatial firing patterns over hippocampal place fields observed in rat experiments. A realtime demonstration of these capabilities on the binocular mobile robot {MAVIN} (the mobile adaptive visual navigator) illustrates the potential of this approach for qualitative mapping and fine localization.},
	number = {6-7},
	journal = {Neural Networks},
	author = {Ivan A. Bachelder and Allen M. Waxman},
	year = {1994},
	keywords = {Adaptive resonance theory, Cognitive map, Hippocampus, Map-making, Mobile robots, neuro-computation, old, Place cells, Place recognition, Unsupervised learning},
	pages = {1083--1099}
},

@article{frey_fully_1994,
	title = {Fully automatic mesh generation for {3-D} domains based upon voxel sets},
	volume = {37},
	lccn = {0036},
	url = {http://dx.doi.org/10.1002/nme.1620371604},
	abstract = {Fully automatic three-dimensional mesh generation is an essential and increasingly crucial requirement for finite element solution of partial derivative equations. The results of numerical simulation, more precisely the convergence and accuracy of numerical solutions, closely depends on the quality of the underlying mesh. This work introduces a fully automatic finite element mesh algorithm with simplexes (tetrahedra), adapted to complex geometries described by disctete {data.This} paper is divided in four sections: (a) brief introduction to discrete geometry is given, as well as the basic definition of the domain of interest; (b) description of the voxel approach to tetrahedronization. The tetrahedronization process uses a divide-and-conquer method, which provides small elements on the boundary of the domain of interest. Voxels of the domain are subdivided according to an automatic procedure, which preserves the topology. Specific rules were introduced which allow reducing the number of voxel configurations to be treated, and consequently the computation time; (c) presentation of results and performances of the mesh algorithms. The resulting algorithm demonstrates an n log n growth rate with respect to the number of elements; (d) optimization of the mesh generation process at hand of a ?finite-octree? type of explicit controlling space.},
	number = {16},
	journal = {International Journal for Numerical Methods in Engineering},
	author = {Pascal Frey and Beno�t Sarter and Michel Gautherie},
	year = {1994},
	keywords = {geometric model, octree, tetrahedron},
	pages = {2735--2753}
},

@misc{kaufman_voxels_1994,
	title = {Voxels as a computational representation of geometry},
	lccn = {0013},
	url = {http://citeseer.ist.psu.edu/kaufman94voxels.html},
	abstract = {This paper is a survey of volume visualization, volume graphics, and volume rendering techniques. It
focuses specifically on the use of the voxel representation and volumetric techniques for geometric
applications.

1. Introduction

Volume data are {3D} entities that may have information inside them, might not consist of surfaces and
edges, or might be too voluminous to be represented geometrically . Volume visualization is a method
of extracting meaningful information from volumetric data using...},
	author = {A Kaufman},
	year = {1994},
	keywords = {geometry, graphics, old, representation, volume-graphics, voxel-representation, voxels}
},

@inproceedings{weiss_keeping_1994,
	address = {Munich, Germany},
	title = {Keeping track of position and orientation of moving indoor systems by correlation of range-finder scans},
	lccn = {0112},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=407420},
	doi = {10.1109/IROS.1994.407420},
	abstract = {One of the problems of autonomous mobile systems is the continuous tracking of position and orientation. In most cases, this problem is solved by dead reckoning, based on measurement of wheel rotations or step counts and step width. Unfortunately dead reckoning leads to accumulation of drift errors and is very sensitive to slipping. In this paper an algorithm for tracking position and orientation is presented, it is nearly independent from odometry and its problems with slipping. To achieve these results, a rotating range-finder is used, delivering scans of the environmental structure. The properties of this structure are used to match the scans from different locations in order to find their translational and rotational displacement. For this purpose derivatives of range-finder scans are calculated which can be used to find position and orientation by crosscorrelation},
	booktitle = {Proceedings of {IEEE/RSJ} International Conference on Intelligent Robots and Systems {(IROS'94)}},
	author = {G. Weiss and C. Wetzler and E. von Puttkamer},
	year = {1994},
	keywords = {old, registration},
	pages = {595--601}
},

@article{schiele_comparison_1994,
	title = {A comparison of position estimation techniques using occupancy grids},
	volume = {12},
	issn = {09218890},
	lccn = {0204},
	url = {http://linkinghub.elsevier.com/retrieve/pii/092188909490023X},
	doi = {10.1016/0921-8890(94)90023-X},
	abstract = {A mobile robot requires a perception of its local environment for both sensor-based locomotion and for position estimation. Occupancy grids, based on ultrasonic range data, provide a robust description of the local environment for locomotion. Unfortunately, current techniques for position estimation based on occupancy grids are both unreliable and computationally expensive. This paper reports on experiments with four techniques for position estimation using occupancy grids. A world modelling technique based on combining global and local occupancy grids is described. Techniques are described for extracting line segments from an occupancy grid based on a Hough transform. The use of an extended Kalman filter for position estimation is then adapted to this framework. Four matching techniques are presented for obtaining the innovation vector required by the Kalman filter equations. Experimental results show that matching of segments extracted from both the local and global occupancy grids gives results which are superior to a direct matching of grids, or to a mixed matching of segments to grids.},
	number = {3-4},
	journal = {Robotics and Autonomous Systems},
	author = {Bernt Schiele and James L. Crowley},
	year = {1994},
	keywords = {occupancy grid, old, registration},
	pages = {163--171}
},

@phdthesis{alonzo_kelly_intelligent_1995,
	title = {An intelligent predictive control approach to the high speed cross country autonomous navigation problem},
	lccn = {0085},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.71.3292},
	abstract = {Autonomous robot vehicles promise many ultimate civilian,
military, and space applications. Off-road autonomous
vehicles must engage the world exactly as they find it
without relying on having it engineered to suit them. For
this reason, offroad autonomous navigation is one of the
most difficult automation challenges. Previous work in the
area has been disappointing from the perspective of the
speeds attained, and the inability of systems to travel long
distances autonomously. Indeed, no system has travelled an
autonomous mile or exceeded 3 m/s speeds. To date, no
off-road system has approached the capabilities needed to
address real applications. This thesis examines and proposes
a solution to the problem of high speed autonomous
navigation of outdoor vehicles. As a systems-level effort,
aspects of perception, path planning, position estimation,
and to a lesser extent, strategic planning and motion
control are considered. The emphasis of the work has been to
assess the fundamental requirements of the problem, and to
validate the conclusions},
	school = {Carnegie Mellon University},
	author = {Alonzo Kelly},
	year = {1995},
	annote = {{CiteSeerX} - Scientific Literature Digital Library and Search
Engine [http://citeseerx.ist.psu.edu/oai2] {(United} States)
{ER}}
},

@misc{kak_experimental_1995,
	title = {Experimental State of the Art in {3D} Object Recognition and Localization Using Range Data},
	lccn = {0011},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.51.4632},
	abstract = {This paper discusses current state of the art research
at the Purdue Robot Vision Lab in the area
of {3D} object recognition and localization using range
data. We review three approaches to model representation:
feature spheres, Local Feature Sets, and multipleattribute
hash tables. The incorporation of these three
representational schemes into the {MULTI-HASH} binpicking
system has resulted in significant reductions in
time complexity for scene-to-model hypothesis generation
and verification. We...},
	publisher = {Proceedings of Workshop on Vision for Robots in {IROS'95} Conference, Pittsburgh, {PA}},
	author = {Avinash Kak},
	year = {1995},
	keywords = {multi-hash, object\_recognition, old}
},

@inproceedings{kitamura_3d_1995,
	address = {Pittsburgh, {PA,} {USA}},
	title = {{3-D} path planning in a dynamic environment using an octree and an artificial potential field},
	lccn = {0036},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=526259},
	doi = {10.1109/IROS.1995.526259},
	abstract = {Proposes an efficient and simple method for finding a collision-free path and orientation for a rigid robot in a dynamic observable {3-D} environment for unmanned aerial vehicles {(UAVs).} The method uses an octree for representing every object (robot and static/dynamic obstacles) in the environment without any distinction of the movability of objects; therefore, all objects are dealt with in the same way. The path of a robot from its starting position to the given goal with arbitrary motion (i.e., translation and rotation) in a {3-D} environment is efficiently searched for in successive adjoining regions (octree white cells) by using the potential field generated from each black cell of the octree. The algorithm is simple, so it can easily be accelerated by using parallelization techniques. Experimental results obtained under several conditions, such as a point shaped robot and arbitrarily shaped robots in static/dynamic environments, are reported},
	booktitle = {Proceedings 1995 {IEEE/RSJ} International Conference on Intelligent Robots and Systems. Human Robot Interaction and Cooperative Robots},
	author = {Y. Kitamura and T. Tanaka and F. Kishino and M. Yachida},
	year = {1995},
	keywords = {octree, old, planning, uav},
	pages = {474--481}
},

@article{lavallee_recovering_1995,
	title = {Recovering the position and orientation of free-form objects from image contours using {3D} distance maps},
	volume = {17},
	lccn = {0203},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=385980},
	abstract = {The accurate matching of {3D} anatomical surfaces with sensory data such as {2D} X-ray projections is a basic problem in computer and robot assisted surgery, In model-based vision, this problem can be formulated as the estimation of the spatial pose (position and orientation) of a {3D} smooth object from {2D} video images. The authors present a new method for determining the rigid body transformation that describes this match. The authors' method performs a least squares minimization of the energy necessary to bring the set of the camera-contour projection lines tangent to the surface. To correctly deal with projection lines that penetrate the surface, the authors consider the minimum signed distance to the surface along each line (i.e., distances inside the object are negative). To quickly and accurately compute distances to the surface, the authors introduce a precomputed distance map represented using an octree spline whose resolution increases near the surface. This octree structure allows the authors to quickly find the minimum distance along each line using best-first search. Experimental results for {3D} surface to {2D} projection matching are presented for both simulated and real data. The combination of the authors' problem formulation in {3D,} their computation of line to surface distances with the octree-spline distance map, and their simple minimization technique based on the {Levenberg-Marquardt} algorithm results in a method that solves the {3D/2D} matching problem for arbitrary smooth shapes accurately and quickly},
	number = {4},
	journal = {Pattern Analysis and Machine Intelligence, {IEEE} Transactions on},
	author = {S Lavallee and R Szeliski},
	year = {1995},
	keywords = {octree, old, registration},
	pages = {378--390}
},

@inproceedings{matthies_obstacle_1995,
	title = {Obstacle detection for unmanned ground vehicles: a progress report},
	lccn = {0116},
	shorttitle = {Obstacle detection for unmanned ground vehicles},
	doi = {10.1109/IVS.1995.528259},
	abstract = {To detect obstacles during off-road autonomous navigation,
unmanned ground vehicles {(UGV's)} must sense terrain geometry and
composition (terrain type) under day, night, and low-visibility
conditions. To sense terrain geometry, we have developed a real-time
stereo vision system that uses a Datacube {MV-200} and a 68040 {CPU} board
to produce 256�240-pixel range images in about 0.6 seconds/frame.
To sense terrain type, we used the same computing hardware with red and
near infrared imagery to classify 256�240-pixel frames into
vegetation and non-vegetation regions at a rate of five to ten
frames/second. This paper reviews the rationale behind the choice of
these sensors, describes their recent evolution and on-going
development, and summarizes their use in demonstrations of autonomous
{UGV} navigation over the past five years},
	booktitle = {Intelligent Vehicles '95 Symposium., Proceedings of the},
	author = {L. Matthies and A. Kelly and T. Litwin and G. Tharp},
	year = {1995},
	keywords = {68040 {CPU} board, classification, Computer vision, Datacube {MV-200,} intelligent control, microcomputer applications, navigation, near infrared imagery, Object detection, obstacle detection, off-road autonomous navigation, old, real-time system, real-time systems, red imagery, stereo, terrain composition, terrain geometry, unmanned ground vehicles, vegetation, {VEHICLES}},
	pages = {66--71}
},

@incollection{samet_spatial_1995,
	title = {Spatial Data Structures},
	lccn = {2745},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.46.9624},
	abstract = {An overview is presented of the use of spatial data structures in spatial databases. The focus
is on hierarchical data structures, including a number of variants of quadtrees, which sort
the data with respect to the space occupied by it. Such techniques are known as spatial
indexing methods. Hierarchical data structures are based on the principle of recursive
decomposition. They are attractive because they are compact and depending on the nature
of the data they save space as well as time and...},
	booktitle = {Modern Database Systems: The Object Model, Interoperability, and Beyond.},
	author = {Hanan Samet},
	year = {1995},
	keywords = {data, octree, spatial, structures, survey},
	pages = {361--385}
},

@article{arakawa_fractal_1996,
	title = {Fractal Modeling of Natural Terrain: Analysis and Surface Reconstruction with Range Data},
	volume = {58},
	lccn = {0024},
	url = {http://citeseer.ist.psu.edu/arakawa96fractal.html},
	abstract = {this paper we address two issues in modeling natural
terrain using fractal geometry: estimation of fractal dimension,
and fractal surface reconstruction. For estimation of fractal
dimension, we extend the fractal Brownian function approach

to accommodate irregularly sampled data, and we develop
methods for segmentingsets of points exhibitingself-similarity

over only certain scales. For fractal surface reconstruction, we
extend Szeliski's regularization with fractal priors to
use a temperature ...},
	number = {5},
	journal = {Graphical models and image processing: {GMIP}},
	author = {Kenichi Arakawa and Eric Krotkov},
	year = {1996},
	keywords = {brownianmotion, fractal, old},
	pages = {413--436}
},

@inproceedings{burgard_position_1996,
	address = {Kaiserslautern, Germany},
	title = {Position tracking with position probability grids},
	lccn = {0028},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=551874},
	doi = {10.1109/EURBOT.1996.551874},
	abstract = {One of the main problems in the field of mobile robotics is the estimation of the robot's position in the environment. Position probability grids have been proven to be a robust technique for the estimation of the absolute position of a mobile robot. In this paper we describe an application of position probability grids to the tracking of the position of the robot. The main difference of our method to previous approaches lies in the fact that the position probability grid technique is a Bayesian approach which is able to deal with noisy sensors as well as ambiguities and is able to integrate sensor readings of different types of sensors over time. Given a starting position this method estimates the robot's current position by matching sensor readings against a metric model of the environment. Results described in this paper illustrate the robustness of this method against noisy sensors and errors in the environmental model},
	booktitle = {Proceedings of the First Euromicro Workshop on Advanced Mobile Robots {(EUROBOT} '96)},
	author = {W. Burgard and D. Fox and D. Hennig and T. Schmidt},
	year = {1996},
	keywords = {occupancy grid, old},
	pages = {2--9}
},

@inproceedings{burgard_estimating_1996,
	title = {Estimating the Absolute Position of a Mobile Robot Using Position Probability Grids},
	lccn = {0365},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.44.2554},
	abstract = {In order to re-use existing models of the environment mobile
robots must be able to estimate their position and orientation
in such models. Most of the existing methods for position
estimation are based on special purpose sensors or aim at
tracking the robot's position relative to the known starting
point. This paper describes the position probability grid approach
to estimating the robot's absolute position and orientation
in a metric model of the environment. Our method is
designed to work...},
	booktitle = {{AAAI/{IAAI},} Vol. 2},
	author = {Wolfram Burgard and Dieter Fox and Daniel Hennig and Timo Schmidt},
	year = {1996},
	keywords = {estimation, indoor, old, position, probabilistic, robotics, slam},
	pages = {896--901}
},

@inproceedings{curless_volumetric_1996,
	address = {New York, {NY,} {USA}},
	series = {{SIGGRAPH} '96},
	title = {A volumetric method for building complex models from range images},
	isbn = {0-89791-746-4},
	lccn = {1257},
	doi = {10.1145/237170.237269},
	abstract = {A number of techniques have been developed for reconstructing sur-
faces by integrating groups of aligned range images. A desirable
set of properties for such algorithms includes: incremental updating,
representation of directional uncertainty, the ability to fill gaps in the
reconstruction, and robustness in the presence of outliers. Prior algo-
rithms possess subsets of these properties. In this paper, we present a
volumetric method for integrating range images that possesses all of
these properties.
Our volumetric representation consists of a cumulative weighted
signed distance function. Working with one range image at a time,
we first scan-convert it to a distance function, then combine this with
the data already acquired using a simple additive scheme. To achieve
space efficiency, we employ a run-length encoding of the volume. To
achieve time efficiency, we resample the range image to align with the
voxel grid and traverse the range and voxel scanlines synchronously.
We generate the final manifold by extracting an isosurface from the
volumetric grid. We show that under certain assumptions, this isosur-
face is optimal in the least squares sense. To fill gaps in the model,
we tessellate over the boundaries between regions seen to be empty
and regions never observed.
Using this method, we are able to integrate a large number of range
images (as many as 70) yielding seamless, high-detail models of up
to 2.6 million triangles.},
	booktitle = {Proceedings of the 23rd annual conference on Computer graphics and interactive techniques},
	publisher = {{ACM}},
	author = {Brian Curless and Marc Levoy},
	year = {1996},
	note = {{ACM} {ID:} 237269},
	keywords = {algorithms, curve, surface, solid, and object representations, isosurface extraction, old, surface fitting},
	pages = {303�312}
},

@inproceedings{dam_neural_1996,
	address = {London, {UK}},
	title = {Neural Network Applications in Sensor Fusion for an Autonomous Mobile Robot},
	isbn = {3-540-61376-5},
	lccn = {0013},
	url = {http://portal.acm.org/citation.cfm?id=647202.718895},
	abstract = {In this article, we propose a generic architecture for sensor data fusion and argue that the central issue in such an approach is the choice of a suitable representation of the robot's environment. We argue that for the navigation task a robot-centered discrete probabilistic representation (an occupancy grid) is a suitable choice. If such a representation is used, the two key problems are how to transform such representations upon robot motion and how to represent the sensor's error characteristics (the sensor model) in such a representation. For both these problems, solutions are suggested by the application of neural network theory, and it is argued that these neural networks are the best available alternatives.},
	booktitle = {Proceedings of the International Workshop on Reasoning with Uncertainty in Robotics},
	publisher = {{Springer-Verlag}},
	author = {Joris W. M. van Dam and Ben J. A Kr�se and Frans C. A Groen},
	year = {1996},
	keywords = {neural net, occupancy grid, old},
	pages = {263�278}
},

@inproceedings{jung_octreebased_1996,
	address = {Minneapolis, {MN,} {USA}},
	title = {Octree-based hierarchical distance maps for collision detection},
	lccn = {0043},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=503818},
	doi = {10.1109/ROBOT.1996.503818},
	abstract = {In this paper, we propose a novel hierarchical representation for discretized distance maps commonly used in robotics for path planning and collision detection applications. We augment the well-known octree structure for representing distance maps in a hierarchical manner. Our augmented octree based representation drastically reduces the expensive memory requirement compared to voxel-based distance maps while providing substantially better collision-detection performance than by using unaugmented octrees. Although our main motivation has been collision detection in robotics, similar octree distance maps will have wide applications in many other areas including machine vision, computer graphics and so on},
	booktitle = {Proceedings of {IEEE} International Conference on Robotics and Automation},
	author = {D. Jung and {K.K.} Gupta},
	year = {1996},
	keywords = {octree, old, star},
	pages = {454--459}
},

@incollection{dorst_refined_1996,
	series = {Lecture Notes in Computer Science},
	title = {A refined method for occupancy grid interpretation},
	volume = {1093},
	lccn = {0006},
	url = {http://dx.doi.org/10.1007/BFb0013971},
	abstract = {Occupancy grids are a probabilistic method for fusing multiple sensor readings. Although the underlying theory has been understood for many years, the intricacies of applying it to realtime sensor interpretation have been somewhat neglected. In this paper I analyze how refined sensor models (including specularity models) and assumptions about independence are crucial issues for occupancy grid interpretation. Using this analysis, I develop the {MURIEL} method for occupancy grid calculations, and show how it can dramatically improve the fidelity of occupancy grid interpretations in specular and realtime environments.},
	booktitle = {Reasoning with Uncertainty in Robotics},
	publisher = {Springer Berlin / Heidelberg},
	author = {Leo Dorst and Michiel van Lambalgen and Frans Voorbraak and Kurt Konolige},
	year = {1996},
	keywords = {occupancy grid, old},
	pages = {338--352}
},

@article{kuipers_hierarchy_1996,
	title = {A Hierarchy of Qualitative Representations for Space},
	volume = {1404},
	lccn = {0081},
	abstract = {Research in Qualitative Reasoning builds and uses discrete symbolic models of the continuous world. Inference methods such as qualitative simulation are grounded in the theory of ordinary differential equations. We argue here that cognitive mapping --- building and using symbolic models of the large-scale spatial environment --- is a highly appropriate domain for qualitative reasoning research. We describe the Spatial Semantic Hierarchy {(SSH),} a set of distinct representations for space, each...},
	journal = {Lecture Notes in Computer Science},
	author = {Benjamin Kuipers},
	year = {1996},
	keywords = {cognitive map, old}
},

@techreport{martin_robot_1996,
	title = {Robot evidence grids},
	lccn = {0165},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.94.2489},
	abstract = {Introduction 1 The evidence grid representation was formulated at the {CMU} Mobile Robot Laboratory in 1983 to turn wide angle range measurements from cheap mobile robot-mounted sonar sensors into detailed spatial maps. It accumulates diffuse evidence about the occupancy of a grid of small volumes of nearby space from individual sensor readings into increasingly confident and detailed maps of a robot�s surroundings.},
	author = {Martin C. Martin and Hans P. Moravec},
	year = {1996},
	keywords = {occupancy grid, old}
},

@article{moravec_robot_1996,
	title = {Robot Spatial Perception by Stereoscopic Vision and {3D} Evidence Grids},
	lccn = {0126},
	abstract = {Very encouraging results have been obtained from a new program that derives a dense three-dimensional
evidence grid representation of a robot�s surroundings from wide-angle stereoscopic images. The pro-
gram adds several spatial rays of evidence to a grid for each of about 2,500 local image features chosen
per stereo pair. It was used to construct a 256x256x64 grid, representing 6 by 6 by 2 meters, from a hand-
collected test set of twenty stereo image pairs of an office scene. Fifty nine stereo pairs of an 8 by 8 meter
laboratory were also processed. The positive (probably occupied) cells of the grids, viewed in perspec-
tive, resemble dollhouse scenes. Details as small as the curvature of chair armrests are discernible. The
processing time, on a 100 {MIPS} Sparc 20, is less than five seconds per stereo pair, and total memory is
under 16 megabytes. The results seem abundantly adequate for very reliable navigation of freely roaming
mobile robots, and plausibly adequate for shape identification of objects bigger than 10 centimeters. The
program is a first proof of concept, and awaits optimizations, enhancements, variations, extensions and
applications.},
	author = {H. P Moravec},
	year = {1996},
	keywords = {occupancy grid, old, stereo},
	annote = {{\textless}p{\textgreater}possibly first 3d occupancy grid?{\textless}/p{\textgreater}}
},

@inproceedings{thrun_integrating_1996,
	title = {Integrating {Grid-Based} and Topological Maps for Mobile Robot Navigation},
	lccn = {0200},
	url = {http://citeseer.ist.psu.edu/thrun96integrating.html},
	abstract = {Research on mobile robot navigation has produced two major
paradigms for mapping indoor environments: grid-based
and topological. While grid-based methods produce accurate
metric maps, their complexity often prohibits efficient
planning and problem solving in large-scale indoor environments.
Topological maps, on the other hand, can be used
much more efficiently, yet accurate and consistent topological
maps are considerably difficult to learn in large-scale
environments.
This paper describes an...},
	booktitle = {{AAAI/{IAAI},} Vol. 2},
	author = {Sebastian Thrun and Arno Bucken},
	year = {1996},
	keywords = {certainty, grid, hybrid, map, old, topological},
	pages = {944--950},
	annote = {{\textless}p{\textgreater}cited by 82{\textless}/p{\textgreater}}
},

@inproceedings{vandorpe_exact_1996,
	address = {Minneapolis, {MN,} {USA}},
	title = {Exact dynamic map building for a mobile robot using geometrical primitives produced by a {2D} range finder},
	lccn = {0067},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=503887},
	doi = {10.1109/ROBOT.1996.503887},
	abstract = {In this paper a new mathematically exact algorithm is described for dynamic map building with geometrical primitives for a mobile robot. The dynamic map is built up using a {2D} range finder mounted on the mobile robot {LiAS} which is navigating in the environment. The dynamic map can be used for either planning or localisation purposes. The map is composed of line segments and circles. The parameters describing the geometrical primitives are provided with uncertainties which are used in the matching phase and which are necessary if the map is used for localisation. This paper describes in detail how the uncertainty on the robot position and the uncertainty on a single range measurement leads to the uncertainty on the parameters of a geometrical primitive. Promising experimental results obtained by the algorithm in real unstructured environments are presented},
	booktitle = {Proceedings of {IEEE} International Conference on Robotics and Automation},
	author = {J. Vandorpe and H. Van Brussel and H. Xu},
	month = apr,
	year = {1996},
	keywords = {circles, geometric fitting, lines, old},
	pages = {901--908}
},

@inproceedings{yamauchi_mobile_1996,
	address = {Minneapolis, {MN,} {USA}},
	title = {Mobile robot localization in dynamic environments using dead reckoning and evidence grids},
	lccn = {0052},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=506902},
	doi = {10.1109/ROBOT.1996.506902},
	abstract = {Dead reckoning provides a simple way to keep track of a mobile robot's location. However, due to slippage between the robot's wheels and the underlying surface, this position estimate accumulates errors over time. In this paper, we introduce a method for correcting dead reckoning errors by matching evidence grids constructed at different times. A hill-climbing algorithm is used to search the space of possible translations and rotations used to transform one grid into the other. The transformation resulting in the best match is used to correct the robot's position estimate. This technique has been tested on a real mobile robot and has demonstrated robustness to transient changes (moving people) and lasting changes (rearranged obstacles) in dynamic environments},
	booktitle = {Proceedings of {IEEE} International Conference on Robotics and Automation},
	author = {B. Yamauchi},
	month = apr,
	year = {1996},
	keywords = {localization, occupancy grid, old},
	pages = {1401--1406}
},

@inproceedings{berler_bayes_1997,
	title = {Bayes networks for sensor fusion in occupancy grids},
	lccn = {0003},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.133.3805},
	abstract = {1 {INTRODUCTION} Sonar mapping of the environment by mobile robot is nontrivial due to several sources of uncertainty. The first impediment to mapping is that most sonars used in mobile robots are wide-beam, in order to allow for sufficient coverage for obstacle avoidance. The wide angle causes a large uncertainty of location of the detected obstacle(s), within the arc at the detected distance from the sonar. Second, readings are inexact due to noise and pulse-width problems. These problems have been largely addressed in work by Elfes using a Bayesian model and an occupancy grid [3, 4]. Third, surfaces of objects placed far from the perpendicular to the direction of the beam may reflect almost no acoustic energy in the direction of the sensor (which is also the emitter},
	booktitle = {In Procs. of the Conf. on Uncertainty in Artif. Intell},
	author = {Ami Berler and Solomon Shimony},
	year = {1997},
	keywords = {occupancy grid, old}
},

@inproceedings{burgard_fast_1997,
	title = {Fast {Grid-Based} Position Tracking for Mobile Robots},
	lccn = {0053},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.23.4455},
	abstract = {One of the fundamental problems in the \#eld of mobile robotics is the estimation of the robot's position in the environment. Position probability grids have been proven to be a robust technique for the estimation of the absolute position of a mobile robot. In this paper we describe an application of position probability grids to position tracking. Given a starting position our approachkeeps track of the robot's current position by matching sensor readings against a metric model of the...},
	booktitle = {{KI} - Kunstliche Intelligenz},
	author = {Wolfram Burgard and Dieter Fox and Daniel Henning},
	year = {1997},
	keywords = {fusion, grid, position, probabilistic, robotics, sensor, tracking},
	pages = {289--300}
},

@article{lu_globally_1997,
	title = {Globally Consistent Range Scan Alignment for Environment Mapping},
	volume = {4},
	issn = {0929-5593},
	lccn = {0648},
	url = {http://dx.doi.org/10.1023/A:1008854305733},
	abstract = {A robot exploring an unknown environment may need to build a world model from sensor measurements. In order to integrate all the frames of sensor data, it is essential to align the data properly. An incremental approach has been typically used in the past, in which each local frame of data is aligned to a cumulative global model, and then merged to the model. Because different parts of the model are updated independently while there are errors in the registration, such an approach may result in an inconsistent model.},
	number = {4},
	journal = {Autonomous Robots},
	author = {F Lu and E Milios},
	year = {1997},
	keywords = {3d, old, registration, slam},
	pages = {333--349},
	annote = {{\textless}p{\textgreater}-seminal {SLAM:} smith, self, cheeseman [91,92], adapting to large \# of raw range measurements, [60]{\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}
{{\textless}p{\textgreater}This} one adapts slam to a large number of particles{\textless}/p{\textgreater}}
},

@inproceedings{payeur_probabilistic_1997,
	title = {Probabilistic octree modeling of a {3D} dynamic environment},
	volume = {2},
	lccn = {0014},
	abstract = {Probabilistic occupancy grids have proved to be very useful forworkspace modeling in {2D} environments. Due to the expansion ofcomputational load, this approach was not tractable for mapping a {3Denvironment} in real applications. In this paper, the original occupancygrid scheme is revisited and a generic closed-form function isintroduced to avoid numerical computation of probabilities for a rangesensor with Gaussian error distribution. Occupancy probabilities arecomputed and stored in a multiresolution octree for improved performanceand compactness. Occupancy models are built in local reference framesand linked to a global reference frame through uncertain spatialrelationships that can be updated dynamically. This scheme is used forbuilding a {3D} map in a telerobotic maintenance application of electricpower lines where perturbations may cause motion of objectassembly},
	booktitle = {Proceedings of the {IEEE} International Conference on Robotics and Automation},
	author = {P Payeur and P Hebert and D Laurendeau and {CM} Gosselin},
	year = {1997},
	keywords = {3d, closed-form, distribution, dynamic, electric, Engineering, environment, error, function, gaussian, generic, grids, laser, lines, maintenance, networks, occupancy, occupancy grid, octrees, old, path, planning, power, probabilistic, range, ranging, robot, sensor, star, statistics, telerobotics, vision},
	pages = {1289--1296}
},

@article{pierce_map_1997,
	title = {Map learning with uninterpreted sensors and effectors},
	volume = {92},
	issn = {0004-3702},
	lccn = {0147},
	url = {http://dx.doi.org/10.1016/S0004-3702(96)00051-3},
	abstract = {This paper presents a set of methods by which a learning agent can learn a sequence of increasingly abstract and powerful interfaces to control a robot whose sensorimotor apparatus and environment are initially unknown, The result of the learning is a rich hierarchical model of the robot's world (its sensorimotor apparatus and environment). The learning methods rely on generic properties of the robot's world such as almost-everywhere smooth effects of motor control signals on sensory features. At the lowest level of the hierarchy, the learning agent analyzes the effects of its motor control signals in order to define a new set of control signals, one for each of the robot's degrees of freedom. It uses a generate-and-test approach to define sensory features that capture important aspects of the environment, It uses Linear regression to learn models that characterize context-dependent effects of the control signals on the learned features. It uses these models to define high-level control laws for finding and following paths defined using constraints on the learned features, The agent abstracts these control laws, which interact with the continuous environment, to a finite set of actions that implement discrete state transitions. At this point, the agent has abstracted the robot's continuous world to a finite-state world and can use existing methods to learn its structure. The learning agent's methods are evaluated on several simulated robots with different sensorimotor systems and environments.},
	number = {1-2},
	journal = {Artificial Intelligence},
	author = {David Pierce and Benjamin Kuipers},
	year = {1997},
	keywords = {cognitive map, machine\_learning, old, sensorimotor, sensorimotor\_organization, unsupervised\_learning},
	pages = {169--227}
},

@inproceedings{pulli_robust_1997,
	address = {Los Alamitos, {CA,} {USA}},
	title = {Robust Meshes from Multiple Range Maps},
	volume = {0},
	isbn = {0-8186-7943-3},
	lccn = {0073},
	doi = {http://doi.ieeecomputersociety.org/10.1109/IM.1997.603867},
	abstract = {Abstract: This paper presents a method for modeling the surface of an object from a sequence of range maps. Our method is based on a volumetric approach that produces a compact surface without boundary. It provides robustness through the use of interval analysis techniques and computational efficiency through hierarchical processing using octrees.},
	booktitle = {{3D} Digital Imaging and Modeling, International Conference on},
	publisher = {{IEEE} Computer Society},
	author = {K. Pulli and T. Duchamp and H. Hoppe and J. {McDonald} and L. Shapiro and W. Stuetzle},
	year = {1997},
	keywords = {mesh, octree, old, surface fitting},
	pages = {205},
	annote = {Complete {PDF} document was either not available or accessible. Please make sure you're logged in to the digital library to retrieve the complete {PDF} document.}
},

@inproceedings{shatkay_learning_1997,
	address = {Nagoya, Japan},
	title = {Learning topological maps with weak local odometric information},
	isbn = {1-555860-480-4},
	lccn = {0198},
	url = {http://portal.acm.org/citation.cfm?id=1622289},
	abstract = {Topological maps provide a useful abstraction for robotic navigation and planning. Although stochastic maps can theoretically be learned using the {Baum-Welch} algorithm, without strong prior constraint on the structure of the model it is slow to converge, requires a great deal of data, and is often stuck in local minima. In this paper, we consider a special case of hidden Markov models for robot-navigation environments, in which states are associated with points in a metric configuration space. We assume that the robot has some odometric ability to measure relative transformations between its configurations. Such odometry is typically not precise enough to suffice for building a global map, but it does give valuable local information about relations between adjacent states. We present an extension of the {Baum-Welch} algorithm that takes advantage of this local odometric information, yielding faster convergence to better solutions with less data.},
	booktitle = {Proceedings of the Fifteenth international joint conference on Artifical intelligence - Volume 2},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Hagit Shatkay and Leslie Kaelbling},
	year = {1997},
	keywords = {old, topological},
	pages = {920--927}
},

@article{konolige_improved_1997,
	title = {Improved Occupancy Grids for Map Building},
	volume = {4},
	issn = {0929-5593},
	lccn = {0085},
	url = {http://dx.doi.org/10.1023/A:1008806422571},
	abstract = {Occupancy grids are a probabilistic method for fusing multiplesensor readings into surface maps of the environment. Although theunderlying theory has been understood for many years, the intricacies ofapplying it to realtime sensor interpretation have been neglected. Thispaper analyzes how refined sensor models (including specularity models) andassumptions about independence are crucial issues for occupancy gridinterpretation. Using this analysis, the {MURIEL} method for occupancy gridupdate is developed. Experiments show how it can dramatically improve thefidelity of occupancy grid map-making in specular and realtimeenvironments.},
	number = {4},
	journal = {Autonomous Robots},
	author = {Kurt Konolige},
	month = oct,
	year = {1997},
	keywords = {Computer Science, occupancy grid, old},
	pages = {351--367}
},

@inproceedings{dedieu_efficient_1998,
	title = {Efficient Occupancy Grids for Variable Resolution Map Building},
	lccn = {0004},
	abstract = {This paper presents two parts of the whole system we are developing. The first one is a new method for integrating metric information into local occupancy grids that makes them more appropriate for learning variable resolution hybrid maps. It has two major appealing features:},
	booktitle = {In 6th International Symposium on Intelligent Robotic Systems},
	author = {Eric Dedieu and Jos� del R. Mill�n and Jos'e Del R. Mill'an},
	year = {1998},
	keywords = {occupancy grid, old},
	pages = {195�203}
},

@inproceedings{gibson_using_1998,
	title = {Using distance maps for accurate surface representation in sampled volumes},
	isbn = {1581131054},
	lccn = {0142},
	url = {http://dx.doi.org/10.1145/288126.288142},
	abstract = {High quality rendering and physics-based modeling in volumes graphics have been limited because intensity-based volumetric data do not represent surfaces well. High spatial frequencies due to abrupt intensity changes at objects surfaces result in jagged or terraced surfaces in rendered images. {THe} use of a distance-to-closest-surface function to encode object surfaces is proposed. This function varies smoothly across surfaces and hence can be accurately reconstructed from sampled data. the zero-value iso-surface of the distance map yields the object surface and the derivative of the distance map yields the surface normal. Examples of rendered images are presented along with a new method for calculating distance maps from sampled binary data.},
	booktitle = {{VVS} '98: Proceedings of the 1998 {IEEE} symposium on Volume visualization},
	publisher = {{ACM} Press},
	author = {Sarah Gibson},
	year = {1998},
	keywords = {geometric-modeling, geometry, implicit-distance-field, implicit-representation, old, representation, sampling, surface fitting, voxelization},
	pages = {23--30}
},

@incollection{gribble_integrating_1998,
	title = {Integrating Vision and Spatial Reasoning for Assistive Navigation},
	lccn = {0037},
	abstract = {This paper describes the goals and research directions of the University of Texas Artificial Intelligence Lab's Intelligent Wheelchair Project {(IWP).} The {IWP} is a work in progress. The authors are part of a collaborative effort to bring expertise from knowledge representation, control, planning, and machine vision to bear on this difficult and interesting problem domain. Our strategy uses knowledge about the semantic structure of space to focus processing power and sensing resources. The semi-autonomous assistive control of a wheelchair shares many subproblems with mobile robotics, including those of sensor interpretation, spatial knowledge representation, and real-time control. By enabling the wheelchair with active vision and other sensing modes, and by application of our theories of spatial knowledge representation and reasoning, we hope to provide substantial assistance to people with severe mobility impairments.},
	booktitle = {Assistive Technology and Artificial Intelligence},
	publisher = {{Springer-Verlag}},
	author = {{WS} Gribble and {RL} Browning and M Hewett and E Remolina and {BJ} Kuipers and V Mittal and H Yanco and J Aronis and R Simpson},
	year = {1998},
	keywords = {cognitive map, nn, old}
},

@inproceedings{payeur_range_1998,
	address = {Leuven, Belgium},
	title = {Range data merging for probabilistic octree modeling of {3D} workspaces},
	lccn = {0012},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=680897},
	doi = {10.1109/ROBOT.1998.680897},
	abstract = {In a previous paper by Payeur et al. (1997), probabilistic occupancy modeling has been successfully extended to {3D} environments by means of a closed-form approximation of the probability distribution. In this paper, the closed-form approximation is revisited in order to provide more reliable and meaningful models. A merging strategy of local probabilistic occupancy grids originating from each sensor viewpoint is introduced. The merging process takes advantage of the multiresolution characteristics of octrees to minimize the computational complexity and enhance performances. An experimental testbed is used to validate the approach and models computed from real range images are presented},
	booktitle = {Proceedings. 1998 {IEEE} International Conference on Robotics and Automation {(Cat.} {No.98CH36146)}},
	author = {P. Payeur and D. Laurendeau and {C.M.} Gosselin},
	year = {1998},
	keywords = {occupancy grid, octree, old},
	pages = {3071--3078}
},

@inproceedings{schultz_continuous_1998,
	address = {Leuven, Belgium},
	title = {Continuous localization using evidence grids},
	lccn = {0112},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=680595},
	doi = {10.1109/ROBOT.1998.680595},
	abstract = {Evidence grids provide a uniform representation for fusing temporally and spatially distinct sensor readings. However, the use of evidence grids requires that the robot be localized within its environment. Odometry errors typically accumulate over time, making localization estimates degrade, and introducing significant errors into evidence grids as they are built. We have addressed this problem by developing a method for �continuous localization�, in which the robot corrects its localization estimates incrementally and on the fly. Assuming the mobile robot has a map of its environment represented as an evidence grid, localization is achieved by building a series of �local perception grids� based on localized sensor readings and the current odometry, and then registering the local and global grids. The registration produces an offset which is used to correct the odometry. Results are given on the effectiveness of this method, and quantify the improvement of continuous localization over dead reckoning. We also compare different techniques for matching evidence grids and for searching registration offsets},
	booktitle = {Proceedings. 1998 {IEEE} International Conference on Robotics and Automation {(Cat.} {No.98CH36146)}},
	author = {{A.C.} Schultz and W. Adams},
	year = {1998},
	keywords = {old, slam},
	pages = {2833--2839}
},

@article{thrun_learning_1998,
	title = {Learning metric-topological maps for indoor mobile robot navigation},
	volume = {99},
	issn = {0004-3702},
	lccn = {0711},
	url = {http://dx.doi.org/10.1016/S0004-3702(97)00078-7},
	abstract = {Autonomous robots must be able to learn and maintain models of their environments. Research on mobile robot navigation has produced two major paradigms for mapping indoor environments: grid-based and topological. While grid-based methods produce accurate metric maps, their complexity often prohibits efficient planning and problem solving in large-scale indoor environments. Topological maps, on the other hand, can be used much more efficiently, yet accurate and consistent topological maps are often difficult to learn and maintain in large-scale environments, particularly if momentary sensor data is highly ambiguous. This paper describes an approach that integrates both paradigms: grid-based and topological. Grid-based maps are learned using artificial neural networks and naive Bayesian integration. Topological maps are generated on top of the grid-based maps, by partitioning the latter into coherent regions. By combining both paradigms, the approach presented here gains advantages from both worlds: accuracy/consistency and efficiency. The paper gives results for autonomous exploration, mapping and operation of a mobile robot in populated multi-room environments.},
	number = {1},
	journal = {Artif. Intell.},
	author = {Sebastian Thrun},
	year = {1998},
	keywords = {hybrid, slam, tslam},
	pages = {21--71}
},

@article{thrun_learning_1998-1,
	title = {Learning Maps for Indoor Mobile Robot Navigation},
	volume = {99},
	lccn = {0004},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.33.9138},
	abstract = {Autonomous robots must be able to learn and maintain models of their environments. Research on mobile robot navigation has produced two major paradigms for mapping indoor environments: grid-based and topological. While grid-based methods produce accurate metric maps, their complexity often prohibits efficient planning and problem solving in large-scale indoor environments. Topological maps, on the other hand, can be used much more efficiently, yet accurate and consistent topological maps are considerably difficult to learn in large-scale environments. This paper describes an approach that integrates both paradigms: grid-based and topological. Grid-based maps are learned using artificial neural networks and Bayesian integration. Topological maps are generated on top of the gridbased maps, by partitioning the latter into coherent regions. By combining both paradigms---grid-based and topological---, the approach presented here gains the best of both worlds: accuracy/consistency and effic...},
	journal = {Artificial Intelligence},
	author = {Sebastian Thrun and Arno B�cken},
	year = {1998},
	keywords = {hybrid, mobile-robot, navigation, old, path-planning},
	pages = {21--71},
	annote = {{\textless}p{\textgreater}cited by 73{\textless}/p{\textgreater}}
},

@inproceedings{thrun_integrating_1998,
	address = {Menlo Park, {CA,} {USA}},
	series = {{AAAI} {'98/IAAI} '98},
	title = {Integrating topological and metric maps for mobile robot navigation: a statistical approach},
	isbn = {0-262-51098-7},
	lccn = {0120},
	location = {Madison, Wisconsin, United States},
	url = {http://portal.acm.org/citation.cfm?id=295240.295943},
	abstract = {The problem of concurrent mapping and localization has re-
ceived considerable attention in the mobile robotics commu-
nity. Existing approaches can largely be grouped into two dis-
tinct paradigms: topological and metric. This paper proposes
a method that integrates both. It poses the mapping problem as
a statistical maximum likelihood problem, and devises an ef-
ficient algorithm for search in likelihood space. It presents an
novel mapping algorithm that integrates two phases: a topo-
logical and a metric mapping phase. The topological mapping
phase solves a global position alignment problem between po-
tentially indistinguishable, significant places. The subsequent
metric mapping phase produces a fine-grained metric map of
the environment in floating-point resolution. The approach
is demonstrated empirically to scale up to large, cyclic, and
highly ambiguous environments.},
	booktitle = {Proceedings of the fifteenth national/tenth conference on Artificial {intelligence/Innovative} applications of artificial intelligence},
	publisher = {American Association for Artificial Intelligence},
	author = {Sebastian Thrun and {Jens-Steffen} Gutmann and Dieter Fox and Wolfram Burgard and Benjamin J Kuipers},
	year = {1998},
	keywords = {hybrid, old},
	pages = {989�995}
},

@article{thrun_probabilistic_1998,
	title = {A Probabilistic Approach to Concurrent Mapping and Localization for Mobile Robots},
	volume = {31},
	lccn = {0742},
	url = {http://citeseer.ist.psu.edu/thrun98probabilistic.html},
	abstract = {. This paper addresses the problem of building large-scale geometric maps of indoor environments with
mobile robots. It poses the map building problem as a constrained, probabilistic maximum-likelihood estimation
problem. It then devises a practical algorithm for generating the most likely map from data, along with the most
likely path taken by the robot. Experimental results in cyclic environments of size up to 80 by 25 meter illustrate
the appropriateness of the approach.
Keywords: Bayes...},
	number = {1-3},
	journal = {Machine Learning},
	author = {Sebastian Thrun and Wolfram Burgard and Dieter Fox},
	year = {1998},
	keywords = {got, old, slam},
	pages = {29--53},
	annote = {{\textless}p{\textgreater}cited by 348{\textless}/p{\textgreater}}
},

@article{whitaker_level-set_1998,
	title = {A {Level-Set} Approach to {3D} Reconstruction from Range Data},
	volume = {29},
	issn = {0920-5691},
	lccn = {0274},
	url = {http://dx.doi.org/10.1023/A:1008036829907},
	abstract = {This paper presents a method that uses the level sets of volumes to
reconstruct the shapes of {3D} objects from range data. The strategy is
to formulate {3D} reconstruction as a statistical problem: find that
surface which is mostly likely, given the data and some prior knowledge
about the application domain. The resulting optimization problem is
solved by an incremental process of deformation. We represent a
deformable surface as the level set of a discretely sampled scalar
function of three dimensions, i.e., a volume. Such level-set models
have been shown to mimic conventional deformable surface models by
encoding surface movements as changes in the greyscale values of the
volume. The result is a voxel-based modeling technology that offers
several advantages over conventional parametric models, including
flexible topology, no need for reparameterization, concise
descriptions of differential structure, and a natural scale space for
hierarchical representations. This paper builds on previous work in
both {3D} reconstruction and level-set modeling. It presents a
fundamental result in surface estimation from range data: an
analytical characterization of the surface that maximizes the
posterior probability. It also presents a novel computational
technique for level-set modeling, called the sparse-field algorithm,
which combines the advantages of a level-set approach with the
computational efficiency and accuracy of a parametric representation.
The sparse-field algorithm is more efficient than other approaches,
and because it assigns the level set to a specific set of grid points,
it positions the level-set model more accurately than the grid itself.
These properties, computational efficiency and subcell accuracy, are
essential when trying to reconstruct the shapes of {3D} objects.
Results are shown for the reconstruction objects from sets of noisy
and overlapping range maps.},
	number = {3},
	journal = {Int. J. Comput. Vision},
	author = {Ross Whitaker},
	year = {1998},
	keywords = {3d, doctorate, level-sets, old, plane fitting, reconstruction, surface fitting},
	pages = {203--231}
},

@article{arleo_efficient_1999,
	title = {Efficient learning of variable-resolution cognitive maps for autonomous indoor navigation},
	volume = {15},
	issn = {{1042-296X}},
	lccn = {0045},
	doi = {10.1109/70.817664},
	abstract = {This paper presents an adaptive method that allows mobile robots
to learn cognitive maps of indoor environments incrementally and online.
Our approach models the environment. By means of a variable-resolution
partitioning that discretizes the world in perceptually homogeneous
regions. The resulting model incorporates both a compact geometrical
representation of the environment and a topological map of the spatial
relationships between its obstacle-free areas. The efficiency of the
learning process is based on the use of local memory-based techniques
for partitioning and of active learning techniques for selecting the
most appropriate region to be explored next. In addition, a feedforward
neural network is used to interpret sensor readings. We present
experimental results obtained with two different mobile robots, the
Nomad 200 and Khepera. The current implementation of the method relies
on the assumption that obstacles are parallel or perpendicular to each
other. This results in variable-resolution partitioning consisting of
simple rectangular partitions and reduces the complexity of treating the
underlying geometrical properties},
	number = {6},
	journal = {Robotics and Automation, {IEEE} Transactions on},
	author = {A. Arleo and J. del R. Millan and D. Floreano},
	year = {1999},
	keywords = {active learning, cognitive maps, computerised navigation, feedforward neural nets, feedforward neural network, hybrid, indoor navigation, learning (artificial intelligence), map learning, Mobile robots, occupancy grid, old, path planning, topological graph, topological map, topology, variable-resolution partitioning},
	pages = {990--1000}
},

@article{castellanos_spmap:_1999,
	title = {The {SPmap:} a probabilistic framework for simultaneous localization and map building},
	volume = {15},
	issn = {{1042-296X}},
	lccn = {0257},
	shorttitle = {The {SPmap}},
	doi = {10.1109/70.795798},
	abstract = {This article describes a rigorous and complete framework for the
simultaneous localization and map building problem for mobile robots:
the symmetries and perturbation map {(SPmap),} which is based on a general
probabilistic representation of uncertain geometric information. We
present a complete experiment with a {LabMateTM} mobile robot
navigating in a human-made indoor environment and equipped with a
rotating {2D} laser rangefinder. Experiments validate the appropriateness
of our approach and provide a real measurement of the precision of the
algorithms},
	number = {5},
	journal = {Robotics and Automation, {IEEE} Transactions on},
	author = {{J.A.} Castellanos and {J.M.M.} Montiel and J. Neira and {J.D.} Tardos},
	year = {1999},
	keywords = {{2D} laser rangefinder, correlation methods, correlations, indoor environment, laser ranging, localization, map building, Mobile robots, navigation, old, path planning, perturbation map, position control, probabilistic model, probability, slam, {SPmap,} symmetries},
	pages = {948--952}
},

@misc{dieter_fox_probabilistic_1999,
	title = {Probabilistic methods for mobile robot mapping},
	lccn = {0017},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=?doi=10.1.1.120.1038},
	abstract = {The problem of map building is the problem of determining
the location of entities-of-interest in a global frame of
reference. Over the last years, probabilistic methods have
shown to be well suited for dealing with the uncertainties
involved in mobile robot map building. In this paper we
introduce a general probabilistic approach to concurrent
mapping and localization. This method poses the mapping
problem as a statistical maximum likelihood problem, and
devises an efficient algorithm for search in likelihood
space. We furthermore address the problem of using occupancy
grid maps for path planning in highly dynamic environments.
The approaches have been tested extensively and several
experimental results are given in the paper. 1},
	author = {Dieter Fox and Wolfram Burgard and Sebastian Thrun},
	year = {1999},
	keywords = {occupancy grid, old},
	annote = {{CiteSeerX} - Scientific Literature Digital Library and Search
Engine [http://citeseerx.ist.psu.edu/oai2] {(United} States)}
},

@misc{dmitry_o._gorodnichy_parametric_1999,
	title = {A Parametric Alternative to Grids for {Occupancy-Based} World Modeling},
	lccn = {0005},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.47.3820},
	abstract = {In the paper, we consider an occupancy-based approach for
range data fusion, as it is used in mobile robotics. We
tackle the major problem of this approach, which is the
redundancy of stored and processed data caused by using the
grid representation of the occupancy function, by proposing
a parametric piece-wise linear representation. When applied
to the vision-based world exploration, the new
representation is shown to have advantages over the former
one, which include its suitability for radial range data,
its efficiency in representing and fusing range data, and
its convenience for navigation map extraction. The proposed
technique is implemented on a mobile robot, Boticelli. The
results obtained from running the robot are presented. 1
Introduction In mobile robot world exploration, the
occupancybased approach is one of the most commonly used [7,
13, 3, 2, 8, 4, 11]. In this approach, the exploration
policy is determined by the occupancy model of the world
which is built from the r...},
	author = {Dmitry O. Gorodnichy and William W. Armstrong},
	year = {1999},
	keywords = {occupancy grid, old, star},
	annote = {{CiteSeerX} - Scientific Literature Digital Library and Search
Engine [http://citeseerx.ist.psu.edu/oai2] {(United} States)}
},

@inproceedings{fox_monte_1999,
	title = {Monte Carlo Localization: Efficient Position Estimation for Mobile Robots},
	lccn = {0645},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.55.9389},
	abstract = {This paper presents a new algorithm for mobile robot localization, called Monte Carlo Localization {(MCL).} {MCL} is a version of Markov localization, a family of probabilistic approaches that have recently been applied with great practical success. However, previous approaches were either computationally cumbersome (such as grid-based approaches that represent the state space by high-resolution {3D} grids), or had to resort to extremely coarse-grained resolutions. Our approach is computationally efficient while retaining the ability to represent (almost) arbitrary distributions. {MCL} applies sampling-based methods for approximating probability distributions, in a way that places computation "where needed." The number of samples is adapted on-line, thereby invoking large sample sets only when necessary. Empirical results illustrate that {MCL} yields improved accuracy while requiring an order of magnitude less computation when compared to previous approaches. It is also much easier to implement....},
	booktitle = {In Proc. of the National Conference on Artificial Intelligence {(AAAI}},
	author = {Dieter Fox and Wolfram Burgard and Frank Dellaert and Sebastian Thrun},
	year = {1999},
	keywords = {localization, mobile-robotics, monte-carlo, parameters-characterization, particle-filter},
	pages = {343--349}
},

@article{fox_markov_1999,
	title = {Markov Localization for Mobile Robots in Dynamic Environments},
	volume = {11},
	lccn = {0624},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.34.372},
	abstract = {Localization, that is the estimation of a robot's location from sensor data, is a fundamental problem in mobile robotics. This papers presents a version of Markov localization which provides accurate position estimates and which is tailored towards dynamic environments. The key idea of Markov localization is to maintain a probability density over the space of all locations of a robot in its environment. Our approach represents this space metrically, using a ne-grained grid to approximate densities. It is able to globally localize the robot from scratch and to recover from localization failures. It is robust to approximate models of the environment (such as occupancy grid maps) and noisy sensors (such as ultrasound sensors). Our approach also includes a ltering technique which allows a mobile robot to reliably estimate its position even in densely populated environments in which crowds of people block the robot's sensors for extended periods of time. The method described he...},
	journal = {Journal of Artificial Intelligence Research},
	author = {Dieter Fox and Wolfram Burgard and Sebastian Thrun},
	year = {1999},
	keywords = {localization, old},
	pages = {391--427}
},

@inproceedings{gibbons_synopsis_1999,
	title = {Synopsis data structures for massive data sets},
	volume = {50},
	lccn = {0171},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.36.1647},
	abstract = {Massive data sets with terabytes of data are becoming commonplace. There is an increasing demand for algorithms and data structures that provide fast response times to queries on such data sets. In this paper, we describe a context for algorithmic work relevant to massive data sets and a framework for evaluating such work. We consider the use of \&quot;synopsis \&quot; data structures, which use very little space and provide fast (typically approximated) answers to queries. The design and analysis of effective synopsis data structures offer many algorithmic challenges. We discuss a number of concrete examples of synopsis data structures, and describe fast algorithms for keeping them up-to-date in the presence of online updates to the data sets. 1},
	booktitle = {{DIMACS:} Series in Discrete Mathematics and Theoretical Computer Science: Special Issue on External Memory Algorithms and Visualization, A},
	author = {Phillip Gibbons and Yossi Matias},
	year = {1999},
	keywords = {al-datastructs, al-streaming, data structures},
	pages = {909--910}
},

@techreport{gibson_calculating_1999,
	title = {Calculating the distance map for binary sampled data},
	lccn = {0007},
	abstract = {High quality rendering and physics-based modeling in volume graphics have been limited be-
cause intensity-based volumetric data do not represent surfaces well. High spatial frequencies
due to abrupt intensity changes at object surfaces result in jagged or terraced surfaces in rendered
images. Use of a distance-to-closest-surface function to encode object surfaces allows accurate
reconstruction of objet surfaces for volumetric data. However, constructing the distance map for
distance-based rendering requires a prior model of the object surface. Here we present a num-
ber of methods that can be used to estimate the distance map from a binary segmented volume,
where no prior knowledge of object surfaces exists.},
	author = {Sarah Gibson},
	year = {1999},
	keywords = {aliasing, implicit-distance-field, implicit-representation, old, plane fitting, representation, sampling, voxelization}
},

@inproceedings{gorodnichy_using_1999,
	address = {Edmonton, Alta., Canada},
	title = {On using regression for range data fusion},
	lccn = {0005},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=804889},
	doi = {10.1109/CCECE.1999.804889},
	abstract = {We consider an occupancy based approach for range data fusion, as it is used in mobile robotics. We identify two major problems of this approach. The first problem deals with the combination rule which in many cases assumes the independence of range data, contrary to the usual situation. The second problem concerns the redundancy of stored and processed data, which results from using the grid representation of the occupancy function and which is the main obstacle to building {3D} occupancy world models. We propose a solution to these problems by proposing a new range data fusion technique based on regression. This technique uses the evidence theory in assigning occupancy values, which we argue is advantageous for fusion, and builds the occupancy function by fitting the sample data provided by a sensor with a piecewise linear function. Having developed a general framework for our approach, we apply it to building {3D} occupancy models from visual range data, where the models are used for navigating a robot in an unknown environment},
	booktitle = {Engineering Solutions for the Next Millennium. 1999 {IEEE} Canadian Conference on Electrical and Computer Engineering {(Cat.} {No.99TH8411)}},
	author = {{D.O.} Gorodnichy},
	year = {1999},
	keywords = {3d, occupancy grid, old},
	pages = {1345--1350}
},

@inproceedings{leonard_computationally_1999,
	title = {A computationally efficient method for large-scale concurrent mapping and localization},
	lccn = {0253},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.122.4705},
	abstract = {Decoupled stochastic mapping {(DSM)} is a computationally efficient approach to large-scale concurrent mapping and localization. {DSM} reduces the computational burden of conventional stochastic mapping by dividing the environment into multiple overlapping submap regions, each with its own stochastic map. Two new approximation techniques are utilized for transferring vehicle state information from one submap to another, yielding a constant-time algorithm whose memory requirements scale linearly with the size of the operating area. The performance of two different variations of the algorithm is demonstrated through simulations of environments with 110 and 1200 features. Experimental results are presented for an environment with 93 features using sonar data obtained in a 3 by 9 by 1 meter testing tank. 1.},
	booktitle = {Proceedings of the Ninth International Symposium on Robotics Research},
	author = {John Leonard and Hans Jacob and S Feder},
	year = {1999},
	keywords = {old, robot, slam},
	pages = {169--176}
},

@article{murphy_bayesian_1999,
	title = {Bayesian Map Learning in Dynamic Environments},
	volume = {12},
	lccn = {0268},
	url = {http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.21.3240},
	abstract = {We show how map learning can be formulated as inference in a graphical model, which allows us to handle changing environments in a natural manner. We describe several different approximation schemes for the problem, and illustrate some results on a simulated grid-world with doors that can open and close. We close by briefly discussing how to learn more general models of (partially observed) environments, which can contain a variable number of objects with changing internal state. 1 Introduction Mobile robots need to navigate in dynamic environments: on a short time scale, obstacles, such as people, can appear and disappear, and on longer time scales, structural changes, such as doors opening and closing, can occur. In this paper, we consider how to create models of dynamic environments. In particular, we are interested in modeling the location of objects, which we can represent using a map. This enables the robot to perform path planning, etc. We propose a Bayesian approach in ...},
	journal = {{IN} {NEURAL} {INFO.} {PROC.} {SYSTEMS} {(NIPS}},
	author = {Kevin Murphy},
	year = {1999},
	keywords = {dynamic, occupancy grid, old},
	pages = {1015---1021}
},

@inproceedings{olson_subpixel_1999,
	address = {Detroit, {MI,} {USA}},
	title = {Subpixel localization and uncertainty estimation using occupancy grids},
	lccn = {0029},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=770399},
	doi = {10.1109/ROBOT.1999.770399},
	abstract = {We describe techniques for performing mobile robot localization using occupancy grids that allow subpixel localization and uncertainty estimation in the pixelized pose space. The techniques are based on a localization method where matching is performed between the visible landmarks at the current robot position and a previously generated map of the environment. A likelihood function over the space of possible robot positions is formulated as a function of the probability distribution for the map matching error. Subpixel localization and uncertainty estimation are performed by fitting the likelihood function with a parameterized surface. The performance of the method is analyzed using synthetic experiments and an example is given using the Rocky 7 Mars rover prototype},
	booktitle = {Proceedings 1999 {IEEE} International Conference on Robotics and Automation {(Cat.} {No.99CH36288C)}},
	author = {{C.F.} Olson},
	year = {1999},
	keywords = {occupancy grid, old},
	pages = {1987--1992}
},

@misc{vazquez_visibility_1999,
	title = {The visibility octree: A data structure for 3d navigation},
	lccn = {0000},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.3025},
	abstract = {This paper describes the Visibility Octree, a data structure to accelerate {3D} navigation
through very complex scenes. A conservative visibility algorithm that computes
and hierarchically stores the structure at a preprocessing stage is presented. The
Visibility Octree is used during navigation and its main contribution is its ability
to provide an effective control over the coarseness of the visibility approximation.
Tests with indoor ship scenes show that the visibility octree performs well on ...},
	author = {Saona Vazquez and I Navazo and P Brunet},
	year = {1999},
	keywords = {octree, old}
},

@article{axelsson_processing_1999,
	title = {Processing of laser scanner data�algorithms and applications},
	volume = {54},
	issn = {09242716},
	lccn = {0269},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0924271699000088},
	doi = {10.1016/S0924-2716(99)00008-8},
	abstract = {Airborne laser scanning systems are opening new possibilities for surveys and documentation of difficult areas and objects, such as dense city areas, forest areas and electrical power lines. Laser scanner systems available on the market are presently in a fairly mature state of art while the processing of airborne laser scanner data still is in an early phase of development. To come from irregular {3D} point clouds to useful representations and formats for an end-user requires continued research and development of methods and algorithms for interpretation and modelling. This paper presents some methods and algorithms concerning filtering for determining the ground surface, {DEM,} classification of buildings for {3D} City Models and the detection of electrical power lines. The classification algorithms are based on the Minimum Description Length criterion. The use of reflectance data and multiple echoes from the laser scanner is examined and found to be useful in many applications.},
	number = {2-3},
	journal = {{ISPRS} Journal of Photogrammetry and Remote Sensing},
	author = {P Axelsson},
	year = {1999},
	keywords = {classification},
	pages = {138--147}
},

@article{feder_adaptive_1999,
	title = {Adaptive Mobile Robot Navigation and Mapping},
	volume = {18},
	lccn = {0190},
	url = {http://dx.doi.org/10.1177/02783649922066484},
	abstract = {The task of building a map of an unknown environment and concurrently using that map to navigate is a central problem in mobile robotics research. This paper addresses the problem of how to perform concurrent mapping and localization {(CML)} adaptively using sonar. Stochastic mapping is a feature-based approach to {CML} that generalizes the extended Kalman filter to incorporate vehicle localization and environmental mapping. The authors describe an implementation of stochastic mapping that uses a delayed nearest neighbor data association strategy to initialize new features into the map, match measurements to map features, and delete out-of-date features. The authors introduce a metric for adaptive sensing that is defined in terms of Fisher information and represents the sum of the areas of the error ellipses of the vehicle and feature estimates in the map. Predicted sensor readings and expected dead-reckoning errors are used to estimate the metric for each potential action of the robot, and the action that yields the lowest cost (i.e., the maximum information) is selected. This technique is demonstrated via simulations, in-air sonar experiments, and underwater sonar experiments. Results are shown for (1) adaptive control of motion and (2) adaptive control of motion and scanning. The vehicle tends to explore selectively different objects in the environment. The performance of this adaptive algorithm is shown to be superior to straight-line motion and random motion. 10.1177/02783649922066484},
	number = {7},
	journal = {The International Journal of Robotics Research},
	author = {Hans Feder and John Leonard and Christopher Smith},
	month = jul,
	year = {1999},
	keywords = {old, slam},
	pages = {650--668}
},

@inproceedings{huber_new_1999,
	title = {A New Approach to {3-D} Terrain Mapping},
	lccn = {0058},
	abstract = {We discuss the problem of building large, high-resolution three-dimensional representations of unstructured terrain using terrestrial range sensors, which operate at the scale of meters to hundreds of meters. Issues specific to this sensing modality include widely varying resolution, absence of reliably detectable features, and very large data sets. We have developed a map building algorithm that registers and integrates sequences of range images, and we demonstrate its capabilities by building large terrain maps (260 x 166 meters) using ground-based and low-altitude terrestrial range sensors.},
	booktitle = {Proceedings of the 1999 {IEEE/RSJ} International Conference on Intelligent Robotics and Systems {(IROS} '99)},
	publisher = {{IEEE}},
	author = {Daniel Huber and Martial Hebert},
	month = oct,
	year = {1999},
	keywords = {3d, old, registration, star},
	pages = {1121--1127}
},

@inproceedings{gutmann_incremental_1999,
	title = {Incremental mapping of large cyclic environments},
	lccn = {0427},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.1.6452},
	abstract = {Mobile robots can use geometric or topological maps of their environment to navigate reliably. Automatic creation of such maps is still an unrealized goal, especially in environments that have large cyclical structures. Drawing on recent techniques of global registration and correlation, we present a method, called Local Registration and Global Correlation {(LRGC),} for reliable reconstruction of consistent global maps from dense range data. The method is attractive because it is incremental,...},
	booktitle = {Proceedingsof the {IEEE} International Symposium on Computational Intelligence in Robotics and Automation {({CIRA})}},
	author = {J Gutmann and K Konolige},
	month = nov,
	year = {1999},
	keywords = {old, registration, slam},
	pages = {318--325}
},

@incollection{remolina_formalizing_1999,
	title = {Formalizing Regions in the Spatial Semantic Hierarchy: an {AH-Graphs} implementation approach},
	volume = {1661},
	isbn = {978-3-540-66365-2},
	lccn = {0018},
	url = {http://dx.doi.org/10.1007/3-540-48384-5_8},
	abstract = {We are interested in the problem of how an agent organizes its sensorimotor experiences in order to create a spatial representation. Our approach to solve this problem is the Spatial Semantic Hierarchy {(SSH),} an ontological hierarchy of representations for knowledge of large-scale space. At the {SSH} topological level, space is represented by places and connectivity relationships among them. Places are arranged into paths so that the topological representation looks like the street network of a city. Grouping places into regions allows an agent to reason efficiently about its spatial knowledge. Regions can be organized in a hierarchical structure suitable for hierarchical planning and human-level interface. In this paper we show how a hierarchy of regions can be automatically created by an agent. We extend the {SSH} axiomatic theory to include regions as first order objects at the {SSH} topological level. Based on this formalization, an implementation using Annotated Hierarchical graphs {(AH-graphs)} is proposed. The {AH-graph} model is chosen for its eficiency to perform basic operations like path planning, its facility to integrate information needed by different agent�s tasks, and because it provides a large indexed database of knowledge about the world with a friendly flow of information from and to human operators.},
	booktitle = {Spatial Information Theory. Cognitive and Computational Foundations of Geographic Information Science},
	publisher = {Springer Berlin Heidelberg},
	author = {Emilio Remolina and Juan Fernandez and Benjamin Kuipers and Javier Gonzalez and Christian Freksa and David Mark},
	month = dec,
	year = {1999},
	keywords = {cognitive map, old},
	pages = {750}
},

@misc{arnaud_doucet_raoblackwellised_2000,
	title = {Raoblackwellised particle filtering for dynamic bayesian networks},
	lccn = {0017},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.155.817},
	abstract = {Particle filters {(PFs)} are powerful samplingbased
inference/learning algorithms for dynamic Bayesian networks
{(DBNs).} They allow us to treat, in a principled way, any
type of probability distribution, nonlinearity and
non-stationarity. They have appeared in several fields under
such names as �condensation�, �sequential Monte Carlo
� and �survival of the fittest�. In this paper, we
show how we can exploit the structure of the {DBN} to increase
the efficiency of particle filtering, using a technique
known as {Rao-Blackwellisation.} Essentially, this samples
some of the variables, and marginalizes out the rest
exactly, using the Kalman filter, {HMM} filter, junction tree
algorithm, or any other finite dimensional optimal filter.
We show that {Rao-Blackwellised} particle filters {(RBPFs)} lead
to more accurate estimates than standard {PFs.} We demonstrate
{RBPFs} on two problems, namely non-stationary online
regression with radial basis function networks and robot
localization and map building. We also discuss other
potential application areas and provide references to some
finite dimensional optimal filters. 1},
	publisher = {Morgan Kaufmann Publishers},
	author = {Arnaud Doucet and Nando Freitas and Kevin Murphy and Stuart Russell},
	year = {2000},
	keywords = {graphical models, localization},
	annote = {{CiteSeerX} - Scientific Literature Digital Library and Search
Engine [http://citeseerx.ist.psu.edu/oai2] {(United} States)}
},

@inproceedings{frisken_adaptively_2000,
	title = {Adaptively sampled distance fields: a general representation of shape for computer graphics},
	isbn = {1581132085},
	lccn = {0412},
	url = {http://dx.doi.org/10.1145/344779.344899},
	abstract = {Adaptively Sampled Distance Fields {(ADFs)} are a unifying representation of shape that integrate numerous concepts in computer graphics including the representation of geometry and volume data and a broad range of processing operations such as rendering, sculpting, level-of-detail management, surface offsetting, collision detection, and color gamut correction. Its structure is uncomplicated and direct, but is especially effective for quality reconstruction of complex shapes, e.g., artistic and organic forms, precision parts, volumes, high order functions, and fractals. We characterize one implementation of {ADFs,} illustrating its utility on two diverse applications: 1) artistic carving of fine detail, and 2) representing and rendering volume data and volumetric effects. Other applications are briefly presented.},
	booktitle = {{SIGGRAPH} '00: Proceedings of the 27th annual conference on Computer graphics and interactive techniques},
	publisher = {{ACM} {Press/Addison-Wesley} Publishing Co.},
	author = {Sarah Frisken and Ronald Perry and Alyn Rockwood and Thouis Jones},
	year = {2000},
	keywords = {geometric-modeling, geometry, implicit-distance-field, octree, representation, sampling, volume-graphics, voxelization},
	pages = {249--254}
},

@inproceedings{huber_3d_2000,
	address = {San Francisco, {CA,} {USA}},
	title = {{3D} map reconstruction from range data},
	lccn = {0039},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=844162},
	doi = {10.1109/ROBOT.2000.844162},
	abstract = {We present techniques for building models of complex environments from range data gathered at multiple viewpoints. The challenges in this problem are: the matching of unregistered views without prior knowledge of pose, the use of very large data sets, and the manipulation of data sets of different resolutions and from different sensors. Our approach is unique in that no prior knowledge of the relative viewpoints is needed in order to register the data. We show results in building maps of interior environment from range finding data, building large terrain maps from ground-based and from aerial data, and from an operational for mapping from stereo data for hazardous environment characterization. The paper summarizes the major results obtained so far in this area},
	booktitle = {Proceedings 2000 {ICRA.} Millennium Conference. {IEEE} International Conference on Robotics and Automation. Symposia Proceedings {(Cat.} {No.00CH37065)}},
	author = {D. Huber and O. Carmichael and M. Hebert},
	year = {2000},
	keywords = {registration},
	pages = {891--897}
},

@article{kuipers_spatial_2000,
	title = {The Spatial Semantic Hierarchy},
	volume = {119},
	issn = {0004-3702},
	lccn = {0513},
	url = {http://dx.doi.org/10.1016/S0004-3702(00)00017-5},
	abstract = {The Spatial Semantic Hierarchy is a model of knowledge of large-scale space
consisting of multiple interacting representations, both qualitative and
quantitative. The {SSH} is inspired by the properties of the human cognitive map,
and is intended to serve both as a model of the human cognitive map and as a
method for robot exploration and map-building. The multiple levels of the {SSH}
express states of partial knowledge, and thus enable the human or robotic agent to
deal robustly with uncertainty during both learning and problem-solving. The
control level represents useful patterns of sensorimotor interaction with the
world in the form of trajectory-following and hill-climbing control laws leading
to locally distinctive states. Local geometric maps in local frames of reference
can be constructed at the control level to serve as observers for control laws in
particular neighborhoods. The causal level abstracts continuous behavior among
distinctive states into a discrete model consisting of states linked by
actions. The topological level introduces the external ontology of places, paths
and regions by abduction to explain the observed pattern of states and actions at
the causal level. Quantitative knowledge at the control, causal and topological
levels supports a ``patchwork map'' of local geometric frames of reference linked by
causal and topological connections. The patchwork map can be merged into a single
global frame of reference at the metrical level when sufficient information and
computational resources are available. We describe the assumptions and guarantees
behind the generality of the {SSH} across environments and sensorimotor
systems. Evidence is presented from several partial implementations of the {SSH} on
simulated and physical robots.},
	number = {1-2},
	journal = {Artificial Intelligence},
	author = {Benjamin Kuipers},
	year = {2000},
	keywords = {ai, architecture, cognitive, cognitive map, maps, robotics, semantics, slam, spatial},
	pages = {191--233},
	annote = {{\textless}p{\textgreater}cited by 177{\textless}/p{\textgreater}}
},

@misc{rodrigues_fast_2000,
	title = {Fast segmentation of {3D} data using an octree},
	lccn = {0009},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.7.8564},
	abstract = {The algorithm developed uses an octree pyramid in which noise is reduced at the expense of the spatial resolution. At a certain level an unsupervised clustering without spatial connectivity constraints is applied. After the classification, isolated voxels and insignificant regions are removed by assigning them to their neighbours. The spatial resolution is then increased by the downprojection of the regions, level by level. At each level the uncertainty of the boundary voxels is minimised by a...},
	author = {J Rodrigues and {RE} Loke and {JMH} du Buf},
	year = {2000},
	keywords = {3d, doctorate, segmentation}
},

@inproceedings{thrun_real-time_2000,
	address = {San Francisco, {CA,} {USA}},
	title = {A real-time algorithm for mobile robot mapping with applications to multi-robot and {3D} mapping},
	lccn = {0482},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=844077},
	doi = {10.1109/ROBOT.2000.844077},
	abstract = {We present an incremental method for concurrent mapping and localization for mobile robots equipped with {2D} laser range finders. The approach uses a fast implementation of scan-matching for mapping, paired with a sample-based probabilistic method for localization. Compact {3D} maps are generated using a multi-resolution approach adopted from the computer graphics literature, fed by data from a dual laser system. Our approach builds {3D} maps of large, cyclic environments in real-time, and it is robust. Experimental results illustrate that accurate maps of large, cyclic environments can be generated even in the absence of any odometric data},
	booktitle = {Proceedings 2000 {ICRA.} Millennium Conference. {IEEE} International Conference on Robotics and Automation. Symposia Proceedings {(Cat.} {No.00CH37065)}},
	author = {S. Thrun and W. Burgard and D. Fox},
	year = {2000},
	keywords = {slam},
	pages = {321--328}
},

@article{murray_using_2000,
	title = {Using {Real-Time} Stereo Vision for Mobile Robot Navigation},
	volume = {8},
	issn = {09295593},
	lccn = {0207},
	url = {http://dx.doi.org/10.1023/A:1008987612352},
	abstract = {This paper describes a working vision-based mobile robot that navigates and autonomously explores its environment while building occupancy grid maps of the environment. We present a method for reducing stereo vision disparity images to two-dimensional map information. Stereo vision has several attributes that set it apart from other sensors more commonly used for occupancy grid mapping. We discuss these attributes, the errors that some of them create, and how to overcome them. We reduce errors by segmenting disparity images based on continuous disparity surfaces to reject spikes caused by stereo mismatches. Stereo vision processing and map updates are done at 5 Hz and the robot moves at speeds of 300 cm/s.},
	number = {2},
	journal = {Autonomous Robots},
	author = {Don Murray and James Little},
	month = apr,
	year = {2000},
	keywords = {occupancy grid, stereo},
	pages = {161--171}
},

@article{pulli_surface_2000,
	title = {Surface Reconstruction and Display from Range and Color Data},
	volume = {62},
	issn = {1524-0703},
	lccn = {0061},
	url = {http://www.sciencedirect.com.ezproxy.tntech.edu/science/article/B6WG3-45F4N4B-H/2/c46716b3a5c57be4a0651d40b7cd2cf9},
	doi = {10.1006/gmod.1999.0519},
	abstract = {This paper addresses the problem of scanning both the color and geometry of real objects and displaying realistic images of the scanned objects from arbitrary viewpoints. We describe a complete system that uses a stereo camera setup with active lighting to scan the object surface geometry and color. Scans expressed in sensor coordinates are registered into a single object-centered coordinate system by aligning both the color and geometry where the scans overlap. The range data are integrated into a surface model using a robust hierarchical space carving method. The fit of the resulting approximate mesh to data is improved and the mesh structure is simplified using mesh optimization methods. In addition, a method for view-dependent texturing of the reconstructed surfaces is described. The method projects the color data from the input images onto the surface model and blends the various images depending on the location of the viewpoint and other factors such as surface orientation.},
	number = {3},
	journal = {Graphical Models},
	author = {Kari Pulli and Linda G. Shapiro},
	month = may,
	year = {2000},
	keywords = {graphical models, surface fitting},
	pages = {165--201}
},

@inproceedings{bandera_hierarchical_2001,
	address = {Maui, {HI,} {USA}},
	title = {An hierarchical approach to grid-based and topological maps integration for autonomous indoor navigation},
	lccn = {0010},
	url = {http://dx.doi.org/10.1109/IROS.2001.976280},
	abstract = {Research in mobile robot navigation has been based in approaches
that integrate the metric and topological paradigms for mapping indoor
environments. While metric methods produce accurate environment
representations, their huge data volume and time complexity often
prohibits efficient planning in large-scale indoor environments. On the
other hand, topological maps can be used in a more efficient way, but
accurate and coherent topological maps are often difficult to learn and
maintain in large-scale environments. The paper describes an approach
that integrates both paradigms: metric and topological. The metric map
is learnt using a very simple scheme based on the works of Moravec and
Elfes (1988). Then, a topological map is generated on top of the metric
map by using a hierarchical structure. The main advantage of the
proposed structure is that the partitioning of the metric map into
coherent regions is achieved in an unsupervised manner with a low
computational time. The paper gives results for autonomous exploration,
mapping and planning of a Nomad200 mobile robot in large indoor
environments},
	author = {A Bandera and C Urdiales and F Sandoval},
	year = {2001},
	keywords = {hybrid, slam, tslam},
	pages = {883--888}
},

@inproceedings{carr_reconstruction_2001,
	title = {Reconstruction and representation of {3D} objects with radial basis functions},
	isbn = {{1-58113-374-X}},
	lccn = {0928},
	abstract = {We use polyharmonic Radial Basis Functions {(RBFs)} to reconstruct smooth, manifold surfaces from point-cloud data and to repair incomplete meshes. An object's surface is defined implicitly as the zero set of an {RBF} fitted to the given surface data. Fast methods for fitting and evaluating {RBFs} allow us to model large data sets, consisting of millions of surface points, by a single {RBF} � previously an impossible task. A greedy algorithm in the fitting process reduces the number of {RBF} centers required to represent a surface and results in significant compression and further computational advantages. The energy-minimisation characterisation of polyharmonic splines result in a �smoothest� interpolant. This scale-independent characterisation is well-suited to reconstructing surfaces from non-uniformly sampled data. Holes are smoothly filled and surfaces smoothly extrapolated. We use a non-interpolating approximation when the data is noisy. The functional representation is in effect a solid model, which means that gradients and surface normals can be determined analytically. This helps generate uniform meshes and we show that the {RBF} representation has advantages for mesh simplification and remeshing applications. Results are presented for real-world rangefinder data.},
	booktitle = {Proceedings of the 28th annual conference on Computer graphics and interactive techniques},
	publisher = {{ACM}},
	author = {J. C. Carr and R. K. Beatson and J. B. Cherrie and T. J. Mitchell and W. R. Fright and B. C. {McCallum} and T. R. Evans},
	year = {2001},
	keywords = {surface fitting},
	pages = {67--76}
},

@article{choset_topological_2001,
	title = {Topological simultaneous localization and mapping {(SLAM):} toward exact localization without explicit localization Topological simultaneous localization and mapping {(SLAM):} toward exact localization without explicit localization},
	volume = {17},
	lccn = {0000},
	abstract = {This paper presents a new method for simultaneous localization and mapping that exploits the topology of the robot's free space to localize the robot on a partially constructed map. The topology of the environment is encoded in a topological map; the particular topological map used in this paper is the generalized Voronoi graph {(GVG),} which also encodes some metric information about the robot's environment, as well. In this paper, we present the low-level control laws that generate the {GVG} edges and nodes, thereby allowing for exploration of an unknown space. With these prescribed control laws, the {GVG} can be viewed as an arbitrator for a hybrid control system that determines when to invoke a particular low-level controller from a set of controllers all working toward the high-level capability of mobile robot exploration. The main contribution, however, is using the graph structure of the {GVG,} via a graph matching process, to localize the robot. Experimental results verify the described work},
	number = {2},
	journal = {Robotics and Automation, {IEEE} Transactions on},
	author = {H Choset and H Choset and K Nagatani},
	year = {2001},
	keywords = {articles, computational, control, found, free, geometry, graph, localization, map, matching, mobile, motion, navigation, path, pattern, planning, position, robot, robots, simultaneous, space, thesis, topological, topology, voronoi},
	pages = {125--137},
	annote = {{1042-296X}},
	annote = {Topological simultaneous localization and mapping {(SLAM):} toward exact localization without explicit localization
Topological simultaneous localization and mapping {(SLAM):} toward exact localization without explicit localization}
},

@article{faber_pros_2001,
	title = {Pros and Cons of Euclidean Fitting},
	volume = {2191},
	lccn = {0013},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.22.7178},
	abstract = {The purpose of this paper is to discuss pros and cons of fitting general curves and surfaces to {2D} and {3D} edge and range data using the Euclidean distance. In the past researchers have used approximate distance functions rather than the Euclidean distance. But the main disadvantage of the Euclidean fitting, computational cost, has become less important due to rising computing speed. Experiments with the real Euclidean distance show the limitations of suggested approximations like the Algebraic...},
	journal = {Lecture Notes in Computer Science},
	author = {P Faber and {RB} Fisher},
	year = {2001},
	keywords = {plane fitting},
	pages = {414--??}
},

@inproceedings{gumhold_feature_2001,
	title = {Feature Extraction from Point Clouds},
	lccn = {0105},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.12.913},
	abstract = {This paper describes a new method to extract feature lines directly from a surface point cloud. No surface reconstruction is needed in advance, only the inexpensive computation of a neighbor graph connecting nearby points.},
	booktitle = {In Proceedings of the 10 th International Meshing Roundtable},
	author = {Stefan Gumhold and Xinlong Wang and Rob Macleod},
	year = {2001},
	keywords = {line, shape},
	pages = {293--305}
},

@inproceedings{liu_using_2001,
	address = {San Francisco, {CA,} {USA}},
	series = {{ICML} '01},
	title = {Using {EM} to Learn {3D} Models of Indoor Environments with Mobile Robots},
	isbn = {1-55860-778-1},
	lccn = {0160},
	url = {http://portal.acm.org/citation.cfm?id=645530.655822},
	abstract = {This paper describes an algorithm for generating
compact {3D} models of indoor environments with
mobile robots. Our algorithm employs the ex-
pectation maximization algorithm to fit a low-
complexity planar model to {3D} data collected
by range finders and a panoramic camera. The
complexity of the model is determined during
model fitting, by incrementally adding and re-
moving surfaces. In a final post-processing step,
measurements are converted into polygons and
projected onto the surface model where possible.
Empirical results obtained with a mobile robot
illustrate that high-resolution models can be ac-
quired in reasonable time.},
	booktitle = {Proceedings of the Eighteenth International Conference on Machine Learning},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Yufeng Liu and Rosemary Emery and Deepayan Chakrabarti and Wolfram Burgard and Sebastian Thrun},
	year = {2001},
	keywords = {{EM,} plane fitting},
	pages = {329�336},
	annote = {{\textless}p{\textgreater}using sets of polyhedra instead of grids{\textless}/p{\textgreater}}
},

@article{duckett_mobile_2001,
	title = {Mobile robot self-localisation using occupancy histograms and a mixture of Gaussian location hypotheses},
	volume = {34},
	issn = {09218890},
	lccn = {0023},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0921889000001160},
	doi = {10.1016/S0921-8890(00)00116-0},
	abstract = {The topic of mobile robot self-localisation is often divided into the sub-problems of global localisation and position tracking. Both are now well understood individually, but few mobile robots can deal simultaneously with the two problems in large, complex environments. In this paper, we present a unified approach to global localisation and position tracking which is based on a topological map augmented with metric information. This method combines a new scan matching technique, using histograms extracted from local occupancy grids, with an efficient algorithm for tracking multiple location hypotheses over time. The method was validated with experiments in a series of real world environments, including its integration into a complete navigating robot. The results show that the robot can localise itself reliably in large, indoor environments using minimal computational resources.},
	number = {2-3},
	journal = {Robotics and Autonomous Systems},
	author = {T Duckett},
	year = {2001},
	keywords = {localization, multi-hypothesis, occupancy grid},
	pages = {117--129}
},

@inproceedings{arbuckle_temporal_2002,
	address = {Lausanne, Switzerland},
	title = {Temporal occupancy grids: a method for classifying the spatio-temporal properties of the environment},
	lccn = {0015},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1041424},
	doi = {10.1109/IRDS.2002.1041424},
	abstract = {This paper introduces the concept of a temporal occupancy grid as a method for modeling and classifying spatial areas according to the time properties of their occupancy. The method extends the idea of occupancy grids by considering occupancy over a number of different timescales. This paper presents the basic formalism and its implementation using planar laser rangefinders. It includes the results of a number of validation experiments, and an experiment in which we demonstrate the ability to locate doors in a real-world setting.},
	booktitle = {{IEEE/RSJ} International Conference on Intelligent Robots and System},
	author = {D. Arbuckle and A. Howard and M. Mataric},
	year = {2002},
	keywords = {dynamic, occupancy grid, spatiotemporal},
	pages = {409--414}
},

@inproceedings{biswas_towards_2002,
	address = {Lausanne, Switzerland},
	title = {Towards object mapping in non-stationary environments with mobile robots},
	isbn = {0-7803-7398-7},
	lccn = {0036},
	url = {http://dx.doi.org/10.1109/IRDS.2002.1041523},
	abstract = {We propose an occupancy grid mapping algorithm for mobile robots operating in environments where objects change their locations over time. Our approach uses a straightforward map differencing technique to detect changes in an environment over time. It employs the expectation maximization algorithm to learn models of non-stationary objects, and to determine the location of such objects in individual occupancy grid maps built at different points in time. By combining data from multiple maps when learning object models, the resulting models have higher fidelity than could be obtained from any single map. A Bayesian complexity measure is applied to determine the number of different objects in the model, making it possible to apply the approach to situations where not all objects are present at all times in the map.},
	booktitle = {{IEEE/RSJ} International Conference on Intelligent Robots and System},
	publisher = {{IEEE}},
	author = {R Biswas and B Limketkai and S Sanner and S Thrun},
	year = {2002},
	keywords = {dynamic\_map, expectation\_maximization, map, occupancy grid, virtual\_agents},
	pages = {1014--1019},
	annote = {{\textless}p{\textgreater}according to thrun, this is a good paper that uses a non-grid based world representation (collection of lines). This is considered one of the "fleshed-out" papers, along with:{\textless}/p{\textgreater}
{\textless}p{\textgreater}[58] Y. Liu, R. Emery, D. Chakrabarti, W. Burgard, and S. Thrun. Using {EM} to learn {3D} models with mobile robots. In Proceedings of the International Conference on Machine Learning {(ICML),} 2001{\textless}br /{\textgreater}[61] C. Martin and S. Thrun. Online acquisition of compact volumetric maps with mobile robots. In {IEEE} International Conference on Robotics and Automation {(ICRA),} Washington, {DC,} 2002. {ICRA.{\textless}/p{\textgreater}}
{{\textless}p{\textgreater}He} says it originates from{\textless}/p{\textgreater}
{\textless}p{\textgreater}[15] R. Chatila and {J.-P.} Laumond. Position referencing and consistent world modeling for mobile robots. In Proceedings of the 1985 {IEEE} International Conference on Robotics and Automation, 1985.{\textless}/p{\textgreater}},
	annote = {� Most maps assume the world is static, even then the problem can be very hard
� Occupancy grid mapping algorithm called {ROMA}
� Objects need to move sufficiently slowly that they appear to be static at any time
� Compares different occupancy grids and detects changes before modelling the objects in this}
},

@misc{christian_martin_online_2002,
	title = {Online acquisition of compact volumetric maps with mobile robots},
	lccn = {0023},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=?doi=10.1.1.19.7603},
	abstract = {This paper describes an online algorithm for generating
compact {3D} maps of mobile robot environments. Maps generated
by our approach consist of small numbers of planar surfaces,
which are augmented by fine-grained polygons for non-flat
environmental features. Our approach builds on the
expectation maximization {(EM)} algorithm, but develops a new,
incremental version that can be executed in real-time.
Experimental results obtained in corridor-type environments
illustrate that compact and accurate maps can be acquired in
real-time, from range and camera data collected by a mobile
robot. 1},
	author = {Christian Martin and Sebastian Thrun},
	year = {2002},
	keywords = {plane fitting},
	annote = {{CiteSeerX} - Scientific Literature Digital Library and Search
Engine [http://citeseerx.ist.psu.edu/oai2] {(United} States)},
	annote = {{\textless}p{\textgreater}sets of polyhedra for describing geometry of environment,{\textless}/p{\textgreater}}
},

@article{desouza_vision_2002,
	title = {Vision for mobile robot navigation: a survey},
	volume = {24},
	issn = {01628828},
	lccn = {0524},
	url = {http://dx.doi.org/10.1109/34.982903},
	abstract = {Surveys the developments of the last 20 years in the area of
vision for mobile robot navigation. Two major components of the paper
deal with indoor navigation and outdoor navigation. For each component,
we have further subdivided our treatment of the subject on the basis of
structured and unstructured environments. For indoor robots in
structured environments, we have dealt separately with the cases of
geometrical and topological models of space. For unstructured
environments, we have discussed the cases of navigation using optical
flows, using methods from the appearance-based paradigm, and by
recognition of specific objects in the environment},
	number = {2},
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {{GN} Desouza and {AC} Kak},
	year = {2002},
	keywords = {based, image, localization, survey, vision},
	pages = {237--267}
},

@article{elfes_using_2002,
	title = {Using occupancy grids for mobile robot perception and navigation},
	volume = {22},
	lccn = {0791},
	url = {http://dx.doi.org/10.1109/2.30720},
	abstract = {An approach to robot perception and world modeling that uses a probabilistic tesselated representation of spatial information called the occupancy grid is reviewed. The occupancy grid is a multidimensional random field that maintains stochastic estimates of the occupancy state of the cells in a spatial lattice. To construct a sensor-derived map of the robot's world, the cell state estimates are obtained by interpreting the incoming range readings using probabilistic sensor models. Bayesian estimation procedures allow the incremental updating of the occupancy grid, using readings taken from several sensors over multiple points of view. The use of occupancy grids from mapping and for navigation is examined. Operations on occupancy grids and extensions of the occupancy grid framework are briefly considered},
	number = {6},
	journal = {Computer},
	author = {A Elfes},
	year = {2002},
	keywords = {localization, occupancy},
	pages = {46--57}
},

@phdthesis{ellore_dynamically_2002,
	title = {Dynamically expanding occupancy grids},
	lccn = {0004},
	url = {http://etd.lib.ttu.edu/theses/available/etd-07312008-31295018555556/},
	abstract = {Previous evidence grid based robot architectures have used static arrays for representing the environment map. We present a method for dynamically sizing the environment map. Basically, the mobile robot explores and as it explores the map grows in a non-rectilinear fashion. Thus, the area formed as a result of this method may not be a rectangular structure. This approach is flexible and imposes no size or shape constraints on the Occupancy Grid. We are interested only in mapping here, but the architecture we are proposing can also be used for localization and navigation. This method should work well with Markov and Monte Carlo Localization methods, and will have significant advantages over static Occupancy Grid representation methods.},
	school = {Texas Tech},
	author = {Bharani Kumar Ellore},
	year = {2002},
	keywords = {dynamically expanding occupancy grid, occupancy grid, star}
},

@inproceedings{gartshore_incremental_2002,
	address = {Singapore},
	title = {Incremental map building using an occupancy grid for an autonomous monocular robot},
	lccn = {0009},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1238494},
	doi = {10.1109/ICARCV.2002.1238494},
	abstract = {This paper centres on the problem of estimating the location of features in the environment within a map building framework for a mobile robot with a single camera. Most of the existing approaches to feature location from vision data have been developed by a combination of matching and geometric triangulation. Triangulation is used to obtain equations of reconstruction or structure-from-motion. In contrast, our approach avoids the matching problem by looking for evidence of the location of features on an occupancy grid. Similar to map building via sonar methods, we gather evidence of the trace of potential position of features. Thus, maxima in the occupancy grid define robust feature positions. Preliminary results show that our approach can obtain accurate results in real time. The approach can handle noise in the feature detection and in the robot position. The integration of vision data over time reduces the covariance of the estimates.},
	booktitle = {7th International Conference on Control, Automation, Robotics and Vision, 2002. {ICARCV} 2002.},
	author = {R. Gartshore and A. Aguado and C. Galambos},
	year = {2002},
	keywords = {occupancy grid},
	pages = {613--618}
},

@inproceedings{hahnel_map_2002,
	address = {Lausanne, Switzerland},
	title = {Map building with mobile robots in populated environments},
	lccn = {0146},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1041439},
	doi = {10.1109/IRDS.2002.1041439},
	abstract = {The problem of generating maps with mobile robots has received considerable attention over the past years. However, most of the approaches assume that the environment is static during the data-acquisition phase. In this paper we consider the problem of creating maps with mobile robots in populated environments. Our approach uses a probabilistic method to track multiple people and to incorporate the results of the tracking technique into the mapping process. The resulting maps are more accurate since corrupted readings are treated accordingly during the matching phase and since the number of spurious objects in the resulting maps is reduced. Our approach has been implemented and tested on real robot systems in indoor and outdoor scenarios. We present several experiments illustrating the capabilities of our approach to generate accurate {2D} and {3D} maps.},
	booktitle = {{IEEE/RSJ} International Conference on Intelligent Robots and System},
	author = {D. Hahnel and D. Schulz and W. Burgard},
	year = {2002},
	keywords = {3d, dynamic},
	pages = {496--501}
},

@inproceedings{kuipers_bootstrap_2002,
	address = {Edmonton, Alberta, Canada},
	title = {Bootstrap learning for place recognition},
	isbn = {0-262-51129-0},
	lccn = {0106},
	url = {http://portal.acm.org/citation.cfm?id=777122},
	abstract = {We present a method whereby a robot can learn to recognize places with high accuracy, in spite of perceptual aliasing (different places appear the same) and image variability (the same place appears differently). The first step in learning place recognition restricts attention to distinctive states identified by the map-learning algorithm, and eliminates image variability by unsupervised learning of clusters of similar sensory images. The clusters define views associated with distinctive states, often increasing perceptual aliasing. The second step eliminates perceptual aliasing by building a causal/topological map and using history information gathered during exploration to disambiguate distinctive states. The third step uses the labeled images for supervised learning of direct associations from sensory images to distinctive states. We evaluate the method using a physical mobile robot in two environments, showing high recognition rates in spite of large amounts of perceptual aliasing.},
	booktitle = {Eighteenth national conference on Artificial intelligence},
	publisher = {American Association for Artificial Intelligence},
	author = {Benjamin Kuipers and Patrick Beeson},
	year = {2002},
	keywords = {classification, cognitive map},
	pages = {174--180}
},

@inproceedings{montemerlo_fastslam:_2002,
	title = {{FastSLAM:} A Factored Solution to the Simultaneous Localization and Mapping Problem},
	lccn = {0880},
	abstract = {This article provides a comprehensive description of {FastSLAM,} a new family of algorithms for the
simultaneous localization and mapping problem, which specifically address hard data association
problems. The algorithm uses a particle filter for sampling robot paths, and extended Kalman filters
for representing maps acquired by the vehicle. This article presents two variants of this algorithm, the
original algorithm along with a more recent variant that provides improved performance in certain
operating regimes. In addition to a mathematical derivation of the new algorithm, we present a proof
of convergence and experimental results on its performance on real-world data.},
	booktitle = {{AAAI} National Conference on Artificial Intelligence},
	publisher = {{AAAI} Press},
	author = {M Montemerlo and S Thrun and D Koller and B Wegbreit},
	year = {2002},
	keywords = {fastslam, slam},
	annote = {{\textless}p{\textgreater}this is one of the important fast slam papers that uses a "tree representation" to do slam{\textless}/p{\textgreater}}
},

@inproceedings{pauly_efficient_2002,
	address = {Boston, {MA,} {USA}},
	title = {Efficient simplification of point-sampled surfaces},
	lccn = {0413},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1183771},
	doi = {10.1109/VISUAL.2002.1183771},
	abstract = {We introduce, analyze and quantitatively compare a number of surface simplification methods for point-sampled geometry. We have implemented incremental and hierarchical clustering, iterative simplification, and particle simulation algorithms to create approximations of point-based models with lower sampling density. All these methods work directly on the point cloud, requiring no intermediate tesselation. We show how local variation estimation and quadric error metrics can be employed to diminish the approximation error and concentrate more samples in regions of high curvature. To compare the quality of the simplified surfaces, we have designed a new method for computing numerical and visual error estimates for point-sampled surfaces. Our algorithms are fast, easy to implement, and create high-quality surface approximations, clearly demonstrating the effectiveness of point-based surface simplification.},
	booktitle = {{IEEE} Visualization, 2002. {VIS} 2002.},
	author = {M. Pauly and M. Gross and {L.P.} Kobbelt},
	year = {2002},
	keywords = {surface fitting},
	pages = {163--170}
},

@inproceedings{rofer_using_2002,
	address = {Lausanne, Switzerland},
	title = {Using histogram correlation to create consistent laser scan maps},
	lccn = {0058},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1041461},
	doi = {10.1109/IRDS.2002.1041461},
	abstract = {The paper presents an approach to generate consistent maps in real-time using a laser range sensor. Its application scenario is the Bremen Autonomous Wheelchair {"Rolland"} that is developed as an autonomous transport vehicle for hospitals. The paper consists of two parts. First, a laser scan matching method is presented that improves an algorithm originally proposed by Weiss et al. (1994) in several aspects. Then, a mapping approach is introduced that is based on the scan matching method. Using a laser scanner mounted on the wheelchair, it generates consistent maps, i.e. maps that do not have discontinuities resulting from the accumulation of errors in the mapping process. As such accumulations cannot be avoided, the resulting errors are corrected whenever the wheelchair returns to areas already mapped An important property of the presented approach is its real-time capability. The mapping is performed on the fly and, thus, the resulting maps can immediately be employed for self-localization.},
	booktitle = {{IEEE/RSJ} International Conference on Intelligent Robots and System},
	author = {T. Rofer},
	year = {2002},
	keywords = {registration},
	pages = {625--630}
},

@misc{thrun_robotic_2002,
	title = {Robotic mapping: A survey},
	lccn = {0868},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.9.7791},
	abstract = {This article provides a comprehensive introduction into the field of robotic mapping, with a focus on indoor
mapping. It describes and compares various probabilistic techniques, as they are presently being applied
to a vast array of mobile robot mapping problems. The history of robotic mapping is also described, along
with an extensive list of open research problems.},
	author = {S Thrun},
	year = {2002},
	keywords = {maps, navigation, star, survey},
	annote = {{{\textless}p{\textgreater}-FASTSlam,} [67],[29,71], uses efficient "tree representations"{\textless}br /{\textgreater}{\textless}br /{\textgreater}*[29] A Doucet, N. de Freitas, K. Murphy, and S. Russell. {Rao-Blackwellised} particle ?ltering for dynamic Bayesian networks. In Proceedings of the Sixteenth Conference on Uncertainty in Arti?cial Intelligence , pages 176�183, Stanford, 2000.{\textless}br /{\textgreater}**[67] M. Montemerlo, S. Thrun, D. Koller, and B. Wegbreit. {FastSLAM:} A factored solution to the simultaneous localization and mapping problem. Submitted for publication, 2002{\textless}br /{\textgreater}*[71] {K.Murphy} and S. Russell. {Rao-Blackwellized} particle ?ltering for dynamic Bayesian networks. In A. Doucet, N. de Freitas, and Gordon. N., editors, Sequential Monte Carlo Methods in Practice, pages 499�516. Springer Verlag, 2001.{\textless}br /{\textgreater}{\textless}br {/{\textgreater}Early} Stuff{\textless}br /{\textgreater}-one of earliest is the occupancy grid mapping algorithm [31, 32, 69] (80's), Elfes and Moravec{\textless}br /{\textgreater}{\textless}br /{\textgreater}*[31] A. Elfes. Sonar-based real-world mapping and navigation. {IEEE} Journal of Robotics and Automation, {RA-3(3):249�265,} June 1987.{\textless}br /{\textgreater}*[32] A. Elfes. Occupancy Grids: A Probabilistic Framework for Robot Perception and Navigation. {PhD} thesis, Department of Electrical and Computer Engineering, Carnegie Mellon University, 1989.{\textless}br /{\textgreater}*[69] H. P. Moravec. Sensor fusion in certainty grids for mobile robots. {AI} Magazine, 9(2):61�74, 1988.{\textless}br /{\textgreater}{\textless}br /{\textgreater}-[15] sets of polyhedra for describing geometry of environment, Chatila Laumond, repr {2D} maps as a collection of lines rather than grids, fleshed out in [6, 58, 61]{\textless}br /{\textgreater}{\textless}br /{\textgreater}*[15] R. Chatila and {J.-P.} Laumond. Position referencing and consistent world modeling for mobile robots. In Proceedings of the 1985 {IEEE} International Conference on Robotics and Automation, 1985.{\textless}br /{\textgreater}*[6] R. Biswas, B. Limketkai, S. Sanner, and S. Thrun. Towards object mapping in dynamic environments with mobile robots. Submitted for publication, 2002{\textless}br /{\textgreater}*[58] Y. Liu, R. Emery, D. Chakrabarti, W. Burgard, and S. Thrun. Using {EM} to learn {3D} models with mobile robots. In Proceedings of the International Conference on Machine Learning {(ICML),} 2001{\textless}br /{\textgreater}*[61] C. Martin and S. Thrun. Online acquisition of compact volumetric maps with mobile robots. In {IEEE} International Conference on Robotics and Automation {(ICRA),} Washington, {DC,} 2002. {ICRA.{\textless}br} /{\textgreater}{\textless}br /{\textgreater}-seminal {SLAM:} smith, self, cheeseman [91,92], adapting to large \# of raw range measurements, [60]{\textless}br /{\textgreater}{\textless}br /{\textgreater}*[60] F. Lu and E. Milios. Globally consistent range scan alignment for environment mapping. Autonomous Robots, 4:333�349, 1997.{\textless}br /{\textgreater}*[91] R. Smith, M. Self, and P. Cheeseman. Estimating uncertain spatial relationships in robotics. In {I.J.} Cox and {G.T.} Wilfong, editors, Autonomous Robot Vehnicles, pages 167�193. {Springer-Verlag,} 1990.{\textless}br /{\textgreater}*[92] R. C. Smith and P. Cheeseman. On the representation and estimation of spatial uncertainty. Technical Report {TR} 4760 \&amp; 7239, {SRI,} 1985.{\textless}br /{\textgreater}{\textless}br /{\textgreater}-[24] original em paper{\textless}br /{\textgreater}{\textless}br /{\textgreater}[24] {A.P.} Dempster, {A.N.} Laird, and {D.B.} Rubin. Maximum likelihood from incomplete data via the {EM} algorithm. Journal of the Royal Statistical Society, Series B, 39(1):1�38, 1977{\textless}br /{\textgreater}{\textless}br /{\textgreater}{\textless}br /{\textgreater}{\textless}br {/{\textgreater}Summary:{\textless}br} /{\textgreater}{\textless}br {/{\textgreater}Mapping} must be construed, fundamentally, as a probabilistic problem, due to so much error present in measurements. Thus, posteriors or multiple "best guesses" must be kept around as sensor information come in, so that in light of new knowledge, old ideas can be reevaluated for consistency and truth. Author makes point to say that robot-centric mapping is not actually used for much of note. Thus, the robot must be able to project its measurements in the world frame and thus have a concept of history and global pose. Probabilistic really means Bayes Filter, as all the map strategies that are used and work well utilize some form of Bayes filter (particle filter, kalman filter, {EM).{\textless}br} /{\textgreater}{\textless}br {/{\textgreater}He} makes the dichotomy between topological and metric, but then reneges on this idea because, as he says, topological is really just a coarser grained metric, as topological also contains metric information.{\textless}/p{\textgreater}}
},

@inproceedings{unnikrishnan_constrained_2002,
	address = {Lausanne, Switzerland},
	title = {A constrained optimization approach to globally consistent mapping},
	lccn = {0014},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1041450},
	doi = {10.1109/IRDS.2002.1041450},
	abstract = {Mobile robot localization from large-scale appearance mosaics has been showing increasing promise as a low-cost, high-performance and infrastructure free solution to vehicle-guidance in man-made environments. The generation of the globally consistent high-resolution mosaics crucial to this procedure suffers from the same problem of loop-closure in cyclic environments that is commonly encountered in all map-building procedures. This paper presents a batch solution to the problem of reliably generating globally consistent mosaics at low computational cost, that simultaneously exploits the topological constraints among the observations and minimizes the total residual in observed features. An extension to a general scalable framework that facilitates an incremental online mapping strategy is also presented, along with results using simulated data and from real indoor environments.},
	booktitle = {{IEEE/RSJ} International Conference on Intelligent Robots and System},
	author = {R. Unnikrishnan and A. Kelly},
	year = {2002},
	keywords = {mosaics},
	pages = {564--569}
},

@article{woo_new_2002,
	title = {A new segmentation method for point cloud data},
	volume = {42},
	issn = {08906955},
	lccn = {0087},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0890695501001201},
	doi = {10.1016/S0890-6955(01)00120-1},
	abstract = {In the process of generating a surface model from point cloud data, a segmentation that extracts the edges and partitions the three-dimensional {(3D)} point data is necessary and plays an important role in fitting surface patches and applying the scan data to the manufacturing process. Many researchers have tried to develop segmentation methods by fitting curves or surfaces in order to extract geometric information, such as edges and smooth regions, from the scan data. However, the surface- or curve-fitting tasks take a long time and it is also difficult to extract the exact edge points because the scan data consist of discrete points and the edge points are not always included in these data. In this research, a new method for segmenting the point cloud data is proposed. The proposed algorithm uses the octree-based {3D-grid} method to handle a large amount of unordered sets of point data. The final {3D-grids} are constructed through a refinement process and iterative subdivisioning of cells using the normal values of points. This {3D-grid} method enables us to extract edge-neighborhood points while considering the geometric shape of a part. The proposed method is applied to two quadric models and the results are discussed.},
	number = {2},
	journal = {International Journal of Machine Tools and Manufacture},
	author = {H Woo},
	year = {2002},
	keywords = {3d, octree, segmentation},
	pages = {167--178}
},

@article{olson_selecting_2002,
	title = {Selecting Landmarks for Localization in Natural Terrain},
	volume = {12},
	issn = {0929-5593},
	lccn = {0021},
	url = {http://dx.doi.org/10.1023/A:1014053611681},
	abstract = {We describe techniques to optimally select landmarks for performing mobile robot localization by matching terrain maps. The method is based upon a maximum-likelihood robot localization algorithm that efficiently searches the space of possible robot positions. We use a sensor error model to estimate a probability distribution over the terrain expected to be seen from the current robot position. The estimated distribution is compared to a previously generated map of the terrain and the optimal landmark is selected by minimizing the predicted uncertainty in the localization. This approach has been applied to the generation of a sensor uncertainty field that can be used to plan a robot's movements. Experiments indicate that landmark selection improves not only the localization uncertainty, but also the likelihood of success. Examples of landmark selection are given using real and synthetic data.},
	number = {2},
	journal = {Autonomous Robots},
	author = {Clark F. Olson},
	month = mar,
	year = {2002},
	keywords = {Computer Science, slam},
	pages = {201--210}
},

@inproceedings{feddema_rapid_2002,
	address = {Albuquerque, {NM,} {USA}},
	title = {Rapid world modeling: fitting range data to geometric primitives},
	lccn = {0020},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=606712},
	doi = {10.1109/ROBOT.1997.606712},
	abstract = {World modeling is defined as the process of creating a numerical geometric model of a real world environment or workspace. This model is often used in robotics to plan robot motions which perform a task while avoiding obstacles. In many applications where the world model does not exist ahead of time, structured lighting, laser range finders, and even acoustical sensors have been used to create three dimensional maps of the environment. These maps consist of thousands of range points which are difficult to handle and interpret. This paper presents a least squares technique for fitting range data to planar and quadric surfaces, including cylinders and ellipsoids. Once fit to these primitive surfaces, the amount of data associated with a surface is greatly reduced up to three orders of magnitude, thus allowing for more rapid handling and analysis of world data},
	booktitle = {Proceedings of International Conference on Robotics and Automation},
	author = {{J.T.} Feddema and {C.Q.} Little},
	month = aug,
	year = {2002},
	keywords = {cylinders, geometric fitting, plane fitting, star},
	pages = {2807--2812}
},

@inproceedings{hebert_decoupling_2002,
	address = {Minneapolis, {MN,} {USA}},
	title = {Decoupling odometry and exteroceptive perception in building a global world map of a mobile robot: the use of local maps},
	lccn = {0024},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=503865},
	doi = {10.1109/ROBOT.1996.503865},
	abstract = {A mobile robot navigates in an environment and incrementally builds a map while locating itself. The quality of the map depends on the sensor models. Due to the difficulty of defining a stochastic odometric model, the classical approach based on Kalman filtering is revisited in order to decouple the information provided by the odometric sensor and exteroceptive sensors. The proposed approach is based on the observation and fusion of geometric relationships between objects. These relationships are represented in local maps and related in a global map where odometric information is exploited. The resulting local maps are invariant with respect to biases introduced in the robot location (position and orientation) due to sliding for instance. Experimental results on real data compare both the classical and the proposed approach},
	booktitle = {Proceedings of {IEEE} International Conference on Robotics and Automation},
	author = {P. Hebert and S. {Betge-Brezetz} and R. Chatila},
	month = aug,
	year = {2002},
	keywords = {maps, star},
	pages = {757--764}
},

@inproceedings{martin_real-time_2002,
	address = {Washington, {DC,} {USA}},
	title = {Real-time acquisition of compact volumetric {3D} maps with mobile robots},
	lccn = {0029},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1013379},
	doi = {10.1109/ROBOT.2002.1013379},
	abstract = {Describes an online algorithm for generating compact {3D} maps of mobile robot environments. Maps generated by our approach consist of small numbers of planar surfaces, which are augmented by fine-grained polygons for non-flat environmental features. Our approach builds on the expectation maximization {(EM)} algorithm, but develops a new, incremental version that can be executed in real-time. Experimental results obtained in corridor-type environments illustrate that compact and accurate maps can be acquired in real-time, from range and camera data collected by a mobile robot.},
	booktitle = {Proceedings 2002 {IEEE} International Conference on Robotics and Automation {(Cat.} {No.02CH37292)}},
	author = {C. Martin and S. Thrun},
	month = aug,
	year = {2002},
	keywords = {{EM,} plane fitting},
	pages = {311--316}
},

@article{gonzalez-banos_navigation_2002,
	title = {Navigation Strategies for Exploring Indoor Environments},
	volume = {21},
	lccn = {0105},
	url = {http://ijr.sagepub.com/content/21/10-11/829.abstract},
	doi = {10.1177/0278364902021010834},
	abstract = {In this paper, we investigate safe and efficient map-building strategies for a mobile robot with imperfect control and sensing. In the implementation, a robot equipped with a range sensor builds a polygonal map (layout) of a previously unknown indoor environment. The robot explores the environment and builds the map concurrently by patching together the local models acquired by the sensor into a global map. A well-studied and related problem is the simultaneous localization and mapping {(SLAM)} problem, where the goal is to integrate the information collected during navigation into the most accurate map possible. However, {SLAM} does not address the sensor-placement portion of the map-building task. That is, given the map built so far, where should the robot go next? This is the main question addressed in this paper. Concretely, an algorithm is proposed to guide the robot through a series of 'good' positions, where 'good' refers to the expected amount and quality of the information that will be revealed at each new location. This is similar to the next-best-view {(NBV)} problem studied in computer vision and graphics. However, in mobile robotics the problem is complicated by several issues, two of which are particularly crucial. One is to achieve safe navigation despite an incomplete knowledge of the environment and sensor limitations (e.g., in range and incidence). The other issue is the need to ensure sufficient overlap between each new local model and the current map, in order to allow registration of successive views under positioning uncertainties inherent to mobile robots. To address both issues in a coherent framework, in this paper we introduce the concept of a safe region, defined as the largest region that is guaranteed to be free of obstacles given the sensor readings made so far. The construction of a safe region takes sensor limitations into account. In this paper we also describe an {NBV} algorithm that uses the safe-region concept to select the next robot position at each step. The new position is chosen within the safe region in order to maximize the expected gain of information under the constraint that the local model at this new position must have a minimal overlap with the current global map. In the future, {NBV} and {SLAM} algorithms should reinforce each other. While a {SLAM} algorithm builds a map by making the best use of the available sensory data, an {NBV} algorithm, such as that proposed here, guides the navigation of the robot through positions selected to provide the best sensory inputs.},
	number = {10-11},
	journal = {The International Journal of Robotics Research},
	author = {Hector H {Gonzalez-Banos} and {Jean-Claude} Latombe},
	month = oct,
	year = {2002},
	keywords = {exploration, slam},
	pages = {829 --848}
},

@inproceedings{caspary_wavelet-based_2002,
	title = {Wavelet-based multiresolution stereo vision},
	volume = {3},
	lccn = {0006},
	url = {http://dx.doi.org/10.1109/ICPR.2002.1048030},
	abstract = {An efficient wavelet-based multiresolution approach to the stereo vision problem is presented. A cost function is defined and iteratively minimized. The minimization is performed on the image representation in wavelet space. We employ the theory of representation of operators in spaces spanned by scaling functions and thereby take advantage of a simplified approximation of differentiation. Examples illustrate the advantages afforded by the application of our algorithm over correlation-based methods.},
	booktitle = {Pattern Recognition, 2002. Proceedings. 16th International Conference on},
	author = {G Caspary and {YY} Zeevi},
	month = dec,
	year = {2002},
	keywords = {stereo, wavelet},
	pages = {680--683 vol.3}
},

@article{bischoff_sub-voxel_2003,
	title = {{Sub-Voxel} Topology Control for {Level-Set} Surfaces},
	volume = {22},
	issn = {0167-7055},
	lccn = {0026},
	url = {http://dx.doi.org/10.1111/1467-8659.00674},
	abstract = {Active contour models are an efficient, accurate, and robust tool for the segmentation of {2D} and {3D} image {data.In} particular, geometric deformable models {(GDM)} that represent an active contour as the level set of an implicitfunction have proven to be very effective. {GDMs,} however, do not provide any topology control, i.e. contours maymerge or split arbitrarily and hence change the genus of the reconstructed surface. This behavior is inadequate insettings like the segmentation of organic tissue or other objects whose genus is known beforehand. In this paperwe describe a novel method to overcome this limitation while still preserving the favorable properties of the {GDMsetup.} We achieve this by adding (sparse) topological information to the volume representation at locations whereit is necessary to locally resolve topological ambiguities. Since the sparse topology information is attached to theedges of the voxel grid, we can reconstruct the interfaces where the deformable surface touches itself at sub-voxelaccuracy. We also demonstrate the efficiency and robustness of our method.},
	number = {3},
	journal = {Computer Graphics Forum},
	author = {S Bischoff and L Kobbelt},
	year = {2003},
	keywords = {cartesian, geometric-modeling, geometry, implicit-distance-field, implicit-representation, level-set, octree, representation, segmentation, surface fitting, topology, voxelization, voxel-representation},
	pages = {273--280}
},

@inproceedings{bosse_atlas_2003,
	title = {An Atlas framework for scalable mapping},
	volume = {2},
	isbn = {1050-4729},
	lccn = {0237},
	doi = {10.1109/ROBOT.2003.1241872},
	abstract = {This paper describes Atlas, a hybrid metrical/topological approach to {SLAM} that achieves efficient mapping of large-scale environments. The representation is a graph of coordinate frames, with each vertex in the graph representing a local frame, and each edge representing the transformation between adjacent frames. In each frame, we build a map that captures the local environment and the current robot pose along with the uncertainties of each. Each map's uncertainties are modeled with respect to its own frame. Probabilities of entities with respect to arbitrary frames are generated by following a path formed by the edges between adjacent frames, computed via Dijkstra's shortest path algorithm. Loop closing is achieved via an efficient map matching algorithm. We demonstrate the technique running in real-time in a large indoor structured environment (2.2 km path length) with multiple nested loops using laser or ultrasonic ranging sensors.},
	booktitle = {Robotics and Automation, 2003. Proceedings. {ICRA} '03. {IEEE} International Conference on},
	author = {M. Bosse and P. Newman and J. Leonard and M. Soika and W. Feiten and S. Teller},
	year = {2003},
	keywords = {Atlas, cartography, Dijkstra shortest path algorithm, edge detection, frame based representation, hybrid, indoor structured environment, large scale environments, laser ranging sensors, map matching algorithm, mobile robot, Mobile robots, multiple nested loops, path planning, probability, real time technique, registration, scalable mapping, {SLAM,} star, topology, ultrasonic ranging sensors},
	pages = {1899--1906 vol.2}
},

@inproceedings{carr_smooth_2003,
	address = {Melbourne, Australia},
	title = {Smooth surface reconstruction from noisy range data},
	isbn = {1-58113-578-5},
	lccn = {0097},
	url = {http://dx.doi.org/10.1145/604471.604495},
	abstract = {This paper shows that scattered range data can be smoothed at low cost by fitting a Radial Basis Function {(RBF)} to the data and convolving with a smoothing kernel (low pass filtering). The {RBF} exactly describes the range data and interpolates across holes and gaps. The data is smoothed during evaluation of the {RBF} by simply changing the basic function. The amount of smoothing can be varied as required without having to fit a new {RBF} to the data. The key feature of our approach is that it avoids resampling the {RBF} on a fine grid or performing a numerical convolution. Furthermore, the computation required is independent of the extent of the smoothing kernel, i.e., the amount of smoothing. We show that particular smoothing kernels result in the applicability of fast numerical methods. We also discuss an alternative approach in which a discrete approximation to the smoothing kernel achieves similar results by adding new centres to the original {RBF} during evaluation. This approach allows arbitrary filter kernels, including anisotropic and spatially varying filters, to be applied while also using established fast evaluation methods. We illustrate both techniques with {LIDAR} laser scan data and noisy synthetic data.},
	booktitle = {{GRAPHITE} '03: Proceedings of the 1st international conference on Computer graphics and interactive techniques in Australasia and South East Asia},
	publisher = {{ACM}},
	author = {{JC} Carr and {RK} Beatson and {BC} {McCallum} and {WR} Fright and {TJ} {McLennan} and {TJ} Mitchell},
	year = {2003},
	keywords = {interpolation, rbf, surface fitting, tps},
	pages = {119--ff}
},

@inproceedings{dachsbacher_sequential_2003,
	address = {San Diego, California},
	title = {Sequential point trees},
	isbn = {1-58113-709-5},
	lccn = {0160},
	url = {http://dx.doi.org/10.1145/1201775.882321},
	abstract = {In this paper we present sequential point trees, a data structure that allows adaptive rendering of point clouds completely on the graphics processor. Sequential point trees are based on a hierarchical point representation, but the hierarchical rendering traversal is replaced by sequential processing on the graphics processor, while the {CPU} is available for other tasks. Smooth transition to triangle rendering for optimized performance is integrated. We describe optimizations for backface culling and texture adaptive point selection. Finally, we discuss implementation issues and show results.},
	booktitle = {{ACM} {SIGGRAPH} 2003 Papers},
	publisher = {{ACM}},
	author = {Carsten Dachsbacher and Christian Vogelgsang and Marc Stamminger},
	year = {2003},
	keywords = {gpu, point trees, star},
	pages = {657--662}
},

@inproceedings{eliazar_dp-slam:_2003,
	address = {Acapulco, Mexico},
	title = {{DP-SLAM:} fast, robust simultaneous localization and mapping without predetermined landmarks},
	lccn = {0160},
	url = {http://portal.acm.org/citation.cfm?id=1630822},
	abstract = {We present a novel, laser range finder based algorithm for simultaneous localization and mapping {(SLAM)} for mobile robots. {SLAM} addresses the problem of constructing an accurate map in real time despite imperfect information about the robot's trajectory through the environment. Unlike other approaches that assume predetermined landmarks (and must deal with a resulting data-association problem) our algorithm is purely laser based. Our algorithm uses a particle filter to represent both robot poses and possible map configurations. By using a new map representation, which we call distributed particle {(DP)} mapping, we are able to maintain and update hundreds of candidate maps and robot poses efficiently. The worst-case complexity of our algorithm per laser sweep is log-quadratic in the number of particles we maintain and linear in the area swept out by the laser. However, in practice our run time is usually much less than that. Our technique contains essentially no assumptions about the environment yet it is accurate enough to close loops of 60m in length with crisp, perpendicular edges on corridors and minimal or no misalignment errors.},
	booktitle = {Proceedings of the 18th international joint conference on Artificial intelligence},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Austin Eliazar and Ronald Parr},
	year = {2003},
	keywords = {slam},
	pages = {1135--1142}
},

@inproceedings{fong_representing_2003,
	title = {Representing a {3-D} environment with a 2 1/2 {-D} map structure},
	volume = {3},
	lccn = {0006},
	doi = {10.1109/IROS.2003.1249325},
	abstract = {This paper explores the development of a two and one-half dimensional (2 1/2 {-D)} map structure to provide an autonomous mobile robot with a more three-dimensional {(3-D)} model of its environment than those afforded by current map structures. The 2 1/2 {-D} map structure was created by modifying the widely used evidence grid to store a height, along with a probability value, in each cell location to record the varying elevations of a {3-D} environment. Results show that this map structure is capable of providing an autonomous mobile robot with a representation of a limited {3-D} environment that will allow it to perform obstacle detection, path planning, and to an extent, localization.},
	booktitle = {Intelligent Robots and Systems, 2003. {(IROS} 2003). Proceedings. 2003 {IEEE/RSJ} International Conference on},
	author = {{E.H.L.} Fong and W. Adams and {F.L.} Crabbe and {A.C.} Schultz},
	year = {2003},
	keywords = {2 1/2 {-D} map structure, {2.5D} map structure, {3D} environment, autonomous mobile robot, localisation, Mobile robots, obstacle detection, path planning, probability, star, three-dimensional model},
	pages = {2986--2991 vol.3}
},

@incollection{kumar_efficient_2003,
	series = {Lecture Notes in Computer Science},
	title = {Efficient Proximity Search for {3-D} Cuboids},
	volume = {2669},
	lccn = {0004},
	url = {http://dx.doi.org/10.1007/3-540-44842-X_83},
	abstract = {In this paper, we give the definition for the voronoi diagram and its dual graph � Delaunay triangulation for {3D} cuboids. We prove properties of the {3D} Delaunay triangulation, and provide algorithms to construct and update the Delaunay triangulation. The Delaunay triangulation data structure is used to perform proximity searches for both static and kinetic cases. We describe experimental results that show how the Delaunay triangulation is used on a mobile robot to model, understand and reason about the spatial information of the environment.},
	booktitle = {Computational Science and Its Applications � {ICCSA} 2003},
	publisher = {Springer Berlin / Heidelberg},
	author = {Vipin Kumar and Marina Gavrilova and Chih Tan and Pierre {L�Ecuyer} and Jie Gao and Rakesh Gupta},
	year = {2003},
	keywords = {non-cubic voxel},
	pages = {987}
},

@misc{haehnel_towards_2003,
	title = {Towards Lazy Data Association in {SLAM}},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.10.6362},
	abstract = {We present a lazy data association algorithm for the simultaneous localization and mapping {(SLAM)} problem. Our approach uses a tree-structured Bayesian representation of map posteriors that makes it possible to revise data association decisions arbitrarily far into the past. We describe a criterion for detecting and repairing poor data association decisions. This technique makes it possible to acquire maps of large-scale environments with many loops, with a minimum of computational overhead for the management of multiple data association hypotheses. A empirical comparison with the popular {FastSLAM} algorithm shows the advantage of lazy over proactive data association.},
	author = {Dirk H�hnel and Sebastian Thrun and Ben Wegbreit and Wolfram Burgard},
	year = {2003},
	keywords = {localization, slam},
	howpublished = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.10.6362}
},

@inproceedings{haehnel_highly_2003,
	title = {A highly efficient {{FastSLAM}} algorithm for generating cyclic maps of large-scale environments from raw laser range measurements},
	lccn = {0112},
	abstract = {The ability to learn a consistent model of its environment is a prerequisite for autonomous mobile robots. A particularly challenging problem in acquiring environment maps is that of closing loops; loops in the environment create challenging data association problems 9. This paper presents a novel algorithm that combines {Rao-Blackwellized} particle filtering and scan matching. In our approach scan matching is used for minimizing odometric errors during mapping. A probabilistic model of the residual errors of scan matching process is then used for the resampling steps. This way the number of samples required is seriously reduced. Simultaneously we reduce the particle depletion problem that typically prevents the robot from closing large loops. We present extensive experiments that illustrate the superior performance of our approach compared to previous approaches.},
	booktitle = {Proc.{\textasciitilde}of the {IEEE/RSJ} International Conference on Intelligent Robots and Systems {(IROS)}},
	author = {D H�hnel and W Burgard and D Fox and S Thrun},
	year = {2003},
	keywords = {fastslam, slam}
},

@inproceedings{lisien_hierarchical_2003,
	address = {Las Vegas, Nevada, {USA}},
	title = {Hierarchical simultaneous localization and mapping},
	lccn = {0041},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1250670},
	doi = {10.1109/IROS.2003.1250670},
	abstract = {This paper presents a novel method of combining topological and feature-based mapping strategies to create a hierarchical approach to simultaneous localization and mapping {(SLAM).} More than simply running both processes in parallel, we use the topological mapping procedure to organize local feature-based methods. The result is an autonomous exploration and mapping strategy that scales well to large environments and higher dimensions while confronting the issue of obstacle avoidance. We have obtained successful results of our approach in an area spanning 5000 square meters.},
	booktitle = {Proceedings 2003 {IEEE/RSJ} International Conference on Intelligent Robots and Systems {(IROS} 2003) {(Cat.} {No.03CH37453)}},
	author = {B. Lisien and D. Morales and D. Silver and G. Kantor and I. Rekleitis and H. Choset},
	year = {2003},
	keywords = {slam},
	pages = {448--453}
},

@inproceedings{mitra_estimating_2003,
	address = {San Diego, California, {USA}},
	title = {Estimating surface normals in noisy point cloud data},
	isbn = {1-58113-663-3},
	lccn = {0162},
	url = {http://dx.doi.org/10.1145/777792.777840},
	abstract = {In this paper we describe and analyze a method based on local least square fitting for estimating the normals at all sample points of a point cloud data {(PCD)} set, in the presence of noise. We study the effects of neighborhood size, curvature, sampling density, and noise on the normal estimation when the {PCD} is sampled from a smooth curve in R2 or a smooth surface in R3 and noise is added. The analysis allows us to find the optimal neighborhood size using other local information from the {PCD.} Experimental results are also provided.},
	booktitle = {Proceedings of the nineteenth annual symposium on Computational geometry},
	publisher = {{ACM}},
	author = {Niloy Mitra and An Nguyen},
	year = {2003},
	keywords = {surface fitting},
	pages = {322--328}
},

@misc{moenning_new_2003,
	title = {A new point cloud simplification algorithm},
	lccn = {0034},
	url = {http://citeseer.ist.psu.edu/moenning03new.html},
	abstract = {We present a new technique for the simplification of pointsampled
geometry without any prior surface reconstruction.
Using Fast Marching farthest point sampling for implicit
surfaces and point clouds [1], we devise a coarse-tofine
uniform or feature-sensitive simplification algorithm
with user-controlled density guarantee. The algorithm is
computationally and memory efficient, easy to implement
and inherently allows for the generation of progressive and
multiresolution representations of the...},
	author = {C Moenning and N Dodgson},
	year = {2003},
	keywords = {cloud, point cloud, points, segmentation, simplification}
},

@phdthesis{montemerlo_fastslam:_2003,
	title = {{FastSLAM:} A Factored Solution to the Simultaneous Localization and Mapping Problem with Unknown Data Association},
	lccn = {0001},
	abstract = {The ability to simultaneously localize a robot and ac-
curately map its surroundings is considered by many to
be a key prerequisite of truly autonomous robots. How-
ever, few approaches to this problem scale up to handle
the very large number of landmarks present in real envi-
ronments. Kalman filter-based algorithms, for example,
require time quadratic in the number of landmarks to in-
corporate each sensor observation. This paper presents
{FastSLAM,} an algorithm that recursively estimates the
full posterior distribution over robot pose and landmark
locations, yet scales logarithmically with the number of
landmarks in the map. This algorithm is based on an ex-
act factorization of the posterior into a product of con-
ditional landmark distributions and a distribution over
robot paths. The algorithm has been run successfully
on as many as 50,000 landmarks, environments far be-
yond the reach of previous approaches. Experimental
results demonstrate the advantages and limitations of
the {FastSLAM} algorithm on both simulated and real-
world data.},
	school = {Robotics Institute, Carnegie Mellon University},
	author = {M Montemerlo},
	year = {2003},
	keywords = {fastslam, slam},
	annote = {{{\textless}p{\textgreater}I} think this is the tech report version...{\textless}/p{\textgreater}}
},

@misc{montemerlo_simultaneous_2003,
	title = {Simultaneous localization and mapping with unknown data association using {FastSLAM}},
	lccn = {0223},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8990},
	abstract = {The Extended Kalman Filter {(EKF)} has been the
de facto approach to the Simultaneous Localization and Mapping
{(SLAM)} problem for nearly fifteen years. However, the {EKF} has two
serious deficiencies that prevent it from being applied to large, realword
environments: quadratic complexity and sensitivity to failures
in data association. {FastSLAM,} an alternative approach based on the
{Rao-Blackwellized} Particle Filter, has been shown to scale logarithmically
with the number of landmarks in the map...},
	author = {M Montemerlo and S Thrun},
	year = {2003},
	keywords = {fastslam}
},

@inproceedings{montemerlo_fastslam_2003,
	title = {{FastSLAM} 2.0: An Improved Particle Filtering Algorithm for Simultaneous Localization and Mapping that Provably Converges},
	lccn = {0386},
	abstract = {In [15], Montemerlo et al. proposed an algorithm called
{FastSLAM} as an efficient and robust solution to the simul-
taneous localization and mapping problem. This paper de-
scribes a modified version of {FastSLAM} that overcomes
important deficiencies of the original algorithm. We prove
convergence of this new algorithm for linear {SLAM} prob-
lems and provide real-world experimental results that il-
lustrate an order of magnitude improvement in accuracy
over the original {FastSLAM} algorithm.},
	booktitle = {Proceedings of the 18th International Joint Conference on Artificial Intelligence {(IJCAI)}},
	author = {M Montemerlo and S Thrun and D Koller and B Wegbreit},
	year = {2003},
	keywords = {fastslam, slam}
},

@techreport{moravec_dense_2003,
	title = {Dense {3D} perception for broad mobile robot applications},
	lccn = {0000},
	abstract = {We near fruition of a decades-long effort to give robots dense spatial awareness to
handle the widest possible range of situations encountered in long periods of
autonomous navigation in unfamiliar surroundings. Lack of long-term reliable
perception has kept autonomous mobile robots out of most utilitarian applications,
domestic and military. Its arrival will enable a growing competitive market, supporting
rapid further development.
Our techniques were at the boundaries of feasibility, but are rapidly becoming practical
with rising computer power. Arbitrarily complex surroundings are modeled in high-
but constant-cost {3D} grid maps of spatial occupancy evidence. The grids allow
quantities of data from very imperfect inputs like sonar and stereoscopic ranging to be
statistically combined into high quality spatial representations. The process is greatly
enhanced by a learning technique that automatically tunes the sensor models by which
the raw data is interpreted. We devised {2D} versions of the approach in the 1980s: they
were used in many successful research mobile robots, but fell short of utilitarian
reliability. We have been developing the 1,000 times richer and much more challenging
{3D} version since 1992. In the last three years, under prior {DARPA} support, 1,000 {MIPS}
of computer power and many innovations allowed us to produce dense near-
photorealistic {3D} maps of large rooms from stereoscopic traverses.
Higher perceptual functions can be built on reliable probabilistic {3D} grid
representations. Path selection minimizing collision probability is straightforward.
Localization techniques that interpolate matches of selected cells between local and
global grid maps achieve 1 mm precision in maps of cell size greater than 1 cm. We
plan to identify surfaces such as floors and walls using weighted least-square plane fits.
We will try recognizing objects of known shape and size by convolving maps with {3D}
object templates, and variable ones by combining the results of several detectors with
combinatorial or trainable statistical recognizers. The techniques will also be applied to
filling in gaps and hidden areas in grids, a model-based inference. By the third year we
will begin to extend the grid approach into the time dimension. Four-dimensional
grids, about 100 times as expensive as {3D,} will enable trajectories of moving objects to
be represented and extracted with techniques similar to those used to recognize and fill
in static features in {3D} grid maps.
Other mobile robot research groups are addressing {3D} and motion. Two-dimensional
mapping has appeared in some commercial products. Quality techniques to date,
however, depend on clean and precise data, typically from {2D} scanning laser
rangefinders from Sick {AG,} and have limited tolerance for clutter. The grid approach
gets good results from a much wider range of sensors, including low-cost stereoscopic
cameras, and can map arbitrarily complex scenes. Though computationally expensive
we think it is superior for reliable operational mobile robots of the near future. In
February 2003 we formed a company, {SEEGRID} Inc, to develop and license these
methods for industrial transport, cleaning and security vehicles and future applications.
The company�s near-term focus will support, motivate and benefit from the long-term
research proposed here. The results of both should, in time, nucleate a self-accelerating
industry that rapidly evolves robot capabilities, perhaps analogous to stages in our own
evolutionary lineage, a proven incremental path.},
	author = {Hans Moravec},
	year = {2003},
	keywords = {3d, occupancy grid, star}
},

@article{pauly_multi-scale_2003,
	title = {Multi-scale Feature Extraction on {Point-Sampled} Surfaces},
	volume = {22},
	issn = {1467-8659},
	lccn = {0131},
	url = {http://dx.doi.org/10.1111/1467-8659.00675},
	abstract = {We present a new technique for extracting line-type features on point-sampled geometry. Given an unstructuredpoint cloud as input, our method first applies principal component analysis on local neighborhoods toclassify points according to the likelihood that they belong to a feature. Using hysteresis thresholding, we thencompute a minimum spanning graph as an initial approximation of the feature lines. To smooth out the featureswhile maintaining a close connection to the underlying surface, we use an adaptation of active contour {models.Central} to our method is a multi-scale classification operator that allows feature analysis at multiplescales, using the size of the local neighborhoods as a discrete scale parameter. This significantly improves thereliability of the detection phase and makes our method more robust in the presence of noise. To illustrate theusefulness of our method, we have implemented a non-photorealistic point renderer to visualize point-sampledsurfaces as line drawings of their extracted feature curves.},
	number = {3},
	journal = {Computer Graphics Forum},
	author = {Mark Pauly and Richard Keiser and Markus Gross},
	year = {2003},
	keywords = {surface fitting},
	pages = {281--289},
	annote = {Abstract We present a new technique for extracting line-type features on point-sampled geometry. Given an unstructuredpoint cloud as input, our method first applies principal component analysis on local neighborhoods toclassify points according to the likelihood that they belong to a feature. Using hysteresis thresholding, we thencompute a minimum spanning graph as an initial approximation of the feature lines. To smooth out the featureswhile maintaining a close connection to the underlying surface, we use an adaptation of active contour {models.Central} to our method is a multi-scale classification operator that allows feature analysis at multiplescales, using the size of the local neighborhoods as a discrete scale parameter. This significantly improves thereliability of the detection phase and makes our method more robust in the presence of noise. To illustrate theusefulness of our method, we have implemented a non-photorealistic point renderer to visualize point-sampledsurfaces as line drawings of their extracted feature curves.}
},

@inproceedings{ruiz-correa_new_2003,
	title = {A new paradigm for recognizing {3-D} objects from range data},
	lccn = {0062},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1238475},
	abstract = {Most of the work on {3D} object recognition from range data has used an alignment-verification approach in which a specific {3D} object is matched to an exact instance of the same object in a scene. This approach has been successfully used in industrial machine vision, but it is not capable of dealing with the complexities of recognizing classes of similar objects. This paper undertakes this task by proposing and testing a component-based methodology encompassing three main ingredients: 1) a new way of learning and extracting shape-class components from surface shape information; 2) a new shape representation called a symbolic surface signature that summarizes the geometric relationships among components; and 3) an abstract representation of shape classes formed by a hierarchy of classifiers that learn object-class parts and their spatial relationships from examples.},
	booktitle = {Computer Vision, 2003. Proceedings. Ninth {IEEE} International Conference on},
	author = {S {Ruiz-Correa} and {LG} Shapiro and M Meila},
	year = {2003},
	keywords = {shape},
	pages = {1126--1133 vol.2}
},

@inproceedings{stewart_revisiting_2003,
	title = {The revisiting problem in mobile robot map building: A hierarchical Bayesian approach},
	lccn = {0039},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.143.7023},
	abstract = {We present an application of hierarchical Bayesian estimation to robot map building. The revisiting problem occurs when a robot has to decide whether it is seeing a previously-built portion of a map, or is exploring new territory. This is a difficult decision problem, requiring the probability of being outside of the current known map. To estimate this probability, we model the structure of a �typical � environment as a hidden Markov model that generates sequences of views observed by a robot navigating through the environment. A Dirichlet prior over structural models is learned from previously explored environments. Whenever a robot explores a new environment, the posterior over the model is estimated by Dirichlet hyperparameters. Our approach is implemented and tested in the context of multi-robot map merging, a particularly difficult instance of the revisiting problem. Experiments with robot data show that the technique yields strong improvements over alternative methods. 1},
	booktitle = {In Proc. of the Conference on Uncertainty in Artificial Intelligence {(UAI}},
	author = {Benjamin Stewart and Jonathan Ko and Dieter Fox and Kurt Konolige},
	year = {2003},
	keywords = {slam},
	pages = {551--558}
},

@article{thrun_learning_2003,
	title = {Learning Occupancy Grid Maps with Forward Sensor Models},
	volume = {15},
	lccn = {0172},
	url = {http://dx.doi.org/10.1023/A:1025584807625},
	abstract = {This article describes a new algorithm for acquiring occupancy grid maps with mobile robots. Existing occupancy grid mapping algorithms decompose the high-dimensional mapping problem into a collection of one-dimensional problems, where the occupancy of each grid cell is estimated independently. This induces conflicts that may lead to inconsistent maps, even for noise-free sensors. This article shows how to solve the mapping problem in the original, high-dimensional space, thereby maintaining all dependencies between neighboring cells. As a result, maps generated by our approach are often more accurate than those generated using traditional techniques. Our approach relies on a statistical formulation of the mapping problem using forward models. It employs the expectation maximization algorithm for searching maps that maximize the likelihood of the sensor measurements.},
	number = {2},
	journal = {Autonomous Robots},
	author = {Sebastian Thrun},
	year = {2003},
	keywords = {bayesian, forward sensor model, mapping, mobile, navigation, occupancy grid, robot, robotics, slam},
	pages = {111--127},
	annote = {{\textless}p{\textgreater}cited by 17{\textless}/p{\textgreater}}
},

@misc{wolf_towards_2003,
	title = {Towards Mapping Dynamic Environments},
	lccn = {0010},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.58.3972},
	abstract = {We propose an algorithm for mapping dynamic environments.
Our algorithm creates a representation of
the environment where objects move over time. Our
approach is based on maintaining two occupancy grids
in parallel. One grid models the static parts of the
environment, and the other models the dynamic parts
of the environment. The union of the two provides
a complete description of the environment over time.
We also apply a size-based classifier to the cells in
the dynamic map, to detect and...},
	author = {D Wolf and S Sukhatme},
	year = {2003},
	keywords = {dynamic, mapping, occupancy, occupancy grid, robot, static}
},

@misc{zachmann_geometric_2003,
	title = {Geometric Data Structures for Computer Graphics},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.10.2297},
	abstract = {pefully make them curious about further powerful treasures to be discovered in the area of computational geometry. In order to achieve these goals in an engaging yet sound manner, the general concept throughout the course is to present each geometric data structure in the following way: first, the data strucure will be defined and described in detail; then, some of its fundamental properties will be highlighted; after that, one or more computational geometry algorithms based on the data structure will be presented; and finally, a number of recent, representative and practically relevant algorithms from computer graphics will be described in detail, showing the utilization of the data structure in a creative and enlightening way. We have arranged the topics in roughly increasing degree of difficulty. The hierarchical data structures are ordered by increasing flexibility, while the non-hierarchical topics build on each other. Finally, the last topic presents a generic technique for},
	author = {Gabriel Zachmann and Elmar Langetepe},
	year = {2003},
	keywords = {computational-geometry, data-structures, octree, survey},
	howpublished = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.10.2297}
},

@article{filliat_map-based_2003,
	title = {Map-based navigation in mobile robots: I. A review of localization strategies},
	volume = {4},
	issn = {13890417},
	lccn = {0068},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1389041703000081},
	doi = {10.1016/S1389-0417(03)00008-1},
	abstract = {For a robot, an animal, and even for man, to be able to use an internal representation of the spatial layout of its environment to position itself is a very complex task, which raises numerous issues of perception, categorization and motor control that must all be solved in an integrated manner to promote survival. This point is illustrated here, within the framework of a review of localization strategies in mobile robots. The allothetic and idiothetic sensors that may be used by these robots to build internal representations of their environment, and the maps in which these representations may be instantiated, are first described. Then map-based navigation systems are categorized according to a three-level hierarchy of localization strategies, which respectively call upon direct position inference, single-hypothesis tracking, and multiple-hypothesis tracking. The advantages and drawbacks of these strategies, notably with respect to the limitations of the sensors on which they rely, are discussed throughout the text.},
	number = {4},
	journal = {Cognitive Systems Research},
	author = {D Filliat},
	year = {2003},
	keywords = {localization, survey},
	pages = {243--282}
},

@article{meyer_map-based_2003,
	title = {Map-based navigation in mobile robots: {II.} A review of map-learning and path-planning strategies},
	volume = {4},
	issn = {13890417},
	lccn = {0064},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S138904170300007X},
	doi = {10.1016/S1389-0417(03)00007-X},
	abstract = {This article reviews map-learning and path-planning strategies within the context of map-based navigation in mobile robots. Concerning map-learning, it distinguishes metric maps from topological maps and describes procedures that help maintain the coherency of these maps. Concerning path-planning, it distinguishes continuous from discretized spaces and describes procedures applicable when the execution of a plan fails. It insists on the need for an integrated conception of such procedures, which must be tightly tailored to the specific robot that is used, notably to the capacities and limitations of its sensory-motor equipment, and to the specific environment that is experienced. A hierarchy of navigation strategies is outlined in the discussion, together with the sort of adaptive capacities each affords to cope with unexpected obstacles or dangers encountered on an animat or robot�s way to its goal.},
	number = {4},
	journal = {Cognitive Systems Research},
	author = {J Meyer},
	year = {2003},
	keywords = {mapping, survey},
	pages = {283--317}
},

@article{surmann_autonomous_2003,
	title = {An autonomous mobile robot with a {3D} laser range finder for {3D} exploration and digitalization of indoor environments},
	volume = {45},
	issn = {09218890},
	lccn = {0180},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0921889003001556},
	doi = {10.1016/j.robot.2003.09.004},
	abstract = {Digital {3D} models of the environment are needed in rescue and inspection robotics, facility managements and architecture. This paper presents an automatic system for gaging and digitalization of {3D} indoor environments. It consists of an autonomous mobile robot, a reliable {3D} laser range finder and three elaborated software modules. The first module, a fast variant of the Iterative Closest Points algorithm, registers the {3D} scans in a common coordinate system and relocalizes the robot. The second module, a next best view planner, computes the next nominal pose based on the acquired {3D} data while avoiding complicated obstacles. The third module, a closed-loop and globally stable motor controller, navigates the mobile robot to a nominal pose on the base of odometry and avoids collisions with dynamical obstacles. The {3D} laser range finder acquires a {3D} scan at this pose. The proposed method allows one to digitalize large indoor environments fast and reliably without any intervention and solves the {SLAM} problem. The results of two {3D} digitalization experiments are presented using a fast octree-based visualization method.},
	number = {3-4},
	journal = {Robotics and Autonomous Systems},
	author = {H Surmann},
	year = {2003},
	keywords = {octree, registration, slam, star},
	pages = {181--198}
},

@inproceedings{ohtake_multi-scale_2003,
	address = {Seoul, South Korea},
	title = {A multi-scale approach to {3D} scattered data interpolation with compactly supported basis functions},
	lccn = {0135},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1199611},
	doi = {10.1109/SMI.2003.1199611},
	abstract = {We propose a hierarchical approach to {3D} scattered data interpolation with compactly supported basis functions. Our numerical experiments suggest that the approach integrates the best aspects of scattered data fitting with locally and globally supported basis functions. Employing locally supported functions leads to an efficient computational procedure, while a coarse-to-fine hierarchy makes our method insensitive to the density of scattered data and allows us to restore large parts of missed data. Given a point cloud distributed along a surface, we first use spatial down sampling to construct a coarse-to-fine hierarchy of point sets. Then we interpolate the sets starting from the coarsest level. We interpolate a point set of the hierarchy, as an offsetting of the interpolating function computed at the previous level. An original point set and its coarse-to-fine hierarchy of interpolated sets is presented. According to our numerical experiments, the method is essentially faster than the state-of-the-art scattered data approximation with globally supported {RBFs} {(Carr} et al., 2001) and much simpler to implement.},
	booktitle = {2003 Shape Modeling International.},
	author = {Y. Ohtake and A. Belyaev and {H.P.} Seidel},
	month = may,
	year = {2003},
	keywords = {surface fitting},
	pages = {153--161}
},

@article{pauly_shape_2003,
	title = {Shape modeling with point-sampled geometry},
	volume = {22},
	issn = {0730-0301},
	lccn = {0348},
	url = {http://dx.doi.org/10.1145/882262.882319},
	abstract = {We present a versatile and complete free-form shape modeling framework for point-sampled geometry. By combining unstructured point clouds with the implicit surface definition of the moving least squares approximation, we obtain a hybrid geometry representation that allows us to exploit the advantages of implicit and parametric surface models. Based on this representation we introduce a shape modeling system that enables the designer to perform large constrained deformations as well as boolean operations on arbitrarily shaped objects. Due to minimum consistency requirements, point-sampled surfaces can easily be re-structured on the fly to support extreme geometric deformations during interactive editing. In addition, we show that strict topology control is possible and sharp features can be generated and preserved on point-sampled objects. We demonstrate the effectiveness of our system on a large set of input models, including noisy range scans, irregular point clouds, and sparsely as well as densely sampled models.},
	number = {3},
	journal = {{ACM} Trans. Graph.},
	author = {Mark Pauly and Richard Keiser and Leif Kobbelt and Markus Gross},
	month = jul,
	year = {2003},
	keywords = {geometric-modeling, geometry, representation, sampling, surface fitting, voxelization},
	pages = {641--650}
},

@inproceedings{stachniss_mapping_2003,
	address = {Las Vegas, Nevada, {USA}},
	title = {Mapping and exploration with mobile robots using coverage maps},
	lccn = {0020},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1250673},
	doi = {10.1109/IROS.2003.1250673},
	abstract = {Exploration and mapping belongs to the fundamental tasks of mobile robots. In the past, many approaches have used occupancy grid maps to represent the environment during the map building process. Occupancy grids, however, are based on the assumption that each cell is either occupied or free. In this paper we introduce coverage maps as an alternative way of representing the environment of a robot. Coverage maps store for each cell of a given grid a posterior about the amount the corresponding cell is covered by an obstacle. We also present a model that allows us to update coverage maps upon input obtained from proximity sensors. We furthermore describe how to use coverage maps for a decision theoretic approach to exploration. Finally we present experimental results illustrating that coverage maps can be used to efficiently learn highly accurate models even if noisy sensors such as ultrasounds are used.},
	booktitle = {Proceedings 2003 {IEEE/RSJ} International Conference on Intelligent Robots and Systems {(IROS} 2003) {(Cat.} {No.03CH37453)}},
	author = {C. Stachniss and W. Burgard},
	month = oct,
	year = {2003},
	keywords = {coverage map, star},
	pages = {467--472}
},

@inproceedings{hahnel_efficient_2003,
	title = {An efficient {fastSLAM} algorithm for generating maps of large-scale cyclic environments from raw laser range measurements},
	volume = {1},
	lccn = {0214},
	url = {http://dx.doi.org/10.1109/IROS.2003.1250629},
	abstract = {The ability to learn a consistent model of its environment is a prerequisite for autonomous mobile robots. A particularly challenging problem in acquiring environment maps is that of closing loops; loops in the environment create challenging data association problems {[J.-S.} Gutman et al., 1999]. This paper presents a novel algorithm that combines {Rao-Blackwellized} particle filtering and scan matching. In our approach scan matching is used for minimizing odometric errors during mapping. A probabilistic model of the residual errors of scan matching process is then used for the resampling steps. This way the number of samples required is seriously reduced. Simultaneously we reduce the particle depletion problem that typically prevents the robot from closing large loops. We present extensive experiments that illustrate the superior performance of our approach compared to previous approaches.},
	booktitle = {Intelligent Robots and Systems, 2003. {(IROS} 2003). Proceedings. 2003 {IEEE/RSJ} International Conference on},
	author = {D Hahnel and W Burgard and D Fox and S Thrun},
	month = oct,
	year = {2003},
	keywords = {fastslam, lasermessung, slam, star},
	pages = {206--211 vol.1}
},

@inproceedings{unnikrishnan_robust_2003,
	address = {Las Vegas, {NV,} {USA}},
	title = {Robust extraction of multiple structures from non-uniformly sampled data},
	lccn = {0019},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1248828},
	doi = {10.1109/IROS.2003.1248828},
	abstract = {The extraction of multiple coherent structures from point clouds is crucial to the problem of scene modeling. While many statistical methods exist for robust estimation from noisy data, they are inadequate for addressing issues of scale, semi-structured clutter, and large point density variation together with the computational restriction of autonomous navigation. This paper extends an approach of nonparametric projection-pursuit based regression to compensate for the non-uniform and directional nature of data sampled in outdoor environments. The proposed algorithm is employed for extraction of planar structures and clutter grouping. Results are shown for scene abstraction of {3D} range data in large urban scenes.},
	booktitle = {Proceedings 2003 {IEEE/RSJ} International Conference on Intelligent Robots and Systems {(IROS} 2003) {(Cat.} {No.03CH37453)}},
	author = {R. Unnikrishnan and M. Hebert},
	month = dec,
	year = {2003},
	keywords = {plane fitting},
	pages = {1322--1329}
},

@inproceedings{arge_priority_2004,
	address = {Paris, France},
	title = {The Priority R-tree: a practically efficient and worst-case optimal R-tree},
	isbn = {1-58113-859-8},
	lccn = {0077},
	url = {http://dx.doi.org/10.1145/1007568.1007608},
	abstract = {We present the Priority R-tree, or {PR-tree,} which is the first R-tree variant that always answers a window query using {O((N/B)} 1 1/d + {T/B)} {I/Os,} where N is the number of d-dimensional (hyper-) rectangles stored in the R-tree, B is the disk block size, and T is the output size. This is provably asymptotically optimal and significantly better than other R-tree variants, where a query may visit all {N/B} leaves in the tree even when T = 0. We also present an extensive experimental study of the practical performance of the {PR-tree} using both real-life and synthetic data. This study shows that the {PR-tree} performs similar to the best known R-tree variants on real-life and relatively nicely distributed data, but outperforms them significantly on more extreme data.},
	booktitle = {{SIGMOD} '04: Proceedings of the 2004 {ACM} {SIGMOD} international conference on Management of data},
	publisher = {{ACM}},
	author = {Lars Arge and Mark de Berg and Herman Haverkort and Ke Yi},
	year = {2004},
	keywords = {r-tree, spatial-search},
	pages = {347--358}
},

@incollection{biber_probabilistic_2004,
	title = {A Probabilistic Framework for Robust and Accurate Matching of Point Clouds},
	volume = {3175},
	isbn = {978-3-540-22945-2},
	lccn = {0017},
	url = {http://dx.doi.org/10.1007/978-3-540-28649-3_59},
	abstract = {We present a probabilistic framework for matching of point clouds. Variants of the {ICP} algorithm typically pair points to points or points to lines. Instead, we pair data points to probability functions that are thought of having generated the data points. Then an energy function is derived from a maximum likelihood formulation. Each such distribution is a mixture of a bivariate Normal Distribution to capture the local structure of points and an explicit outlier term to achieve robustness. We apply our approach to the {SLAM} problem in robotics using a {2D} laser range scanner.},
	booktitle = {Pattern Recognition},
	publisher = {Springer Berlin / Heidelberg},
	author = {Peter Biber and Sven Fleck and Wolfgang Strasser and Carl Rasmussen and Heinrich B�lthoff and Bernhard Sch�lkopf and Martin Giese},
	year = {2004},
	keywords = {registration, slam, star},
	pages = {480--487}
},

@inproceedings{bodenmueller_online_2004,
	title = {Online surface reconstruction from unorganized {3D-points} for the {DLR} hand-guided scanner system},
	lccn = {0028},
	doi = {10.1109/TDPVT.2004.1335210},
	abstract = {Hand-guided scanners allow for digitization by manually sweeping a laser beam over an object's surface. The result highly depends on the way the user handles the system and his ability to keep track of the parts of the surface that are already scanned. Processing and visualization during data acquisition are helpful in this context. In this paper, we propose an online surface reconstruction algorithm for the visualization of the {DLR} scanner system data. The algorithm successively generates a triangle mesh by incrementally inserting {3D} points. Point neighborhoods are used to limit the point density, to estimate the surface normal at the inserted point, and to locally retriangulate the mesh. A dynamic data structure for fast neighborhood search without restrictions to the amount of vertices or the object size and with low complexity is introduced. Finally, results with the hand-guided scanner system are presented.},
	booktitle = {{3D} Data Processing, Visualization and Transmission, 2004. {3DPVT} 2004. Proceedings. 2nd International Symposium on},
	author = {T. Bodenmueller and G. Hirzinger},
	year = {2004},
	keywords = {data acquisition, data structure, data structures, data visualisation, data visualization, hand-guided scanner system, image digitization, image reconstruction, image resolution, image scanners, mesh generation, online surface reconstruction, surface fitting, surface fitting, triangle mesh},
	pages = {285--292}
},

@inproceedings{cook_face_2004,
	title = {Face recognition from {3D} data using Iterative Closest Point algorithm and Gaussian mixture models},
	lccn = {0032},
	doi = {10.1109/TDPVT.2004.1335279},
	abstract = {An approach to face verification from {3D} data is presented. The method uses {3D} registration techniques designed to work with resolution levels typical of the irregular point cloud representations provided by structured light scanning. Preprocessing using a-priori information of the human face and the Iterative Closest Point algorithm are employed to establish correspondence between test and target and to compensate for the nonrigid nature of the surfaces. Statistical modelling in the form of Gaussian mixture models is used to parameterise the distribution of errors in facial surfaces after registration and is employed to differentiate between intra- and extra-personal comparison of range images. An equal error rate of 2.67\% was achieved on the 30 subject manual subset of the 3d\_rma database.},
	booktitle = {{3D} Data Processing, Visualization and Transmission, 2004. {3DPVT} 2004. Proceedings. 2nd International Symposium on},
	author = {J. Cook and V. Chandran and S. Sridharan and C. Fookes},
	year = {2004},
	keywords = {{3D} data, {3D} registration techniques, error analysis, error distribution, face recognition, face verification, Gaussian distribution, Gaussian mixture models, image registration, image representation, image resolution, irregular point cloud representation, Iterative Closest Point algorithm, registration, solid modelling, statistical modelling, structured light scanning},
	pages = {502--509}
},

@inproceedings{dalmasso_hierarchical_2004,
	title = {Hierarchical {3D} surface reconstruction based on radial basis functions},
	lccn = {0002},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1335290},
	abstract = {Volumetric methods based on implicit surfaces are commonly used in surface reconstruction from uniformly distributed sparse {3D} data. The case of nonuniform distributed data has recently deserved more attention, because it occurs frequently in practice. This work describes a volumetric approach to surface reconstruction from nonuniform data which is suitable for the reconstruction of surfaces from images, in particular from multiple views. Differently from volumetric methods which use both {3D} surface points and surface normals, the approach does not use the surface normals because they are often unreliable when estimated from image data. The method is based on a hierarchical partitioning of the volume data set. The working volume is split and classified at different scales of spatial resolution into surface, internal and external voxels and this hierarchy is described by an octree structure in a multiscale framework. The octree structure is used to build a multiresolution description of the surface by means of compact support radial basis functions {(RBF).} A hierarchy of surface approximations at different levels of details is built by representing the voxels at the same octree level as {RBF} of similar spatial support. At each scale, information related to the reconstruction error drives the reconstruction process at the following finer scale. Preliminary results on synthetic data and future perspectives are presented.},
	booktitle = {{3D} Data Processing, Visualization and Transmission, 2004. {3DPVT} 2004. Proceedings. 2nd International Symposium on},
	author = {P Dalmasso and R Nerino},
	year = {2004},
	keywords = {geometric-modeling, implicit-representation, radial-basis-functions, surface fitting, volume-graphics},
	pages = {574--579}
},

@inproceedings{dima_classifier_2004,
	address = {New Orleans, {LA,} {USA}},
	title = {Classifier fusion for outdoor obstacle detection},
	lccn = {0042},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1307225},
	doi = {10.1109/ROBOT.2004.1307225},
	abstract = {This work describes an approach for using several levels of data fusion in the domain of autonomous off-road navigation. We are focusing on outdoor obstacle detection, and we present techniques that leverage on data fusion and machine learning for increasing the reliability of obstacle detection systems. We are combining color and infrared {(IR)} imagery with range information from a laser range finder. We show that in addition to fusing data at the pixel level, performing high level classifier fusion is beneficial in our domain. Our general approach is to use machine learning techniques for automatically deriving effective models of the classes of interest (obstacle and non-obstacle for example). We train classifiers on different subsets of the features we extract from our sensor suite and show how different classifier fusion schemes can be applied for obtaining a multiple classifier system that is more robust than any of the classifiers presented as input. We present experimental results we obtained on data collected with both the experimental unmanned vehicle {(XUV)} and a {CMU} developed robotic tractor.},
	booktitle = {{IEEE} International Conference on Robotics and Automation, 2004. Proceedings. {ICRA} '04. 2004},
	author = {{C.S.} Dima and N. Vandapel and M. Hebert},
	year = {2004},
	keywords = {classification},
	pages = {665--671 Vol.1}
},

@inproceedings{garcia_3d_2004,
	title = {{3D} simultaneous localization and modeling from stereo vision},
	volume = {1},
	lccn = {0047},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1307255},
	abstract = {This work presents a new algorithm for determining the trajectory of a mobile robot and, simultaneously, creating a detailed volumetric {3D} model of its workspace. The algorithm exclusively utilizes information provided by a single stereo vision system, avoiding thus the use both of more costly laser systems and error-prone odometry. Six-degrees-of-freedom egomotion is directly estimated from images acquired at relatively close positions along the robot's path. Thus, the algorithm can deal with both planar and uneven terrain in a natural way, without requiring extra processing stages or additional orientation sensors. The {3D} model is based on an octree that encapsulates clouds of {3D} points obtained through stereo vision, which are integrated after each egomotion stage. Every point has three spatial coordinates referred to a single frame, as well as true-color components. The spatial location of those points is continuously improved as new images are acquired and integrated into the model.},
	booktitle = {Robotics and Automation, 2004. Proceedings. {ICRA} '04. 2004 {IEEE} International Conference on},
	author = {{MA} Garcia and A Solanas},
	year = {2004},
	keywords = {3d, octree, slam},
	pages = {847--853 Vol.1}
},

@inproceedings{kamberov_topology_2004,
	address = {Thessaloniki, Greece},
	title = {Topology and geometry of unorganized point clouds},
	lccn = {0008},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1335390},
	doi = {10.1109/TDPVT.2004.1335390},
	abstract = {We present a new method for defining neighborhoods, and assigning principal curvature frames, and mean and Gauss curvatures to the points of an unorganized oriented point-cloud. The neighborhoods are estimated by measuring implicitly the surface distance between points. The {3D} shape recovery is based on conformal geometry, works directly on the cloud, does not rely on the generation of polygonal, or smooth models. Test results on publicly available synthetic data, as ground truth, demonstrate that the method compares favorably to the established approaches for quantitative {3D} shape recovery. The proposed method is developed to serve applications involving point based rendering and reliable extraction of differential properties from noisy unorganized point-clouds.},
	booktitle = {Proceedings. 2nd International Symposium on {3D} Data Processing, Visualization and Transmission, 2004. {3DPVT} 2004.},
	author = {G. Kamberov and G. Kamberova},
	year = {2004},
	keywords = {shape},
	pages = {743--750}
},

@inproceedings{kraetzschmar_probabilistic_2004,
	title = {Probabilistic Quadtrees for {Variable-Resolution} Mapping of Large Environments},
	lccn = {0014},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.59.338},
	abstract = {Probabilistic occupancy grids are a common and well-proven spatial representation used in robot mapping. However, representing very large environments with high resolution can still impose prohibitive memory requirements. A quadtree is a well-known data structure able to achieve compact representations of large two-dimensional binary arrays. We extend this idea and present probabilistic quadtrees for efficient representation and storage of probabilistic occupancy maps.},
	booktitle = {Proceedings of the 5th {IFAC/EURON} Symposium on Intelligent Autonomous Vehicles},
	publisher = {Elsevier Science},
	author = {Gerhard Kraetzschmar and Guillem Gassull and Klaus Uhl and {MI} Ribeiro and Santos Victor},
	year = {2004},
	keywords = {quadtree, star},
	annote = {{\textless}p{\textgreater}cited by 4{\textless}/p{\textgreater}}
},

@inproceedings{kuipers_local_2004,
	title = {Local metrical and global topological maps in the hybrid spatial semantic hierarchy},
	volume = {5},
	lccn = {0116},
	url = {http://dx.doi.org/10.1109/ROBOT.2004.1302485},
	abstract = {Topological and metrical methods for representing spatial knowledge have complementary strengths. We present a hybrid extension to the spatial semantic hierarchy that combines their strengths and avoids their weaknesses. Metrical {SLAM} methods are used to build local maps of small-scale space within the sensory horizon of the agent, while topological methods are used to represent the structure of large-scale space. We describe how a local perceptual map is analyzed to identify a local topology description and is abstracted to a topological place. The map building method creates a set of topological map hypotheses that are consistent with travel experience. The set of maps is guaranteed under reasonable assumptions to include the correct map. We demonstrate the method on a real environment with multiple nested large-scale loops.},
	booktitle = {Robotics and Automation, 2004. Proceedings. {ICRA} '04. 2004 {IEEE} International Conference on},
	author = {B Kuipers and J Modayil and P Beeson and M Macmahon and F Savelli},
	year = {2004},
	keywords = {cognitive map, hybrid, mapping, Semantic mapping, slam, ssh, topological},
	pages = {4845--4851 Vol.5}
},

@inproceedings{memoli_comparing_2004,
	address = {Nice, France},
	title = {Comparing point clouds},
	isbn = {3-905673-13-4},
	lccn = {0021},
	url = {http://dx.doi.org/10.1145/1057432.1057436},
	abstract = {Point clouds are one of the most primitive and fundamental surface representations. A popular source of point clouds are three dimensional shape acquisition devices such as laser range scanners. Another important field where point clouds are found is in the representation of high-dimensional manifolds by samples. With the increasing popularity and very broad applications of this source of data, it is natural and important to work directly with this representation, without having to go to the intermediate and sometimes impossible and distorting steps of surface reconstruction. A geometric framework for comparing manifolds given by point clouds is presented in this paper. The underlying theory is based on {Gromov-Hausdorff} distances, leading to isometry invariant and completely geometric comparisons. This theory is embedded in a probabilistic setting as derived from random sampling of manifolds, and then combined with results on matrices of pairwise geodesic distances to lead to a computational implementation of the framework. The theoretical and computational results here presented are complemented with experiments for real three dimensional shapes.},
	booktitle = {Proceedings of the 2004 {Eurographics/ACM} {SIGGRAPH} symposium on Geometry processing},
	publisher = {{ACM}},
	author = {Facundo M�moli and Guillermo Sapiro},
	year = {2004},
	keywords = {point cloud, theory},
	pages = {32--40},
	annote = {{\textless}p{\textgreater}same as A Theoretical and Computational Framework for Isometry Invariant Recognition of Point Cloud Data, which is journal version{\textless}/p{\textgreater}}
},

@inproceedings{miao_wang_lidar_2004,
	address = {Istanbul, Turkey},
	title = {Lidar data segmentation and classification based on octree structure},
	lccn = {0020},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.111.9934},
	abstract = {Lidar (or laser scanning) has become a viable technique for the collection of a large amount of accurate {3D} point data densely distributed on the scanned object surface. The inherent {3D} nature of the sub-randomly distributed point cloud provides abundant spatial information. To explore valuable spatial information from laser scanned data becomes an active research topic. The subrandomly distributed point cloud should be segmented and classified before the extraction of spatial information and the first step in the processing of the spatial data extraction is an organization of the lidar data. This paper proposes a new algorithm to split and merge the lidar data based on the octree structure. After the process a lidar data set can be segmented to {3D} plane clusters and classified by the plane attributes derived from each {3D} plane, such as area, gradient, intensity etc. Some example and analysis of practical data set will be performed for segmentation and classification using the proposed methods here. The test result shows the potential of applying this method to extracting spatial information from lidar data. 1. {INTRUDUCTION} Lidar (or laser scanning) has become a viable technique in recent decades. The ability of collecting a large amount of accurate {3D} point data densely distributed on the scanned object surface has brought us a new research topic {(Ackermann,} 1999). The inherent {3D} nature of the sub-randomly distributed point cloud contains abundant space information and can be further extracted for digital elevation model generation, {3D} building model reconstruction, and trees detection {(Haala} and},
	booktitle = {Geo- Imagery Bridging Continents 20th {ISPRS} Congress},
	author = {Miao Wang and Yi-hsing Tseng B},
	year = {2004},
	keywords = {classification, octree, plane fitting, star}
},

@inproceedings{mitra_registration_2004,
	address = {Nice, France},
	title = {Registration of point cloud data from a geometric optimization perspective},
	isbn = {3-905673-13-4},
	lccn = {0070},
	url = {http://dx.doi.org/10.1145/1057432.1057435},
	abstract = {We propose a framework for pairwise registration of shapes represented by point cloud data {(PCD).} We assume that the points are sampled from a surface and formulate the problem of aligning two {PCDs} as a minimization of the squared distance between the underlying surfaces. Local quadratic approximants of the squared distance function are used to develop a linear system whose solution gives the best aligning rigid transform for the given pair of point clouds. The rigid transform is applied and the linear system corresponding to the new orientation is build. This process is iterated until it converges. The point-to-point and the point-to-plane Iterated Closest Point {(ICP)} algorithms can be treated as special cases in this framework. Our algorithm can align {PCDs} even when they are placed far apart, and is experimentally found to be more stable than point-to-plane {ICP.} We analyze the convergence behavior of our algorithm and of point-to-point and point-to-plane {ICP} under our proposed framework, and derive bounds on their rate of convergence. We compare the stability and convergence properties of our algorithm with other registration algorithms on a variety of scanned data.},
	booktitle = {Proceedings of the 2004 {Eurographics/ACM} {SIGGRAPH} symposium on Geometry processing},
	publisher = {{ACM}},
	author = {Niloy Mitra and Natasha Gelfand and Helmut Pottmann and Leonidas Guibas},
	year = {2004},
	keywords = {registration},
	pages = {22--31}
},

@inproceedings{montemerlo_multi-resolution_2004,
	address = {San Jose, California},
	title = {A multi-resolution pyramid for outdoor robot terrain perception},
	isbn = {0-262-51183-5},
	lccn = {0042},
	url = {http://portal.acm.org/citation.cfm?id=1597148.1597224},
	abstract = {This paper addresses the problem of outdoor terrain modeling for the purposes of mobile robot navigation. We propose an approach in which a robot acquires a set of terrain models at differing resolutions. Our approach addresses one of the major shortcomings of Bayesian reasoning when applied to terrain modeling, namely artifacts that arise from the limited spatial resolution of robot perception. Limited spatial resolution causes small obstacles to be detectable only at close range. Hence, a Bayes filter estimating the state of terrain segments must consider the ranges at which that terrain is observed. We develop a multi-resolution approach that maintains multiple navigation maps, and derive rational arguments for the number of layers and their resolutions. We show that our approach yields significantly better results in a practical robot system, capable of acquiring detailed {3-D} maps in large-scale outdoor environments.},
	booktitle = {Proceedings of the 19th national conference on Artifical intelligence},
	publisher = {{AAAI} Press},
	author = {Michael Montemerlo and Sebastian Thrun},
	year = {2004},
	keywords = {pyramid, star},
	pages = {464--469}
},

@inproceedings{nuechter_automatic_2004,
	title = {Automatic Classification of Objects in {3D} Laser Range Scans},
	lccn = {0026},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.10.1156},
	abstract = {This paper presents a new method for object detection and classification in {3D} laser range data that is acquired by an autonomous mobile robot. Off-screen rendered depth and reflectance images serve as an input for an Ada Boost learning procedure that constructs a cascade of classifiers. The performance of the classification is improved by combining both sensor modalities, which are independent from external light. The resulting approach for object classification is real-time capable and reliable. It combines recent results in computer vision with the emerging technology of {3D} laser scanners.},
	booktitle = {In Proc. 8th Conf. on Intelligent Autonomous Systems, pages 963 � 970},
	author = {Andreas N�chter and Hartmut Surmann and Joachim Hertzberg},
	year = {2004},
	keywords = {3d, classification, integral\_image, laser, scan},
	pages = {963--970}
},

@inproceedings{payeur_improving_2004,
	address = {Boston, {MA,} {USA}},
	title = {Improving robot path planning efficiency with probabilistic virtual environment models},
	lccn = {0002},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1397177},
	doi = {10.1109/VECIMS.2004.1397177},
	abstract = {Probabilistic multiresolution occupancy grid modeling has recently been developed to map both {2D} and {3D} cluttered spaces. These models can be used to provide an enhanced representation of the cluttering state of space in a robot workspace. As a result, they reveal to be promising tools to improve classical potential field based robot path planning strategies. These approaches rely on a combination of repulsive and attractive potential fields to attract the robot toward a given goal while ensuring safe distance from the obstacles. This paper proposes an new approach to directly compute repulsive and attractive potential fields from the probabilistic occupancy models without the need for distance tables or wave propagation. Experimentation revealed that multiresolution probabilistic models encoded as quadtrees or octrees significantly reduce processing time and speed up robot operation.},
	booktitle = {2004 {IEEE} Symposium on Virtual Environments, {Human-Computer} Interfaces and Measurement Systems, 2004. {(VCIMS).}},
	author = {P. Payeur},
	year = {2004},
	keywords = {occupancy grid, octree, planning},
	pages = {13--18}
},

@book{siegwart_introduction_2004,
	title = {Introduction to Autonomous Mobile Robots},
	isbn = {{026219502X}},
	lccn = {0553},
	url = {http://portal.acm.org/citation.cfm?id=983690},
	abstract = {(book)},
	publisher = {Bradford Book},
	author = {Roland Siegwart and Illah Nourbakhsh},
	year = {2004},
	keywords = {book, kinematics, localization, locomotion, perception, planning}
},

@inproceedings{sung-bum_park_multiscale_2004,
	title = {Multiscale surface representation scheme for point clouds},
	lccn = {0000},
	doi = {10.1109/ISPACS.2004.1439051},
	abstract = {We introduce a new multiscale point cloud representation scheme based on a tree-structured multiscale piecewise plane approximation of the underlying {3D} surface geometry. Dyadic division and plane approximation of points within each dyadic cube result in a tree-structured multiscale representation of the {3D} surface described by point cloud data. We then perform a complexity-regularized tree pruning combined with adaptive control of plane thickness to obtain a very compact representation of the surface geometry. Based on its adaptivity and multiscale structure, the proposed representation scheme provides a desirable framework for modelling, coding and processing of point cloud data. We demonstrate the performance of the proposed algorithm through experiments of rendering point clouds.},
	booktitle = {Intelligent Signal Processing and Communication Systems, 2004. {ISPACS} 2004. Proceedings of 2004 International Symposium on},
	author = {{Sung-Bum} Park and H. Choi and {Sang-Uk} Lee},
	year = {2004},
	keywords = {{3D} surface geometry, adaptive control, coding, complexity-regularized tree pruning, data visualisation, dyadic division, image representation, modelling, multiscale point cloud representation, multiscale surface representation scheme, octrees, octree structure, plane fitting, processing, rendering, rendering (computer graphics), solid modelling, tree-structured multiscale piecewise plane approximation},
	pages = {232--237}
},

@misc{vandapel_natural_2004,
	title = {Natural Terrain Classification using {3-D} Ladar Data},
	lccn = {0105},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.58.1402},
	abstract = {Because of the difficulty of interpreting laser data
in a meaningful way, safe navigation in vegetated terrain is still a
daunting challenge. In this paper, we focus on the segmentation
of ladar data using local {3-D} point statistics into three classes:
clutter to capture grass and tree canopy, linear to capture thin
objects like wires or tree branches, and finally surface to capture
solid objects like ground terrain surface, rocks or tree trunks. We
present the details of the method proposed,...},
	author = {Nicolas Vandapel and Daniel Huber and Anuj Kapuria and Martial Hebert},
	year = {2004},
	keywords = {classification},
	annote = {{{\textless}p{\textgreater}SUMMARY:} the paper gives an algorithm for classification, lists the difficulties in adapting the algorithm for mobile robotic use, then gives a modified version of the algorithm and results from experiments on its implementation.  {NOTE:} the algorithm classifies point-cloud regions according to the relative magnitudes of their {PCA} scores, with classification based on mixture of Gaussians. offline labelling and model-fitting for each sensor used is required. also, the paper is a bit vague on some details...  {TECHNICAL} {DETAILS:} terrain: outdoor natural environment sensor(s): {GDRS} mobility laser on the robot (i think active sensing is used, not just continuous sweeping) vs. two stationary sensors {(SICK} \&amp; {Z+F)} vehicle: General Dynamics Robotic Systems {eXperimental} Unmanned Vehicle {(GDRS} {XUV).} Code was run on a linux laptop 750 {MB} of {RAM} and 1.2 {GHz} Pentium {III} {CPU,} connected by ethernet cable to the robot {(I'm} not sure if this means it's onboard??). vehicle speed: 2 m/s; classification was carried out every 3 sec = every 7 meters{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Hebert} talks about computing scatter (shape) matrices on a point-by-point basis to determine the class of the point. {\textless}br /{\textgreater} {\textless}br {/{\textgreater}He} defines three types of shapes: {\textless}br /{\textgreater} {\textless}br /{\textgreater}"flat" distributions (planes, ground) {(2D)} {\textless}br /{\textgreater} {\textless}br {/{\textgreater}"1D"} distributions (elongated structures such as a tree) {\textless}br /{\textgreater} {\textless}br /{\textgreater}"isotropic" distributions (full scattered vegetation) {(3D)} {\textless}br /{\textgreater} {\textless}br {/{\textgreater}The} shape matrices are constructed from the point itself and its neighbors. However, he says that doing this naively would result in outliers, so we need to be able to group points with similar local distributions into terrain regions. {\textless}br /{\textgreater} {\textless}br {/{\textgreater}He} notes that "point-by-point" could mean "cell-by-cell", though it is unclear to me if this changes the notion of neighbors. The shape matrix is computed by looking at voxel lists, which are "used for efficient access to {3-D} neighborhoods". I guess this means that "neighborhood" means all the points in your voxel (and perhaps the neighboring voxels?)� {\textless}br /{\textgreater} {\textless}br {/{\textgreater}The} eigenvalues of the scatter matrix give the axes of the ellipse containing the points, essentially. Thus, it is super-easy to use classification techniques to classify {(1D,} {2D,} or {3D?)} and use that to say (tree trunk/pole, plane/ground, bush). He used mixture of Gaussians (linear combination) as his model for Prob(features{\textbar}label) and the class label is the one that maximizes the likelihood ration, {Prob(feature{\textbar}label)/Prob(feature{\textbar}not} the label). If ratio is 0.5, it is untrustworthy. If it trained on a hand-labeled data set, of course. {\textless}br /{\textgreater} {\textless}br {/{\textgreater}One} thing about classification that I don't understand is how groups of points form classification regions. He says that the shape matrix should propagate to the neighbors, but he's super vague.{\textless}/p{\textgreater}}
},

@misc{wong_terrain_2004,
	title = {Terrain Obstacle Detection and Analysis using {LIDAR}},
	lccn = {0001},
	abstract = {Autonomy is crucial in planetary robotics where extreme distance and limited resource
availability make continuous teleoperation impractical. Environmental obstacles
represent a fundamental hurdle, as natural hazards may prevent robots from
accomplishing certain tasks by invalidating path plans. In the worst-case scenario, it may
even result in physical harm to the robot. Valuable resources can be saved by allowing
the robot to resolve most obstacles automatically and requiring manual intervention only
when absolutely necessary. Current obstacle avoidance schemes are able to detect most
monolithic obstacles easily by looking for signatures like the range gradient. However,
many terrain hazards are missed because the negotiability of passable terrain is rarely
considered. In this paper we outline the development of an obstacle detection system for
rovers used in the {PROSPECT} project at {CMU} and a general approach to terrain analysis
for robots in the lunar environment. The prototype system makes use of {LIDAR}
technology as the primary mode of sensing and specifies a {one-DOF} actuation for the
Sick {LMS} 200 sensor. Data gathered from the sensor are used to analyze the terrain for
obstacles and generate an internal hazard representation of the world. Predicted obstacles
are then assessed and assigned a certainty and threat value which will aid the robot in
navigating the environment.},
	publisher = {{CMU}},
	author = {U. Wong},
	year = {2004},
	keywords = {obstacle detection}
},

@inproceedings{wulf_2d_2004,
	address = {New Orleans, {LA,} {USA}},
	title = {{2D} mapping of cluttered indoor environments by means of {3D} perception},
	lccn = {0090},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1308934},
	doi = {10.1109/ROBOT.2004.1308934},
	abstract = {This paper presents a combination of a {3D} laser sensor and a line-base {SLAM} algorithm which together produce {2D} line maps of highly cluttered indoor environments. The key of the described method is the replacement of commonly used {2D} laser range sensors by {3D} perception. A straightforward algorithm extracts a virtual {2D} scan that also contains partially occluded walls. These virtual scans are used as input for {SLAM} using line segments as features. The paper presents the used algorithms and experimental results that were made in a former industrial bakery. The focus lies on scenes that are known to be problematic for pure {2D} systems. The results demonstrate that mapping indoor environments can be made robust with respect to both, poor odometry and clutter.},
	booktitle = {{IEEE} International Conference on Robotics and Automation, 2004. Proceedings. {ICRA} '04. 2004},
	author = {O. Wulf and {K.O.} Arras and {H.I.} Christensen and B. Wagner},
	year = {2004},
	keywords = {line, slam},
	pages = {4204--4209 Vol.4},
	annote = {{\textless}p{\textgreater}3d to 2d{\textless}/p{\textgreater}
{\textless}p{\textgreater}line-based {SLAM{\textless}/p{\textgreater}}}
},

@article{kwon_fitting_2004,
	title = {Fitting range data to primitives for rapid local {3D} modeling using sparse range point clouds},
	volume = {13},
	issn = {09265805},
	lccn = {0015},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0926580503000773},
	doi = {10.1016/j.autcon.2003.08.007},
	abstract = {Techniques to rapidly model local spaces, using {3D} range data, can enable implementation of: (1) real-time obstacle avoidance for improved safety, (2) advanced automated equipment control modes, and (3) as-built data acquisition for improved quantity tracking, engineering, and project control systems. The objective of the research reported here was to develop rapid local spatial modeling tools. Algorithms for fitting sparse range point clouds to geometric primitives such as spheres, cylinders, and cuboids have been developed as well as methods for merging primitives into assemblies. Results of experiments are presented and practical usage and limitations are discussed.},
	number = {1},
	journal = {Automation in Construction},
	author = {S Kwon},
	year = {2004},
	keywords = {cuboids, cylinders, geometric fitting, spheres},
	pages = {67--81}
},

@article{remolina_towards_2004,
	title = {Towards a general theory of topological maps},
	volume = {152},
	issn = {00043702},
	lccn = {0117},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0004370203001140},
	doi = {10.1016/S0004-3702(03)00114-0},
	abstract = {We present a general theory of topological maps whereby sensory input, topological and local metrical information are combined to define the topological maps explaining such information. Topological maps correspond to the minimal models of an axiomatic theory describing the relationships between the different sources of information explained by a map. We use a circumscriptive theory to specify the minimal models associated with this representation.

The theory here proposed is independent of the exploration strategy the agent follows when building a map. We provide an algorithm to calculate the models of the theory. This algorithm supports different exploration strategies and facilitates map disambiguation when perceptual aliasing arises.},
	number = {1},
	journal = {Artificial Intelligence},
	author = {E Remolina},
	year = {2004},
	keywords = {topological},
	pages = {47--104}
},

@article{peternell_reconstruction_2004,
	title = {Reconstruction of piecewise planar objects from point clouds},
	volume = {36},
	issn = {00104485},
	lccn = {0024},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0010448503001027},
	doi = {10.1016/S0010-4485(03)00102-7},
	abstract = {This article discusses the reverse engineering problem of reconstructing objects with planar faces. We will present the main geometric features of a modeling system which are the detection of planar faces and the generation of a cad model. The algorithms are applied to the problem of reconstruction of buildings from airborne laser scanner data.},
	number = {4},
	journal = {{Computer-Aided} Design},
	author = {M Peternell},
	year = {2004},
	keywords = {plane fitting},
	pages = {333--342}
},

@article{thrun_real-time_2004,
	title = {A {Real-Time} {Expectation-Maximization} Algorithm for Acquiring Multiplanar Maps of Indoor Environments With Mobile Robots},
	volume = {20},
	issn = {{1042-296X}},
	lccn = {0056},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1303689},
	doi = {10.1109/TRA.2004.825520},
	abstract = {This paper presents a real-time algorithm for acquiring compact three-dimensional maps of indoor environments, using a mobile robot equipped with range and imaging sensors. Building on previous work on real-time pose estimation during mapping, our approach extends the popular expectation-maximization algorithm to multisurface models, and makes it amenable to real-time execution. Maps acquired by our algorithm consist of compact sets of textured polygons that can be visualized interactively. Experimental results obtained in corridor-type environments illustrate that compact and accurate maps can be acquired in real time and in a fully automated fashion.},
	number = {3},
	journal = {{IEEE} Transactions on Robotics and Automation},
	author = {S. Thrun and C. Martin and Y. Liu and D. Hahnel and R. {Emery-Montemerlo} and D. Chakrabarti and W. Burgard},
	year = {2004},
	keywords = {geometric fitting, plane fitting, surface fitting},
	pages = {433--442}
},

@article{peternell_developable_2004,
	title = {Developable surface fitting to point clouds},
	volume = {21},
	issn = {01678396},
	lccn = {0024},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0167839604000822},
	doi = {10.1016/j.cagd.2004.07.008},
	abstract = {Given a set of data points as measurements from a developable surface, the present paper investigates the recognition and reconstruction of these objects. We investigate the set of estimated tangent planes of the data points and show that classical Laguerre geometry is a useful tool for recognition, classification and reconstruction of developable surfaces. These surfaces can be generated as envelopes of a one-parameter family of tangent planes. Finally we give examples and discuss the problems especially arising from the interpretation of a surface as set of tangent planes.},
	number = {8},
	journal = {Computer Aided Geometric Design},
	author = {M Peternell},
	year = {2004},
	keywords = {surface fitting},
	pages = {785--803}
},

@unpublished{kobbelt_survey_2004,
	title = {A Survey of {Point-Based} Techniques in Computer Graphics},
	lccn = {0159},
	abstract = {In recent years point-based geometry has gained increasing attention as an alternative surface representation, both for efficient rendering and for flexible geometry processing of highly complex {3D-models.} Point-sampled objects do neither have to store nor to maintain globally consistent topological information. Therefore they are more flexible compared to triangle meshes when it comes to handling highly complex or dynamically changing shapes. In this paper, we make an attempt to give an overview of the various point-based methods that have been proposed over the last years. In particular we review and evaluate different shape representations, geometric algorithms, and rendering methods, which use points as a universal graphics primitive.},
	author = {Leif Kobbelt and Mario Botsch},
	month = jul,
	year = {2004},
	keywords = {geometric-modeling, geometry, point cloud, representation, sampling, survey, voxelization}
},

@article{wagner_egocentric_2004,
	title = {Egocentric qualitative spatial knowledge representation for physical robots},
	volume = {49},
	issn = {0921-8890},
	lccn = {0021},
	url = {http://www.sciencedirect.com.ezproxy.tntech.edu/science/article/B6V16-4DM2DRH-1/2/2986afe65cea828e322ac49e55fc7454},
	doi = {10.1016/j.robot.2004.07.022},
	abstract = {Although recent (physical) robots have powerful sensors and actuators their abilities to show intelligent behavior is often limited. One key reason is the lack of an appropriate spatial representation. Spatial knowledge plays a crucial role in navigation, (self- and object-)localization, planning and reasoning for physically grounded robots. However, it is a major difficulty of most existing approaches that each of these tasks imposes heterogeneous requirements on the representation. In this paper, we propose an egocentric representation which relies on {1D} ordering information that still provides sufficient allocentric information to solve navigation and (self- and object-)localization tasks. Furthermore, we claim that our approach supports an efficient, incremental process based on a simple {1D-representation.}},
	number = {1-2},
	journal = {Robotics and Autonomous Systems},
	author = {T. Wagner and U. Visser and O. Herzog},
	month = nov,
	year = {2004},
	keywords = {{1D,} egocentric, Qualitative knowledge representation, Qualitative navigation, star},
	pages = {25--42}
},

@techreport{vandapel_finding_2004,
	title = {Finding Organized Structures in {3-D} {LADAR} Data},
	lccn = {0011},
	url = {http://stinet.dtic.mil/oai/oai?&verb=getRecord&metadataPrefix=html&identifier=ADA432892},
	abstract = {In this paper, we address the problem of finding concertina wire in three-dimensional {(3-D)} data. Wire entanglements constitute a major obstacle to the mobility of Unmanned Ground Vehicle because of their widespread use and the difficulty to detect them. We pose the problem in term of finding thin structures organized in complex patterns. Such problem did not received as much attention as linear and planar structures segmentation. We are interested especially in the problems posed by repetitive and symmetric structures acquired with a laser range finder. The method relies on {3-D} data projections along specific directions and {2-D} histograms comparison. The sensitivity of the classification algorithm to the parameter settings is evaluated and a segmentation method proposed.},
	author = {Nicolas Vandapel and Martial Hebert},
	month = dec,
	year = {2004},
	keywords = {algorithms, {COMPONENT} {REPORTS,} {*DETECTION,} {GROUND} {VEHICLES,} {*LADAR(LASER} {DETECTION} {AND} {RANGING),} {MILITARY} {OPERATIONS,} {NUMERICAL} {MATHEMATICS,} {OPTICAL} {DETECTION} {AND} {DETECTORS,} {*OPTICAL} {RADAR,} {RANGE} {FINDING.,} shape, {SYMMETRY,} {SYMPOSIA,} {TARGET} {DIRECTION,} {RANGE} {AND} {POSITION} {FINDING,} {TERRAIN,} {THINNESS,} {*THREE} {DIMENSIONAL,} {*UGV(UNMANNED} {GROUND} {VEHICLES),} {UNMANNED,} {WIRE}}
},

@article{thrun_autonomous_2004,
	title = {Autonomous exploration and mapping of abandoned mines},
	volume = {11},
	issn = {1070-9932},
	lccn = {0052},
	url = {http://dx.doi.org/10.1109/MRA.2004.1371614},
	abstract = {This article discusses the software architecture of an autonomous robotic system designed to explore and map abandoned mines. A new set of software tools is presented, enabling robots to acquire maps of unprecedented size and accuracy. On 30 May 2003, the robot {"Groundhog"} successfully explored and mapped a main corridor of the abandoned Mathies mine near Courtney, Pennsylvania. This article also discusses some of the challenges that arise in the subterranean environments and some the difficulties of building truly autonomous robots.},
	number = {4},
	journal = {{IEEE} Robotics \& Automation Magazine},
	author = {S Thrun and S Thayer and W Whittaker and C Baker and W Burgard and D Ferguson and D Hannel and M Montemerlo and A Morris and Z Omohundro and C Reverte and W Whittaker},
	month = dec,
	year = {2004},
	keywords = {3d, application, robotics},
	pages = {79--91}
},

@article{beeson_towards_2005,
	title = {Towards Autonomous Topological Place Detection Using the Extended Voronoi Graph},
	lccn = {0069},
	abstract = {Autonomous place detection has long been a major hurdle to topological map-building techniques. Theoretical work on topological mapping has assumed that places can be reliably detected by a robot, resulting in deterministic actions. Whether or not deterministic place detection is always achievable is controversial; however, even topological mapping algorithms that assume non-determinism benefit from highly reliable place detection. Unfortunately, topological map-building implementations often have hand-coded place detection algorithms that are brittle and domain dependent. This paper presents an algorithm for reliable autonomous place detection that is sensor and domain independent. A preliminary implementation of this algorithm for an indoor robot has demonstrated reliable place detection in real-world environments, with no a priori environmental knowledge. The implementation uses a local, scrolling {2D} occupancy grid and a real-time calculated Voronoi graph to find the skeleton of the free space in the local surround. In order to utilize the place detection algorithm in non-corridor environments, we also introduce the extended Voronoi graph {(EVG),} which seamlessly transitions from a skeleton of a midline in corridors to a skeleton that follows walls in rooms larger than the local scrolling map.},
	journal = {Robotics and Automation, 2005. Proceedings of the 2005 {IEEE} International Conference on},
	author = {P Beeson and {NK} Jong and B Kuipers},
	year = {2005},
	keywords = {topological, voronoi},
	pages = {4373--4379}
},

@misc{blandford_compact_2005,
	title = {Compact Data Structures with Fast Queries},
	lccn = {0010},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.60.2981},
	abstract = {Many applications dealing with large data structures can benefit from keeping them in compressed

form. Compression has many benefits: it can allow a representation to fit in main memory

rather than swapping out to disk, and it improves cache performance since it allows more

data to fit into the cache. However, a data structure is only useful if it allows the application to

perform fast queries (and updates) to the data.},
	author = {Daniel Blandford},
	year = {2005},
	keywords = {compression}
},

@incollection{zhang_evaluating_2005,
	series = {Lecture Notes in Computer Science},
	title = {Evaluating Techniques for Resolving Redundant Information and Specularity in Occupancy Grids},
	volume = {3809},
	lccn = {0005},
	url = {http://dx.doi.org/10.1007/11589990_26},
	abstract = {In this paper we consider the effect that techniques designed to deal with the problems of redundant information and erroneous sensory data have on the results of robotic mapping. We accomplish this by evaluating several configurations of these techniques using identical test data. Through evaluating the results of these experiments using an extensible benchmarking suite, that our group has developed, we outline which technique yields the greatest environmental representational gain.},
	booktitle = {{AI} 2005: Advances in Artificial Intelligence},
	publisher = {Springer Berlin / Heidelberg},
	author = {Shichao Zhang and Ray Jarvis and Thomas Collins and {J.J.} Collins and Mark Mansfield and Shane {O�Sullivan}},
	year = {2005},
	keywords = {occupancy grid},
	pages = {235--244}
},

@inproceedings{dey_normal_2005,
	address = {Stony Brook, {NY,} {USA}},
	title = {Normal estimation for point clouds: a comparison study for a Voronoi based method},
	lccn = {0033},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1500316},
	doi = {10.1109/PBG.2005.194062},
	abstract = {Many applications that process a point cloud data benefit from a reliable normal estimation step. Given a point cloud presumably sampled from an unknown surface, the problem is to estimate the normals of the surface at the data points. Two approaches, one based on numerical optimizations and another based on Voronoi diagrams are known for the problem. Variations of numerical approaches work well even when point clouds are contaminated with noise. Recently a variation of the Voronoi based method is proposed for noisy point clouds. The centrality of the normal estimation step in point cloud processing begs a thorough study of the two approaches so that one knows which approach is appropriate for what circumstances. This paper presents such results.},
	booktitle = {Proceedings {Eurographics/IEEE} {VGTC} Symposium {Point-Based} Graphics, 2005.},
	author = {{T.K.} Dey and G. Li and J. Sun},
	year = {2005},
	keywords = {normal estimation, voronoi},
	pages = {39--46}
},

@misc{eppstein_skip_2005,
	title = {The Skip Quadtree: A Simple Dynamic Data Structure for Multidimensional Data},
	url = {http://arxiv.org/abs/cs.CG/0507049},
	abstract = {We present a new multi-dimensional data structure, which we call the skip
quadtree (for point data in R{\textasciicircum}2) or the skip octree (for point data in R{\textasciicircum}d,
with constant d{\textgreater}2). Our data structure combines the best features of two
well-known data structures, in that it has the well-defined "box"-shaped
regions of region quadtrees and the logarithmic-height search and update
hierarchical structure of skip lists. Indeed, the bottom level of our structure
is exactly a region quadtree (or octree for higher dimensional data). We
describe efficient algorithms for inserting and deleting points in a skip
quadtree, as well as fast methods for performing point location and approximate
range queries.},
	author = {David Eppstein and Michael Goodrich and Jonathan Sun},
	year = {2005},
	keywords = {computational-geometry, data-structure, k-d-tree, quadtree, skip},
	howpublished = {{http://arxiv.org/abs/cs.CG/0507049}}
},

@inproceedings{grisetti_improving_2005,
	title = {Improving Grid-based {SLAM} with {Rao-Blackwellized} Particle Filters by Adaptive Proposals and Selective Resampling},
	lccn = {0208},
	doi = {10.1109/ROBOT.2005.1570477},
	abstract = {Recently {Rao-Blackwellized} particle filters have been introduced as effective means to solve the simultaneous localization and mapping {(SLAM)} problem. This approach uses a particle filter in which each particle carries an individual map of the environment. Accordingly, a key question is how to reduce the number of particles. In this paper we present adaptive techniques to reduce the number of particles in a {Rao-Blackwellized} particle filter for learning grid maps. We propose an approach to compute an accurate proposal distribution taking into account not only the movement of the robot but also the most recent observation. This drastically decrease the uncertainty about the robot's pose in the prediction step of the filter. Furthermore, we present an approach to selectively carry out re-sampling operations which seriously reduces the problem of particle depletion. Experimental results carried out with mobile robots in large-scale indoor as well as in outdoor environments illustrate the advantages of our methods over previous approaches.},
	booktitle = {Robotics and Automation, 2005. {ICRA} 2005. Proceedings of the 2005 {IEEE} International Conference on},
	author = {G. Grisetti and C. Stachniss and W. Burgard},
	year = {2005},
	keywords = {occupancy grid, particle-filter, slam},
	pages = {2432--2437}
},

@inproceedings{gumhold_predictive_2005,
	address = {Los Angeles, California},
	title = {Predictive point-cloud compression},
	lccn = {0018},
	abstract = {Point clouds have recently become a popular alternative to polygonal
meshes for representing three-dimensional geometric models.
{3D} photography and scanning systems acquire the geometry and
appearance of real-world objects in form of point samples. Rendering
directly with points eliminates the complex task of reconstructing
a surface and allows handling of non-surfaces like models such
as trees. With modern acquisition techniques producing larger and
larger amounts of points, efficient schemes for compressing such
data have become necessary.
Several methods for compressing point clouds have been proposed.
Two methods that recursively subdivide the bounding box are the
kd-tree approach of Devillers and Gandoin [2000] and the oct-tree
approach of Peng and Kuo [2003]. One drawback of these spatial
subdivision methods is that they do not generalize to include attribute
data such as normals and colors. The method {ofWaschb�usch}
et al. [2004] generates a binary tree over the points by pairing closeby
points. Each pair is replaced by its centroid to form the next
coarser level. This approach generalizes to include attributes. Coding
starts at the coarsest level using a predictive scheme and local
coordinate systems.},
	booktitle = {{ACM} {SIGGRAPH} 2005 Sketches},
	publisher = {{ACM}},
	author = {Stefan Gumhold and Zachi Kami and Martin Isenburg and {Hans-Peter} Seidel},
	year = {2005},
	keywords = {compression, k-d-tree, octree},
	pages = {137}
},

@inproceedings{jianning_wang_reconstructing_2005,
	address = {Minneapolis, {MN,} {USA}},
	title = {Reconstructing Manifold and {Non-Manifold} Surfaces from Point Clouds},
	lccn = {0014},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1532824},
	doi = {10.1109/VISUAL.2005.1532824},
	abstract = {This paper presents a novel approach for surface reconstruction from point clouds. The proposed technique is general in the sense that it naturally handles both manifold and non-manifold surfaces, providing a consistent way for reconstructing closed surfaces as well as surfaces with boundaries. It is also robust in the presence of noise, irregular sampling and surface gaps. Furthermore, it is fast, parallelizable and easy to implement because it is based on simple local operations. In this approach, surface reconstruction consists of three major steps: first, the space containing the point cloud is subdivided, creating a voxel representation. Then, a voxel surface is computed using gap filling and topological thinning operations. Finally, the resulting voxel surface is converted into a polygonal mesh. We demonstrate the effectiveness of our approach by reconstructing polygonal models from range scans of real objects as well as from synthetic data.},
	booktitle = {{VIS} 05. {IEEE} Visualization, 2005.},
	author = {Jianning Wang and {M.M.} Oliveira and {A.E.} Kaufman},
	year = {2005},
	keywords = {surface fitting},
	pages = {415--422}
},

@incollection{kamberov_3d_2005,
	title = {{3D} Shape from Unorganized {3D} Point Clouds},
	lccn = {0004},
	url = {http://dx.doi.org/10.1007/11595755_76},
	abstract = {We present a framework to automatically infer topology and geometry from an unorganized {3D} point cloud obtained from a {3D} scene. If the cloud is not oriented, we use existing methods to orient it prior to recovering the topology. We develop a quality measure for scoring a chosen topology/orientation. The topology is used to segment the cloud into manifold components and later in the computation of shape descriptors.},
	booktitle = {Advances in Visual Computing},
	author = {George Kamberov and Gerda Kamberova and Amit Jain},
	year = {2005},
	keywords = {3d, shape, unsupervised, voxel},
	pages = {621--629}
},

@inproceedings{lalonde_scale_2005,
	address = {Ottawa, {ON,} Canada},
	title = {Scale Selection for Classification of {Point-Sampled} {3-D} Surfaces},
	lccn = {0017},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1443257},
	doi = {10.1109/3DIM.2005.71},
	abstract = {Three-dimensional ladar data are commonly used to perform scene understanding for outdoor mobile robots, specifically in natural terrain. One effective method is to classify points using features based on local point cloud distribution into surfaces, linear structures or clutter volumes. But the local features are computed using {3D} points within a support-volume. Local and global point density variations and the presence of multiple manifolds make the problem of selecting the size of this support volume, or scale, challenging. In this paper, we adopt an approach inspired by recent developments in computational geometry {(Mitra} et al., 2005) and investigate the problem of automatic data-driven scale selection to improve point cloud classification. The approach is validated with results using data from different sensors in various environments classified into different terrain types (vegetation, solid surface and linear structure).},
	booktitle = {Fifth International Conference on {3-D} Digital Imaging and Modeling {(3DIM'05)}},
	author = {J. Lalonde and R. Unnikrishnan and N. Vandapel and M. Hebert},
	year = {2005},
	keywords = {classification, surface fitting},
	pages = {285--292}
},

@inproceedings{li_multi-scale_2005,
	address = {Vienna, Austria},
	title = {Multi-scale features for approximate alignment of point-based surfaces},
	isbn = {{3-905673-24-X}},
	lccn = {0064},
	abstract = {We introduce a novel method for approximate alignment of point-based surfaces. Our approach is based on detecting a set of salient feature points using a scale-space representation. For each feature point we compute a signature vector that is approximately invariant under rigid transformations. We use the extracted signed feature set in order to obtain approximate alignment of two surfaces. We apply our method for the automatic alignment of multiple scans using both scan-to-scan and scan-to-model matching capabilities.},
	booktitle = {Proceedings of the third Eurographics symposium on Geometry processing},
	publisher = {Eurographics Association},
	author = {Xinju Li and Igor Guskov},
	year = {2005},
	keywords = {registration},
	pages = {217}
},

@book{manolopoulos_r-trees:_2005,
	title = {{R-Trees:} Theory and Applications {(Advanced} Information and Knowledge Processing)},
	isbn = {1852339772},
	lccn = {0031},
	url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&path=ASIN/1852339772},
	abstract = {Space support in databases poses new challenges in every part of a database
management system \& the capability of spatial support in the physical layer is
considered very important. This has led to the design of spatial access
methods to enable the effective \& efficient management of spatial objects.

R-trees have a simplicity of structure \& together with their resemblance to
the B-tree, allow developers to incorporate them easily into existing database
management systems for the support of spatial query processing.

This book provides an extensive survey of the R-tree evolution, studying the
applicability of the structure \& its variations to efficient query processing,
accurate proposed cost models, \& implementation issues like concurrency
control and parallelism. Written for database researchers, designers \&
programmers as well as graduate students, this comprehensive monograph will be
a welcome addition to the field.},
	publisher = {Springer},
	author = {Yannis Manolopoulos and Alexandros Nanopoulos and Apostolos Papadopoulos and Y Theodoridis},
	year = {2005},
	keywords = {algorithms, books, diss-lit-pa, gis-algorithms, r-tree}
},

@inproceedings{mederos_surface_2005,
	address = {Vienna, Austria},
	title = {Surface reconstruction from noisy point clouds},
	isbn = {{3-905673-24-X}},
	lccn = {0044},
	url = {http://portal.acm.org/citation.cfm?id=1281920.1281929},
	abstract = {We show that a simple modification of the power crust algorithm for surface reconstruction produces correct outputs in presence of noise. This is proved using a fairly realistic noise model. Our theoretical results are related to the problem of computing a stable subset of the medial axis. We demostrate the effectiveness of our algorithm with a number of experimental results.},
	booktitle = {Proceedings of the third Eurographics symposium on Geometry processing},
	publisher = {Eurographics Association},
	author = {Boris Mederos and Nina Amenta and Luiz Velho and Luiz de Figueiredo},
	year = {2005},
	keywords = {surface fitting}
},

@inproceedings{paskin_robotic_2005,
	title = {Robotic mapping with polygonal random fields},
	lccn = {0010},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.126.6281},
	abstract = {Two types of probabilistic maps are popular in the mobile robotics literature: occupancy grids and geometric maps. Occupancy grids have the advantages of simplicity and speed, but they represent only a restricted class of maps and they make incorrect independence assumptions. On the other hand, current geometric approaches, which characterize the environment by features such as line segments, can represent complex environments compactly. However, they do not reason explicitly about occupancy, a necessity for motion planning; and, they lack a complete probability model over environmental structures. In this paper we present a probabilistic mapping technique based on polygonal random fields {(PRF),} which combines the advantages of both approaches. Our approach explicitly represents occupancy using a geometric representation, and it is based upon a consistent probability distribution over environments which avoids the incorrect independence assumptions made by occupancy grids. We show how sampling techniques for {PRFs} can be applied to localized laser and sonar data, and we demonstrate significant improvements in mapping performance over occupancy grids. 1},
	booktitle = {In 21st Conf. on Uncertainty in Artificial Intelligence},
	author = {Mark Paskin},
	year = {2005},
	keywords = {graphical models, hybrid, polygonal random field}
},

@article{stepan_robust_2005,
	title = {Robust data fusion with occupancy grid},
	volume = {35},
	lccn = {0026},
	url = {http://dx.doi.org/10.1109/TSMCC.2004.840048},
	abstract = {Accurate models of the environment are a crucial requirement for autonomous mobile robots. The process of how to acquire knowledge about the operating environment is one of the most challenging problems in this research area. The quality of the model depends on the number and types of sensors used. Occupancy grids are the most common low-level models of the environment used in robotics for fusion of noisy data. This paper first introduces a novel method for building an occupancy grid from a monocular color camera. The next part of the work describes a method for fusion of camera data with data from a rangefinder. The final part presents a new method for measuring the quality of the occupancy grid based on the quality of the path created by the grid. The methods were experimentally verified with an indoor experimental robot at the Czech Technical University.},
	number = {1},
	journal = {Systems, Man, and Cybernetics, Part C: Applications and Reviews, {IEEE} Transactions on},
	author = {P Stepan and M Kulich and L Preucil},
	year = {2005},
	keywords = {data, fusion, nc2if, occupancy grid},
	pages = {106--115}
},

@book{thrun_probabilistic_2005,
	title = {Probabilistic robotics},
	isbn = {0262201623},
	lccn = {1699},
	url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&path=ASIN/0262201623},
	abstract = {Probablistic robotics is a growing area in the subject, concerned with perception and control in the face of uncertainty and giving robots a level of robustness in real-world situations. This book introduces techniques and algorithms in the field.},
	publisher = {{MIT} Press},
	author = {Sebastian Thrun and Wolfram Burgard and Dieter Fox},
	year = {2005},
	keywords = {book, robotics, star},
	annote = {{{\textless}p{\textgreater}Contains} really gereat background section at the end of the chapter on occupancy grids...{\textless}/p{\textgreater}}
},

@inproceedings{tuley_analysis_2005,
	title = {Analysis and Removal of Artifacts in {3-D} {LADAR} Data},
	lccn = {0025},
	abstract = {Mixed pixels are points in {LADAR} data which occur when the measurement beam intersects two objects at within a certain range of distances apart. The resulting return signal represents data from both objects; the laser electronics read this as a single point, but not at the real location of either object. As such, mixed pixels present an obstacle to accurate analysis of a scene. We present a survey of mixed pixel phenomena and a method of removing mixed pixels from scenes stored as {3-D} points. Our method does not depend on the sensor used to originally collect the data, and is efficient and effective.},
	booktitle = {Proc Int. Conf. Robotics and Automation},
	author = {J Tuley and N Vandapel and M Hebert},
	year = {2005},
	keywords = {mixed pixels, point clouds}
},

@inproceedings{wolf_towards_2005,
	address = {Edmonton, {AB,} Canada},
	title = {Towards Geometric {3D} Mapping of Outdoor Environments Using Mobile Robots},
	lccn = {0025},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1545152},
	doi = {10.1109/IROS.2005.1545152},
	abstract = {This paper presents an approach to generating compact {3D} maps of urban environments using mobile robots and laser range finders. Our algorithm extracts planar information from {3D} point cloud maps. The planar representation is very efficient for representing building structures in urban environments when a high level of detail is not required. We also present preliminary results on {3D} geometric mapping with incomplete data. Based on previously known models and incomplete data, our system is able to estimate parts of buildings which have never been seen before. As validation, we present experimental results using a Segway {RMP} vehicle in two environments, both approximately the size of a city block.},
	booktitle = {2005 {IEEE/RSJ} International Conference on Intelligent Robots and Systems},
	author = {D. Wolf and A. Howard and {G.S.} Sukhatme},
	year = {2005},
	keywords = {geometric, plane fitting},
	pages = {1258--1263}
},

@inproceedings{wulf_colored_2005,
	address = {Sendai, Japan},
	title = {Colored {2D} maps for robot navigation with {3D} sensor data},
	lccn = {0025},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1389864},
	doi = {10.1109/IROS.2004.1389864},
	abstract = {This paper presents a navigation system for mobile service robots working in urban environments. The system combines a {3D} laser sensor with {2D} algorithms for path planning and simultaneous localization and mapping {(SLAM).} In contrast to other map representations the colored {2D} map, first presented in this paper, is able to hold information adapted to both localization and path planning. The functionality of our approach is demonstrated by an experiment for online navigation with {3D} data.},
	booktitle = {2004 {IEEE/RSJ} International Conference on Intelligent Robots and Systems {(IROS)} {(IEEE} Cat. {No.04CH37566)}},
	author = {O. Wulf and C. Brenneke and B. Wagner},
	year = {2005},
	keywords = {colored map, star},
	pages = {2991--2996}
},

@inproceedings{howard_towards_2005,
	address = {Sendai, Japan},
	title = {Towards {3D} mapping in large urban environments},
	lccn = {0048},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1389388},
	doi = {10.1109/IROS.2004.1389388},
	abstract = {This paper describes work-in-progress aimed at generating dense {3D} maps of urban environments using laser range data acquired from a moving platform. These maps display both fine-scale detail (resolving features only a few centimeters across) and large-scale consistency (typical maps are approximately 0.5 km on a side). In this paper, we sketch a basic {3D} mapping algorithm (paying particular attention to practical engineering details) and present preliminary results acquired on the {USC} University Park campus using a Segway {RMP} vehicle.},
	booktitle = {2004 {IEEE/RSJ} International Conference on Intelligent Robots and Systems {(IROS)} {(IEEE} Cat. {No.04CH37566)}},
	author = {A. Howard and {D.F.} Wolf and {G.S.} Sukhatme},
	month = feb,
	year = {2005},
	keywords = {3d, application, mapping},
	pages = {419--424}
},

@inproceedings{modayil_using_2005,
	address = {Sendai, Japan},
	title = {Using the topological skeleton for scalable global metrical map-building},
	lccn = {0035},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1389613},
	doi = {10.1109/IROS.2004.1389613},
	abstract = {Most simultaneous localization and mapping {(SLAM)} approaches focus on purely metrical approaches to map-building. We present a method for computing the global metrical map that builds on the structure provided by a topological map. This allows us to factor the uncertainty in the map into local metrical uncertainty (which is handled well by existing {SLAM} methods), global topological uncertainty (which is handled well by recently developed topological map-learning methods), and global metrical uncertainty (which can be handled effectively once the other types of uncertainty are factored out). We believe that this method for building the global metrical map is scalable to very large environments.},
	booktitle = {2004 {IEEE/RSJ} International Conference on Intelligent Robots and Systems {(IROS)} {(IEEE} Cat. {No.04CH37566)}},
	author = {J. Modayil and P. Beeson and B. Kuipers},
	month = feb,
	year = {2005},
	keywords = {hybrid, slam},
	pages = {1530--1536}
},

@phdthesis{gupta_monte_2005,
	title = {Monte Carlo localization for robots using dynamically expanding occupancy grids},
	lccn = {0003},
	url = {http://hdl.handle.net/2346/1010},
	abstract = {The past few years have seen tremendous growth in the
research areas of Mobile Robotics. While growth has been
fast and several problems have been very splendidly solved
most mobile roboticists are faced with two primary
challenges: how will the robot gather information about its
environment and how will it know where it is? These two
problems are referred to as: (i). Mapping and (ii).
Localization. Mapping is the process whereby a robot can
extract relevant information from its environment allowing
it to "remember" it. Localization is using this stored map
to move about in the environment with a clear sense of
direction because the robot knows where it is, by referring
to the map. Localization is the problem of estimating a
robot’s pose relative to a map of its environment.
However, both these problems are computationally intensive
to solve and furthermore, limitations on a robot’s on
board computational abilities and inaccuracies in sensor
hardware and motor effectors make it even harder. Most
mapping techniques are limited by memory and hence a robot
has a limitation on the area that it can directly map. Also,
if the mapped area is extended, most mapping implementations
require that the mapping parameters be changed and the
entire mapping algorithm be executed again. However, in
recent times a new mapping technique was explored which is
that of using Dynamically Expanding Occupancy Grids {(Ellore}
2002), and of using a Centralized Storage System {(Barnes,}
Quasny, Garcia, and Pyeatt 2004). By using this approach,
the robot has virtually unlimited storage space and a small
initial map which grows as the robots explores its
environment. Localization has not yet been attempted using
Dynamically Expanding Occupancy Grids and a Centralised
Storage System. This research is geared towards implementing
{Monte-Carlo} Localization methods {(Fox,} Burgard, Dellaert,
and Thrun 1999; Dellaert, {Fox,Burgard,} and Thrun ; Thrun,
Fox, Burgard, and Dellaert 2001; Fox, Thrun, Burgard, and
Dellaert 2001) to robots using Dynamically Expanding
Occupancy Grids. By using this approach this research aims
to provide a complete mapping and localization
implementation for robots using dynamically expanding
occupancy grids and a centralized storage system.},
	school = {Texas Tech University},
	author = {Karan M. Gupta and Karan M. Gupta},
	month = apr,
	year = {2005},
	keywords = {dynamically expanding occupancy grid, localization, occupancy grid, star}
},

@inproceedings{mozos_supervised_2005,
	title = {Supervised Learning of Places from Range Data using {AdaBoost}},
	lccn = {0087},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1570363},
	abstract = {This paper addresses the problem of classifying places in the environment of a mobile robot into semantic categories. We believe that semantic information about the type of place improves the capabilities of a mobile robot in various domains including localization, path-planning, or human-robot interaction. Our approach uses {AdaBoost,} a supervised learning algorithm, to train a set of classifiers for place recognition based on laser range data. In this paper we describe how this approach can be applied to distinguish between rooms, corridors, doorways, and hallways. Experimental results obtained in simulation and with real robots demonstrate the effectiveness of our approach in various environments.},
	booktitle = {Robotics and Automation, 2005. {ICRA} 2005. Proceedings of the 2005 {IEEE} International Conference on},
	author = {{OM} Mozos and C Stachniss and W Burgard},
	month = apr,
	year = {2005},
	keywords = {classification, exploration, indoor, navigation, robotics, semantic-label, topological-map},
	pages = {1730--1735}
},

@inproceedings{biber_dynamic_2005,
	address = {Cambridge, {USA}},
	title = {Dynamic Maps for {Long-Term} Operation of Mobile Service Robots},
	lccn = {0032},
	abstract = {This paper introduces a dynamic map for mobile robots that adapts continuously over time. It resolves the stabilityplasticity dilemma (the trade-off between adaptation to new patterns and preservation of old patterns) by representing the environment over multiple timescales simultaneously (5 in our experiments). A sample-based representation is proposed, where older memories fade at different rates depending on the timescale. Robust statistics are used to interpret the samples. It is shown that this approach can track both stationary and non-stationary elements of the environment, covering the full spectrum of variations from moving objects to structural changes. The method was evaluated in a five week experiment in a real dynamic environment. Experimental results show that the resulting map is stable, improves its quality over time and adapts to changes.},
	booktitle = {Proceedings of Robotics: Science and Systems},
	author = {Peter Biber and Tom Duckett},
	month = jun,
	year = {2005},
	keywords = {dynamic}
},

@article{memoli_theoretical_2005,
	title = {A Theoretical and Computational Framework for Isometry Invariant Recognition of Point Cloud Data},
	volume = {5},
	issn = {1615-3375},
	lccn = {0084},
	url = {http://dx.doi.org/10.1007/s10208-004-0145-y},
	abstract = {Point clouds are one of the most primitive and fundamental manifold representations. Popular sources of point clouds are three-dimensional shape acquisition devices such as laser range scanners. Another important field where point clouds are found is in the representation of high-dimensional manifolds by samples. With the increasing popularity and very broad applications of this source of data, it is natural and important to work directly with this representation, without having to go through the intermediate and sometimes impossible and distorting steps of surface reconstruction. A geometric framework for comparing manifolds given by point clouds is presented in this paper. The underlying theory is based on {Gromov-Hausdorff} distances, leading to isometry invariant and completely geometric comparisons. This theory is embedded in a probabilistic setting as derived from random sampling of manifolds, and then combined with results on matrices of pairwise geodesic distances to lead to a computational implementation of the framework. The theoretical and computational results presented here are complemented with experiments for real three-dimensional shapes.},
	number = {3},
	journal = {Foundations of Computational Mathematics},
	author = {Facundo M�moli and Guillermo Sapiro},
	month = jul,
	year = {2005},
	keywords = {point cloud, theory},
	pages = {313--347}
},

@article{yang_fitting_2005,
	title = {Fitting unorganized point clouds with active implicit B-spline curves},
	volume = {21},
	issn = {0178-2789},
	lccn = {0030},
	url = {http://dx.doi.org/10.1007/s00371-005-0340-0},
	abstract = {In computer-aided geometric design and computer graphics, fitting point clouds with a smooth curve (known as curve reconstruction) is a widely investigated problem. In this paper, we propose an active model to solve the curve reconstruction problem, where the point clouds are approximated by an implicit B-spline curve, i.e., the zero set of a bivariate tensor-product B-spline function. We minimize the geometric distance between the point clouds and the implicit B-spline curve and an energy term (or smooth term) which helps to extrude the possible extra branches of the implicit curve. In each step of the iteration, the trust region algorithm in optimization theory is applied to solve the corresponding minimization problem. We also discuss the proper choice of the initial shape of the approximation curve. Examples are provided to illustrate the effectiveness and robustness of our algorithm. The examples show that the proposed algorithm is capable of handling point clouds with complicated topologies.},
	number = {8},
	journal = {The Visual Computer},
	author = {Zhouwang Yang and Jiansong Deng and Falai Chen},
	month = sep,
	year = {2005},
	keywords = {Computer Science, spline},
	pages = {831--839}
},

@inproceedings{tapus_incremental_2005,
	address = {Edmonton, {AB,} Canada},
	title = {Incremental Robot Mapping with Fingerprints of Places},
	lccn = {0050},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1544977},
	doi = {10.1109/IROS.2005.1544977},
	abstract = {Even today, robot mapping is one of the biggest challenges in mobile robotics. Geometric or topological maps can be used by a robot to navigate in the environment. Automatic creation of such maps is still problematic if the robot tries to map large environments. This paper presents a new method for incremental mapping using fingerprints of places. This type of representation permits a reliable, compact, and distinctive environment-modeling and makes navigation and localization easier for the robot. Experimental results for incremental mapping using a mobile robot equipped with a multi-sensor system composed of two 180� laser range finders and an omni-directional camera are also reported.},
	booktitle = {2005 {IEEE/RSJ} International Conference on Intelligent Robots and Systems},
	author = {A. Tapus and R. Siegwart},
	month = dec,
	year = {2005},
	keywords = {fingerprints, mapping, star},
	pages = {172--177}
},

@inproceedings{bailey_consistency_2006,
	title = {Consistency of the {FastSLAM} algorithm},
	lccn = {0077},
	url = {http://dx.doi.org/10.1109/ROBOT.2006.1641748},
	abstract = {This paper presents an analysis of {FastSLAM} - a {Rao-Blackwellised} particle filter formulation of simultaneous localisation and mapping. It shows that the algorithm degenerates with time, regardless of the number of particles used or the density of landmarks within the environment, and would always produce optimistic estimates of uncertainty in the long-term. In essence, {FastSLAM} behaves like a non-optimal local search algorithm; in the short-term it may produce consistent uncertainty estimates but, in the long-term, it is unable to adequately explore the state-space to be a reasonable Bayesian estimator. However, the number of particles and landmarks does affect the accuracy of the estimated mean and, given sufficient particles, {FastSLAM} can produce good non-stochastic estimates in practice. {FastSLAM} also has several practical advantages, particularly with regard to data association, and would probably work well in combination with other versions of stochastic {SLAM,} such as {EKF-based} {SLAM}},
	booktitle = {Robotics and Automation, 2006. {ICRA} 2006. Proceedings 2006 {IEEE} International Conference on},
	author = {T Bailey and J Nieto and E Nebot},
	year = {2006},
	keywords = {algorithm, and, association, bayes, data, estimator, fastslam, filter, filtering, formulation, local, localisation, mapping, methods, nonoptimal, numerical, particle, path, planning, problemsbayesian, robots, search, simultaneous},
	pages = {424--429}
},

@inproceedings{cole_using_2006,
	title = {Using laser range data for {3D} {SLAM} in outdoor environments},
	lccn = {0079},
	url = {http://dx.doi.org/10.1109/ROBOT.2006.1641929},
	abstract = {Traditional simultaneous localization and mapping {(SLAM)} algorithms have been used to great effect in flat, indoor environments such as corridors and offices. We demonstrate that with a few augmentations, existing {2D} {SLAM} technology can be extended to perform full {3D} {SLAM} in less benign, outdoor, undulating environments. In particular, we use data acquired with a {3D} laser range finder. We use a simple segmentation algorithm to separate the data stream into distinct point clouds, each referenced to a vehicle position. The {SLAM} technique we then adopt inherits much from {2D} delayed state (or scan-matching) {SLAM} in that the state vector is an ever growing stack of past vehicle positions and inter-scan registrations are used to form measurements between them. The registration algorithm used is a novel combination of previous techniques carefully balancing the need for maximally wide convergence basins, robustness and speed. In addition, we introduce a novel post-registration classification technique to detect matches which have converged to incorrect local minima},
	booktitle = {Robotics and Automation, 2006. {ICRA} 2006. Proceedings 2006 {IEEE} International Conference on},
	author = {{DM} Cole and {PM} Newman},
	year = {2006},
	keywords = {3d, slam},
	pages = {1556--1563}
},

@incollection{dey_normal_2006,
	title = {Normal and Feature Approximations from Noisy Point Clouds},
	volume = {4337},
	isbn = {978-3-540-49994-7},
	lccn = {0013},
	url = {http://dx.doi.org/10.1007/11944836_5},
	abstract = {We consider the problem of approximating normal and feature sizes of a surface from point cloud data that may be noisy. These problems are central to many applications dealing with point cloud data. In the noise-free case, the normals and feature sizes can be approximated by the centers of a set of unique large Delaunay balls called polar balls. In presence of noise, polar balls do not necessarily remain large and hence their centers may not be good for normal and feature size approximations. Earlier works suggest that some large Delaunay balls can play the role of polar balls. However, these results were short in explaining how the big Delaunay balls should be chosen for reliable approximations and how the approximation error depends on various factors. We provide new analyses that fill these gaps. In particular, they lead to new algorithms for practical and reliable normal and feature approximations.},
	booktitle = {{FSTTCS} 2006: Foundations of Software Technology and Theoretical Computer Science},
	publisher = {Springer Berlin / Heidelberg},
	author = {Tamal Dey and Jian Sun and S {Arun-Kumar} and Naveen Garg},
	year = {2006},
	keywords = {normal estimation, shape},
	pages = {21--32}
},

@article{goncalves_analysis_2006,
	title = {Analysis of interpolation errors in urban digital surface models created from Lidar data},
	lccn = {0009},
	abstract = {n urban areas Light Dectection and Ranging {(LIDAR)} data is becoming a widely available
source for the construction of Digital Surface Models {(DSMs).} Because the urban surfaces
have specific geometric characteristics such as discontinuities in terms of elevation and slope
gradient, the interpolation of the irregularly spaced set of Lidar points to a regular grid have
to be done carefully. In fact, many of the commercial {GIS} interpolation packages are based on
the assumption that the surface is smoothly undulating. The choice of one of these
interpolation functions will introduce errors across the surface models that they will be more
expressive in the presence of surface discontinuities. Any subsequent analysis of the
interpolated urban surface model, such as flood and viewshed analysis, feature extraction or
image segmentation will be affected by propagation of these errors. In this paper, the pattern
of errors and the general characteristics of six well-known interpolation methods (nearest
neighbour, inverse distance weighting, triangulation with linear interpolation, minimum
curvature, kriging and radial basis functions) are analysed using data either from synthetic
surface models and from real urban scenes},
	journal = {7th International Symposium on Spatial Accuracy Assessment in Natural Resources and Environmental Sciences.},
	author = {G. Gon�alves},
	year = {2006},
	keywords = {aliasing, point cloud, star},
	pages = {160--168}
},

@article{lalonde_automatic_2006,
	title = {Automatic {Three-Dimensional} Point Cloud Processing for Forest Inventory},
	lccn = {0005},
	abstract = {In this paper, we propose an approach that enables automatic, fast and accurate tree
trunks segmentation from three-dimensional {(3-D)} laser data. Results have been demon-
strated in real-time on-board a ground mobile robot. In addition, we propose an ap-
proach to estimate tree diameter at breast height (dbh) that was tested off-line on a
variety of ground laser scanner data. Results are also presented for detection of tree
trunks in aerial laser data. The underlying techniques using in all cases rely on {3-D}
geometry analysis of point clouds and geometric primitives fitting.},
	journal = {Robotics Institute},
	author = {J. F Lalonde and N. Vandapel and M. Hebert},
	year = {2006},
	keywords = {classification},
	pages = {334}
},

@incollection{landa_visibility_2006,
	title = {Visibility of Point Clouds and Mapping of Unknown Environments},
	volume = {4179},
	isbn = {978-3-540-44630-9},
	lccn = {0014},
	url = {http://dx.doi.org/10.1007/11864349_92},
	abstract = {We present an algorithm for interpolating the visible portions of a point cloud that are sampled from opaque objects in the environment. Our algorithm projects point clouds onto a sphere centered at the observing locations and performs essentially non-oscillatory {(ENO)} interpolation to the projected data. Curvatures of the occluding objects can be approximated and used in many ways. We show how this algorithm can be incorporated into novel algorithms for mapping an unknown environment.},
	booktitle = {Advanced Concepts for Intelligent Vision Systems},
	publisher = {Springer Berlin / Heidelberg},
	author = {Yanina Landa and Richard Tsai and {Li-Tien} Cheng and Jacques {Blanc-Talon} and Wilfried Philips and Dan Popescu and Paul Scheunders},
	year = {2006},
	keywords = {interpolation, point cloud},
	pages = {1014--1025}
},

@article{lefohn_glift:_2006,
	title = {Glift: Generic, efficient, random-access {GPU} data structures},
	volume = {25},
	lccn = {0101},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.70.6491},
	abstract = {This paper presents Glift, an abstraction and generic template library for defining complex, random-access graphics processor {(GPU)} data structures. Like modern {CPU} data structure libraries, Glift enables {GPU} programmers to separate algorithms from data structure definitions; thereby greatly simplifying algorithmic development and enabling reusable and interchangeable data structures. We characterize a large body of previously published {GPU} data structures in terms of our abstraction and present several new {GPU} data structures. The structures, a stack, quadtree, and octree, are explained using simple Glift concepts and implemented using reusable Glift components. We also describe two applications of these structures not previously demonstrated on {GPUs:} adaptive shadow maps and octree {3D} paint. Lastly, we show that our example Glift data structures perform comparably to handwritten implementations while requiring only a fraction of the programming effort.},
	journal = {{ACM} Transactions on Graphics},
	author = {Aaron Lefohn and Joe Kniss and Robert Strzodka and Shubhabrata Sengupta and John Owens},
	year = {2006},
	keywords = {gpu, octree},
	pages = {60--99}
},

@article{marfil_pyramid_2006,
	title = {Pyramid segmentation algorithms revisited},
	volume = {39},
	lccn = {0032},
	url = {http://dx.doi.org/10.1016/j.patcog.2006.02.017},
	abstract = {The main goal of this work is to compare pyramidal structures proposed to solve segmentation tasks. Segmentation algorithms based on regular and irregular pyramids are described, together with the data structures and decimation procedures which encode and manage the information in the pyramid. In order to compare the different segmentation algorithms, we have employed three types of quality measurements: the shift variance measure, the F function and the Q function.},
	number = {8},
	journal = {Pattern Recognition},
	author = {R Marfil and L {Molina-Tanco} and A Bandera and {JA} Rodriguez and F Sandoval},
	year = {2006},
	keywords = {pyramid},
	pages = {1430--1451}
},

@article{merry_compression_2006,
	title = {Compression of Dense and Regular Point Clouds},
	volume = {25},
	issn = {1467-8659},
	lccn = {0015},
	url = {http://dx.doi.org/10.1111/j.1467-8659.2006.00993.x},
	abstract = {We present a simple technique for single-rate compression of point clouds sampled from a surface, based on a spanning tree of the points. Unlike previous methods, we predict future vertices using both a linear predictor, which uses the previous edge as a predictor for the current edge, and lateral predictors that rotate the previous edge 90�left or right about an estimated normal.

By careful construction of the spanning tree and choice of prediction rules, our method improves upon existing compression rates when applied to regularly sampled point sets, such as those produced by laser range scanning or uniform tesselation of higher-order surfaces. For less regular sets of points, the compression rate is still generally within 1.5 bits per point of other compression algorithms.},
	number = {4},
	journal = {Computer Graphics Forum},
	author = {Bruce Merry and Patrick Marais and James Gain},
	year = {2006},
	keywords = {compression, E.4 {[Coding} and information theory]: Data compaction and compression, I.3 {[Computer} Graphics]: Picture and image generation, point clouds, range scanning, spanning tree},
	pages = {709--716},
	annote = {Abstract We present a simple technique for single-rate compression of point clouds sampled from a surface, based on a spanning tree of the points. Unlike previous methods, we predict future vertices using both a linear predictor, which uses the previous edge as a predictor for the current edge, and lateral predictors that rotate the previous edge 90�left or right about an estimated normal. By careful construction of the spanning tree and choice of prediction rules, our method improves upon existing compression rates when applied to regularly sampled point sets, such as those produced by laser range scanning or uniform tesselation of higher-order surfaces. For less regular sets of points, the compression rate is still generally within 1.5 bits per point of other compression algorithms.}
},

@incollection{montemerlo_large-scale_2006,
	title = {{Large-Scale} Robotic {3-D} Mapping of Urban Structures},
	volume = {21},
	isbn = {3-540-28816-3},
	lccn = {0034},
	url = {http://dx.doi.org/10.1007/11552246_14},
	abstract = {This article presents results for building accurate {3-D} maps of urban environments with a mobile robot based on the Segway scooter. The goal of this project is to use robotic systems to rapidly acquire accurate {3-D} maps which seamlessly integrate indoor and outdoor structures. Our approach uses an efficient implementation of the global scan alignment algorithm of Lu and Milios in order to integrate {GPS,} {IMU,} and laser data into globally consistent maps. The {3-D} models acquired by the robot are analyzed for navigability using a multi-resolution evidence grid approach, and visualized using a meshing algorithm adapted from the computer graphics literature. Results are presented for a number of environments which combine indoor and outdoor terrain.},
	booktitle = {Experimental Robotics {IX}},
	publisher = {{Springer-Verlag}},
	author = {Michael Montemerlo and Sebastian Thrun and Marcelo Ang and Oussama Khatib},
	year = {2006},
	keywords = {application, registration, star, undecided\_list},
	pages = {141--150}
},

@book{samet_foundations_2006,
	address = {Amsterdam {;;Boston}},
	title = {Foundations of multidimensional and metric data structures},
	isbn = {9780123694461},
	lccn = {0429},
	abstract = {The field of multidimensional data structures is large and growing very quickly. Here, for the first time, is a thorough treatment of multidimensional point data, object and image-based representations, intervals and small rectangles, and high-dimensional datasets.

The book includes a thorough introduction; a comprehensive survey to spatial and multidimensional data structures and algorithms; and implementation details for the most useful data structures. Along with the hundreds of worked exercises and hundreds of illustrations, the result is an excellent and valuable reference tool for professionals in many areas, including computer graphics, databases, geographic information systems {(GIS),} game programming, image processing, pattern recognition, solid modeling, similarity retrieval, and {VLSI} design.},
	publisher = {{Elsevier/Morgan} Kaufmann},
	author = {Hanan Samet},
	year = {2006},
	keywords = {book, octree, star, survey}
},

@article{schmidt_spatial_2006,
	title = {Spatial Memory Organized by Environmental Geometry},
	volume = {6},
	lccn = {0005},
	url = {http://dx.doi.org/10.1207/s15427633scc0604_4},
	abstract = {We investigated the simultaneous effects of different reference systems on spatial memory. Participants studied a configuration of objects surrounding them. During retrieval, they imagined themselves in the center of the object configuration facing a particular object, and then indicated the directions of other objects relative to this imagined heading. Besides strong effects of egocentric retrieval direction, retrieval was enhanced for objects and headings aligned with an object-centered reference system (triangular object configuration within a neutrally-shaped room), or with a sufficiently salient environmental reference system (triangular room surrounding a neutrally-shaped object configuration). Moreover, remembered object positions were spatially distorted by the object-centered reference system. Results suggest that object positions are accessed by imagining oneself within a topographical representation of objects which is preorganized in terms of both environmental and object-centered reference systems.},
	number = {4},
	journal = {Spatial Cognition \& Computation},
	author = {Thomas Schmidt and Eun Lee},
	year = {2006},
	keywords = {cognition, cognitive map, frames-of-reference, geometry, spatial},
	pages = {347--369}
},

@inproceedings{unnikrishnan_scale_2006,
	address = {Los Alamitos, {CA,} {USA}},
	title = {Scale Selection for the Analysis of {Point-Sampled} Curves},
	volume = {0},
	isbn = {0-7695-2825-2},
	lccn = {0007},
	doi = {http://doi.ieeecomputersociety.org/10.1109/3DPVT.2006.123},
	abstract = {An important task in the analysis and reconstruction of curvilinear structures from unorganized {3-D} point samples is the estimation of tangent information at each data point. Its main challenges are in (1) the selection of an appropriate scale of analysis to accommodate noise, density variation and sparsity in the data, and in (2) the formulation of a model and associated objective function that correctly expresses their effects. We pose this problem as one of estimating the neighborhood size for which the principal eigenvector of the data scatter matrix is best aligned with the true tangent of the curve, in a probabilistic sense. We analyze the perturbation on the direction of the eigenvector due to finite samples and noise using the expected statistics of the scatter matrix estimators, and employ a simple iterative procedure to choose the optimal neighborhood size. Experiments on synthetic and real data validate the behavior predicted by the model, and show competitive performance and improved stability over leading polynomial-fitting alternatives that require a preset scale.},
	booktitle = {{3D} Data Processing Visualization and Transmission, International Symposium on},
	publisher = {{IEEE} Computer Society},
	author = {Ranjith Unnikrishnan and {Jean-Francois} Lalonde and Nicolas Vandapel and Martial Hebert},
	year = {2006},
	keywords = {classification, surface fitting},
	pages = {1026--1033},
	annote = {Complete {PDF} document was either not available or accessible. Please make sure you're logged in to the digital library to retrieve the complete {PDF} document.}
},

@inproceedings{vandapel_finding_2006,
	address = {Orlando, Florida, {USA}},
	title = {Finding Organized Structures in {3-D} {LADAR} Data},
	lccn = {0011},
	url = {http://eproceedings.worldscinet.com/9789812772572/9789812772572_0021.html},
	doi = {10.1142/9789812772572_0021},
	abstract = {In this paper, we address the problem of finding organized thin structures in three-dimensional {(3-D)} data. Linear and planar structures segmentation received much attention but thin structures organized in complex patterns remain a challenge for segmentation algorithms. We are interested especially in the problems posed by repetitive and symmetric structures acquired with a laser range finder. The method relies on {3-D} data projections along specific directions and {2-D} histograms comparison. The sensitivity of the classification algorithm to the parameter settings is evaluated and a segmentation method proposed. We illustrate our approach with data from a concertina wire in terrain with vegetation.},
	booktitle = {Transformational Science and Technology for the Current and Future Force - Proceedings of the 24th {US} Army Science Conference},
	author = {Nicolas Vandapel and Martial Hebert},
	year = {2006},
	keywords = {shape},
	pages = {161--168},
	annote = {{\textless}p{\textgreater}{\textless}br {/{\textgreater}Concertina} wire. Looked for bilateral symmetry. Constructed {2D} histograms at varying angles to look for symmetries. Offline process, but successful. Did {NOT} use voxels.{\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Also} exists paper from 2004{\textless}/p{\textgreater}}
},

@inproceedings{von_hansen_cluster_2006,
	address = {Hong Kong, China},
	title = {Cluster Analysis and Priority Sorting in Huge Point Clouds for Building Reconstruction},
	lccn = {0005},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1698824},
	doi = {10.1109/ICPR.2006.1197},
	abstract = {Terrestrial laser scanners produce point clouds with a huge number of points within a very limited surrounding. In built-up areas, many of the man-made objects are dominated by planar surfaces. We introduce a {RANSAC} based preprocessing technique that transforms the irregular point cloud into a set of locally delimited surface patches in order to reduce the amount of data and to achieve a higher level of abstraction. In a second step, the resulting patches are grouped to large planes while ignoring small and irrelevant structures. The approach is tested with a dataset of a built-up area which is described very well needing only a small number of geometric primitives. The grouping emphasizes man-made structures and could be used as a preclassification},
	booktitle = {18th International Conference on Pattern Recognition {(ICPR'06)}},
	author = {W. von Hansen and E. Michaelsen and U. Thonnessen},
	year = {2006},
	keywords = {plane fitting},
	pages = {23--26}
},

@article{wooden_guide_2006,
	title = {A guide to vision-based map building},
	volume = {13},
	lccn = {0008},
	url = {http://dx.doi.org/10.1109/MRA.2006.1638021},
	abstract = {This paper describes a simple vision-based mapping system for mobile robot navigation in an unknown outdoor environment, consistent with the efforts of Georgia Tech's team for the {DARPA-sponsored} Learning Applied to Ground Robots {(LAGR)} project. This approach, which has been robust to different environments and responsive to time-critical constraints, is a good example of robotics in practice.},
	number = {2},
	journal = {Robotics \& Automation Magazine, {IEEE}},
	author = {D Wooden},
	year = {2006},
	keywords = {application, based, building, guide, map, robot, slam, vision},
	pages = {94--98}
},

@inproceedings{xiong_r-trees_2006,
	title = {R-trees with Update Memos},
	lccn = {0045},
	url = {http://dx.doi.org/10.1109/ICDE.2006.125},
	abstract = {The problem of frequently updating multi-dimensional indexes arises in many location-dependent applications. While the R-tree and its variants are one of the dominant choices for indexing multi-dimensional objects, the R-tree exhibits inferior performance in the presence of frequent updates. In this paper, we present an R-tree variant, termed the {RUM-tree} (stands for R-tree with Update Memo) that minimizes the cost of object updates. The {RUM-tree} processes updates in a memo-based approach that avoids disk accesses for purging old entries during an update process. Therefore, the cost of an update operation in the {RUM-tree} reduces to the cost of only an insert operation. The removal of old object entries is carried out by a garbage cleaner inside the {RUM-tree.} In this paper, we present the details of the {RUM-tree} and study its properties. Theoretical analysis and experimental evaluation demonstrate that the {RUMtree} outperforms other R-tree variants by up to a factor of eight in scenarios with frequent updates.},
	booktitle = {Data Engineering, 2006. {ICDE} '06. Proceedings of the 22nd International Conference on},
	author = {Xiaopeng Xiong and {WG} Aref},
	year = {2006},
	keywords = {database, icde, r-tree},
	pages = {22}
},

@incollection{corke_wavelet_2006,
	series = {Springer Tracts in Advanced Robotics},
	title = {Wavelet Occupancy Grids: A Method for Compact Map Building},
	volume = {25},
	lccn = {0008},
	url = {http://dx.doi.org/10.1007/978-3-540-33453-8_19},
	abstract = {This paper introduces the structure of wavelet occupancy grids {(WavOGs)} as a tool for storing occupancy grids in a compact way. We have shown that {WavOGs} provide a continuous semantics of occupancy through scaled spaces. In accordance with the theoretical properties of wavelets, our experiments have validated that {WavOGs} allow major memory gains. {WavOG} as a compact multi-scaled tool provides an efficient framework for the various algorithms that use {OGs} such as robot navigation, spatio-temporal classification or multiple target-tracking. In future works we plan to apply {WavOGs} to the monitoring of urban traffic over large areas.},
	booktitle = {Field and Service Robotics},
	publisher = {Springer Berlin / Heidelberg},
	author = {Peter Corke and Salah Sukkariah and Manuel Yguel and Olivier Aycard and Christian Laugier},
	year = {2006},
	keywords = {wavelet},
	pages = {219--230},
	annote = {This paper introduces the structure of wavelet occupancy grids {(WavOGs)} as a tool for storing occupancy grids in a compact way. We have shown that {WavOGs} provide a continuous semantics of occupancy through scaled spaces. In accordance with the theoretical properties of wavelets, our experiments have validated that {WavOGs} allow major memory gains. {WavOG} as a compact multi-scaled tool provides an efficient framework for the various algorithms that use {OGs} such as robot navigation, spatio-temporal classification or multiple target-tracking. In future works we plan to apply {WavOGs} to the monitoring of urban traffic over large areas.}
},

@misc{yguel_efficient_2006,
	title = {Efficient {GPU-based} Construction of Occupancy Grids Using several Laser Range-finders},
	lccn = {0015},
	url = {http://hal.inria.fr/inria-00182008/en/},
	abstract = {Building occupancy grids {(OGs)} in order to model the
surrounding environment of a vehicle implies to fusion
occupancy information provided by the different embedded
sensors in the same grid. The principal difficulty comes
from the fact that each can have a different resolution, but
also that the resolution of some sensors varies with the
location in the field of view. In this article we present a
new exact approach to this issue and we explain why the
problem of switching coordinate systems is an instance of
the texture mapping problem in computer graphics. Therefore
we introduce a calculus architecture to build occupancy
grids with a graphical processor unit {(GPU).} Thus we present
computational time results that can allow to compute
occupancy grids for 50 sensors at frame rate even for a very
fine grid. To validate our method, the results with {GPU} are
compared to results obtained through the exact approach.},
	publisher = {{HAL} - {CCSD}},
	author = {Manuel Yguel and Olivier Aycard and Christian Laugier},
	year = {2006},
	keywords = {Computer {Science/Other,,} gpu, star},
	annote = {{INRIA} a {CCSD} electronic archive server based on {P.A.O.L}
[http://hal.inria.fr/oai/oai.php] {(France)}}
},

@misc{ziegler_--fly_2006,
	title = {On-the-fly Point Clouds through Histogram Pyramids},
	lccn = {0018},
	url = {http://edoc.mpg.de/314595},
	abstract = {Image Pyramids, as created during a reduction process of {2D}
image maps, are frequently used in porting non-local
algorithms to graphics hardware. A Histogram pyramid (short:
{HistoPyramid),} a special version of image pyramid, collects
the number of active entries in a {2D} image. We show how a
{HistoPyramid} can be utilized as an implicit indexing data
structure, allowing us to convert a sparse {3D} volume into a
point cloud entirely on the graphics hardware. In the
generalized form, the algorithm reduces a highly sparse
matrix with N elements to a list of its M active entries in
{O(N)} + M (log N) steps, despite the restricted graphics
hardware architecture. Our method can be used to deliver new
and unusual visual effects, such as particle explosions of
arbitrary geometry models. Beyond this, the algorithm is
able to accelerate feature detection, pixel classification
and binning, and enable high-speed sparse matrix
compression.},
	publisher = {Aka},
	author = {Gernot Ziegler and Christian Theobalt and {Hans-Peter} Seidel and Leif Kobbelt and Torsten Kuhlen and Til Aach and Rüdiger Westermann},
	year = {2006},
	keywords = {pyramid, star},
	annote = {Max Planck Society - {eDocument} Server
[http://edoc.mpg.de/ac\_oai.pl] {(Germany)}}
},

@inproceedings{hubo_quantized_2006,
	address = {Salt Lake City, {UT,} {USA}},
	title = {The Quantized {kd-Tree:} Efficient Ray Tracing of Compressed Point Clouds},
	lccn = {0010},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4061552},
	doi = {10.1109/RT.2006.280221},
	abstract = {Both ray tracing and point-based representations provide means to efficiently display very complex {3D} models. Computational efficiency has been the main focus of previous work on ray tracing point-sampled surfaces. For very complex models efficient storage in the form of compression becomes necessary in order to avoid costly disk access. However, as ray tracing requires neighborhood queries, existing compression schemes cannot be applied because of their sequential nature. This paper introduces a novel acceleration structure called the quantized kd-tree, which offers both efficient traversal and storage. The gist of our new representation lies in quantizing the kd-tree splitting plane coordinates. We show that the quantized kd-tree reduces the memory footprint up to 18 times, not compromising performance. Moreover, the technique can also be employed to provide {LOD} (level-of-detail) to reduce aliasing problems, with little additional storage cost},
	booktitle = {2006 {IEEE} Symposium on Interactive Ray Tracing},
	author = {Erik Hubo and Tom Mertens and Tom Haber and Philippe Bekaert},
	year = {2006},
	keywords = {k-d-tree, star},
	pages = {105--113}
},

@article{jang_adaptive_2006,
	title = {Adaptive occupancy grid mapping with clusters},
	volume = {10},
	issn = {1433-5298},
	lccn = {0001},
	url = {http://www.springerlink.com/index/10.1007/s10015-005-0358-4},
	doi = {10.1007/s10015-005-0358-4},
	abstract = {In this article, we describe an algorithm for acquiring occupancy grid maps with mobile robots. The standard occupancy grid mapping developed by Elfes and Moravec in the mid-1980s decomposes the high-dimensional mapping problem into many one-dimensional estimation problems, which are then tackled independently. Because of the independencies between neighboring grid cells, this often generates maps that are inconsistent with the sensor data. To overcome this, we propose a cluster that is a set of cells. The cells in the clusters are tackled dependently with another occupancy grid mapping with an expectation maximization {(EM)} algorithm. The occupancy grid mapping with an {EM} algorithm yields more consistent maps, especially in the cluster. As we use the mapping algorithm adaptively with clusters according to the sensor measurements, our mapping algorithm is faster and more accurate than previous mapping algorithms.},
	number = {2},
	journal = {Artificial Life and Robotics},
	author = {{Byoung-Gi} Jang and {Tae-Yong} Choi and {Ju-Jang} Lee},
	year = {2006},
	keywords = {{EM,} occupancy grid, star},
	pages = {162--165}
},

@article{kramer_development_2006,
	title = {Development environments for autonomous mobile robots: A survey},
	volume = {22},
	issn = {0929-5593},
	lccn = {0071},
	shorttitle = {Development environments for autonomous mobile robots},
	url = {http://www.springerlink.com.ezproxy.tntech.edu/content/v57531724h624440/},
	doi = {10.1007/s10514-006-9013-8},
	abstract = {Robotic Development Environments {(RDEs)} have come to play an increasingly important role in robotics research in general, and for the development of architectures for mobile robots in particular. Yet, no systematic evaluation of available {RDEs} has been performed; establishing a comprehensive list of evaluation criteria targeted at robotics applications is desirable that can subsequently be used to compare their strengths and weaknesses. Moreover, there are no practical evaluations of the usability and impact of a large selection of {RDEs} that provides researchers with the information necessary to select an {RDE} most suited to their needs, nor identifies trends in {RDE} research that suggest directions for future {RDE} development.
This survey addresses the above by selecting and describing nine open source, freely available {RDEs} for mobile robots, evaluating and comparing them from various points of view. First, based on previous work concerning agent systems, a conceptual framework of four broad categories is established, encompassing the characteristics and capabilities that an {RDE} supports. Then, a practical evaluation of {RDE}  usability in designing, implementing, and executing robot architectures is presented. Finally, the impact of specific {RDEs} on the field of robotics is addressed by providing a list of published applications and research projects that give concrete examples of areas in which systems have been used. The comprehensive evaluation and comparison of the nine {RDEs} concludes with suggestions of how to use the results of this survey and a brief discussion of future trends in {RDE} design.},
	number = {2},
	journal = {Autonomous Robots},
	author = {James Kramer and Matthias Scheutz},
	year = {2006},
	keywords = {software},
	pages = {101--132}
},

@article{huber_automatic_2006,
	title = {Automatic Three-dimensional Underground Mine Mapping},
	volume = {25},
	lccn = {0004},
	abstract = {For several years, our research group has been developing methods for automated modeling of three-dimensional {(3D)} environments. In September 2002, we were given the opportunity to demonstrate our mapping capability in an underground coal mine. The opportunity arose as a result of the Quecreek mine accident, in which an inaccurate map caused miners to breach an abandoned, water-filled mine, trapping them for several days. Our field test illustrates the feasibility and potential of high-resolution {3D} mapping of an underground coal mine using a cart-mounted {3D} laser scanner. In this paper we present our experimental setup, the automatic {3D} modeling method used, and the results of the field test.},
	number = {1},
	journal = {The International Journal of Robotics Research},
	author = {Daniel Huber and Nicolas Vandapel},
	month = jan,
	year = {2006},
	keywords = {3d, application},
	pages = {7--17}
},

@article{vandapel_unmanned_2006,
	title = {Unmanned Ground Vehicle Navigation Using Aerial Ladar Data},
	volume = {25},
	lccn = {0012},
	url = {http://ijr.sagepub.com/content/25/1/31.abstract},
	doi = {10.1177/0278364906061161},
	abstract = {In this paper, we investigate the use of overhead high-resolution three-dimensional {(3D)} data for enhancing the performances of an unmanned ground vehicle {(UGV)} in vegetated terrains. Data were collected using an airborne laser and provided prior to the robot mission. Through extensive and exhaustive field testing, we demonstrate the significance of such data in two areas: robot localization and global path planning. Absolute localization is achieved by registering {3D} local ground ladar data with the global {3D} aerial data. The same data are used to compute traversability maps that are used by the path planner. Vegetation is filtered both in the ground data and in the aerial data in order to recover the load bearing surface.},
	number = {1},
	journal = {The International Journal of Robotics Research},
	author = {Nicolas Vandapel and Raghavendra Rao Donamukkala and Martial Hebert},
	month = jan,
	year = {2006},
	keywords = {classification, map prior},
	pages = {31 --51}
},

@article{frese_discussion_2006,
	title = {A Discussion of Simultaneous Localization and Mapping},
	volume = {20},
	issn = {0929-5593},
	lccn = {0088},
	url = {http://dx.doi.org/10.1007/s10514-006-5735-x},
	abstract = {This paper aims at a discussion of the structure of the {SLAM} problem. The analysis is not strictly formal but based both on informal studies and mathematical derivation. The first part highlights the structure of uncertainty of an estimated map with the key result being {�Certainty} of Relations despite Uncertainty of Positions�. A formal proof for approximate sparsity of so-called information matrices occurring in {SLAM} is sketched. It supports the above mentioned characterization and provides a foundation for algorithms based on sparse information matrices.
Further, issues of nonlinearity and the duality between information and covariance matrices are discussed and related to common methods for solving {SLAM.}
Finally, three requirements concerning map quality, storage space and computation time an ideal {SLAM} solution should have are proposed. The current state of the art is discussed with respect to these requirements including a formal specification of the term �map quality�.},
	number = {1},
	journal = {Autonomous Robots},
	author = {Udo Frese},
	month = jan,
	year = {2006},
	keywords = {Computer Science, slam, survey},
	pages = {25--42}
},

@article{pauly_point-based_2006,
	title = {Point-based multiscale surface representation},
	volume = {25},
	issn = {0730-0301},
	lccn = {0042},
	doi = {10.1145/1138450.1138451},
	abstract = {In this article we present a new multiscale surface representation based on point samples. Given an unstructured point cloud as input, our method first computes a series of point-based surface approximations at successively higher levels of smoothness, that is, coarser scales of detail, using geometric low-pass filtering. These point clouds are then encoded relative to each other by expressing each level as a scalar displacement of its predecessor. Low-pass filtering and encoding are combined in an efficient multilevel projection operator using local weighted least squares {fitting.Our} representation is motivated by the need for higher-level editing semantics which allow surface modifications at different scales. The user would be able to edit the surface at different approximation levels to perform coarse-scale edits on the whole model as well as very localized modifications on the surface detail. Additionally, the multiscale representation provides a separation in geometric scale which can be understood as a spectral decomposition of the surface geometry. Based on this observation, advanced geometric filtering methods can be implemented that mimic the effects of Fourier filters to achieve effects such as smoothing, enhancement, or band-bass filtering.},
	journal = {{ACM} Transactions on Graphics {(TOG)}},
	author = {Mark Pauly and Leif P Kobbelt and Markus Gross},
	month = apr,
	year = {2006},
	note = {{ACM} {ID:} 1138451},
	keywords = {algorithms, boundary representations, curve, surface, solid, and object representations, surface fitting},
	pages = {177�193}
},

@article{kelly_toward_2006,
	title = {Toward Reliable Off Road Autonomous Vehicles Operating in Challenging Environments},
	volume = {25},
	lccn = {0099},
	url = {http://ijr.sagepub.com/content/25/5-6/449.abstract},
	doi = {10.1177/0278364906065543},
	abstract = {The {DARPA} {PerceptOR} program has implemented a rigorous evaluative test program which fosters the development of field relevant outdoor mobile robots. Autonomous ground vehicles were deployed on diverse test courses throughout the {USA} and quantitatively evaluated on such factors as autonomy level, waypoint acquisition, failure rate, speed, and communications bandwidth. Our efforts over the three year program have produced new approaches in planning, perception, localization, and control which have been driven by the quest for reliable operation in challenging environments. This paper focuses on some of the most unique aspects of the systems developed by the {CMU} {PerceptOR} team, the lessons learned during the effort, and the most immediate challenges that remain to be addressed.},
	number = {5-6},
	journal = {The International Journal of Robotics Research},
	author = {Alonzo Kelly and Anthony Stentz and Omead Amidi and Mike Bode and David Bradley and Antonio {Diaz-Calderon} and Mike Happold and Herman Herman and Robert Mandelbaum and Tom Pilarski and Pete Rander and Scott Thayer and Nick Vallidis and Randy Warner},
	month = may,
	year = {2006},
	keywords = {application},
	pages = {449 --483}
},

@article{thrun_graph_2006,
	title = {The Graph {SLAM} Algorithm with Applications to {Large-Scale} Mapping of Urban Structures},
	volume = {25},
	lccn = {0078},
	url = {http://dx.doi.org/10.1177/0278364906065387},
	abstract = {This article presents {GraphSLAM,} a unifying algorithm for the offline {SLAM} problem. {GraphSLAM} is closely related to a recent sequence of research papers on applying optimization techniques to {SLAM} problems. It transforms the {SLAM} posterior into a graphical network, representing the log-likelihood of the data. It then reduces this graph using variable elimination techniques, arriving at a lower-dimensional problems that is then solved using conventional optimization techniques. As a result, {GraphSLAM} can generate maps with 108 or more features. The paper discusses a greedy algorithm for data association, and presents results for {SLAM} in urban environments with occasional {GPS} measurements. 10.1177/0278364906065387},
	number = {5-6},
	journal = {The International Journal of Robotics Research},
	author = {Sebastian Thrun and Michael Montemerlo},
	month = may,
	year = {2006},
	keywords = {graphslam, slam},
	pages = {403--429}
},

@inproceedings{grisetti_speeding-up_2006,
	title = {Speeding-up rao-blackwellized {SLAM}},
	lccn = {0013},
	url = {http://dx.doi.org/10.1109/ROBOT.2006.1641751},
	abstract = {Recently, {Rao-Blackwellized} particle filters have become a popular tool to solve the simultaneous localization and mapping problem. This technique applies a particle filter in which each particle carries an individual map of the environment. Accordingly, a key issue is to reduce the number of particles and/or to make use of compact map representations. This paper presents an approximative but highly efficient approach to mapping with {Rao-Blackwellized} particle filters. Moreover, it provides a compact map model. A key advantage is that the individual particles can share large parts of the model of the environment. Furthermore, they are able to re-use an already computed proposal distribution. Both techniques substantially speed up the overall process and reduce the memory requirements. Experimental results obtained with mobile robots in large-scale indoor environments and based on published, standard datasets illustrate the advantages of our methods over previous {Rao-Blackwellized} mapping approaches},
	booktitle = {Robotics and Automation, 2006. {ICRA} 2006. Proceedings 2006 {IEEE} International Conference on},
	author = {G Grisetti and {GD} Tipaldi and C Stachniss and W Burgard and D Nardi},
	month = may,
	year = {2006},
	keywords = {estimation, fastslam, grid-mapping, particle-filter, rbpf, robotics},
	pages = {442--447}
},

@article{durrant-whyte_simultaneous_2006,
	title = {Simultaneous localization and mapping: part I},
	volume = {13},
	issn = {1070-9932},
	lccn = {0330},
	url = {http://dx.doi.org/10.1109/MRA.2006.1638022},
	abstract = {This paper describes the simultaneous localization and mapping {(SLAM)} problem and the essential methods for solving the {SLAM} problem and summarizes key implementations and demonstrations of the method. While there are still many practical issues to overcome, especially in more complex outdoor environments, the general {SLAM} method is now a well understood and established part of robotics. Another part of the tutorial summarized more recent works in addressing some of the remaining issues in {SLAM,} including computation, feature representation, and data association},
	number = {2},
	journal = {{IEEE} Robotics \& Automation Magazine},
	author = {H {Durrant-Whyte} and T Bailey},
	month = jun,
	year = {2006},
	keywords = {localization, mapping, slam, survey},
	pages = {99--110},
	annote = {{{\textless}p{\textgreater}This} is a survey{\textless}/p{\textgreater}}
},

@article{jing_2-level_2006,
	title = {2-level r-tree index based on spatial grids and Hilbert R-tree},
	volume = {9},
	lccn = {0000},
	url = {http://dx.doi.org/10.1007/BF02826939},
	abstract = {Abstract  Multi-level spatial index techniques are always used in large spatial databases. After a general survey of R-tree relevant techniques, this paper presents a novel 2-level index structure, which is based on the schemas of spatial grids, Hilbert R-tree and common R-tree. This structure is named {H2R-tree,} and it is specifically suitable for the indexing highly skewed, distributed, and large spatial database. Algorithms and a sample are given subsequently.},
	number = {2},
	journal = {{Geo-Spatial} Information Science},
	author = {Guo Jing and Liu Guangjun and Dong Xurong and Guo Lei},
	month = jun,
	year = {2006},
	keywords = {index, mapping, r-tree, spatial},
	pages = {135--141}
},

@article{schnabel_octree-based_2006,
	title = {Octree-based {Point-Cloud} Compression},
	lccn = {0024},
	url = {http://cg.cs.uni-bonn.de/aigaion2root/attachments/schnabel-2006-octree.pdf},
	abstract = {In this paper we present a progressive compression method for point sampled models that is specifically apt at dealing with densely sampled surface geometry. The compression is lossless and therefore is also suitable for storing the unfiltered, raw scan data. Our method is based on an octree decomposition of space. The point-cloud is encoded in terms of occupied octree-cells. To compress the octree we employ novel prediction techniques that were specifically designed for point sampled geometry and are based on local surface approximations to achieve high compression rates that outperform previous progressive coders for point-sampled geometry. Moreover we demonstrate that additional point attributes, such as color, which are of great importance for point-sampled geometry, can be well integrated and efficiently encoded in this framework.},
	journal = {Proceedings of Symposium on {Point-Based} Graphics 2006},
	author = {Ruwen Schnabel and Reinhard Klein},
	month = jul,
	year = {2006},
	keywords = {compression, octree}
},

@article{miralles_neural-based_2006,
	title = {A Neural-based Model for Fast Continuous and Global Robot Location},
	volume = {46},
	issn = {0921-0296},
	lccn = {0000},
	url = {http://dx.doi.org/10.1007/s10846-006-9046-4},
	abstract = {One of the problems in the field of mobile robotics is the estimation of the robot position in an environment. This paper proposes a model for estimating a confidence interval of the robot position in order to compare it with the estimation made by a dead-reckoning system. Both estimations are fused using heuristic rules. The positioning model is very valuable in estimating the current robot position with or without knowledge about the previous positions. Furthermore, it is possible to define the degree of knowledge of the robot previous position, making it possible to adapt the estimation by varying this knowledge degree. This model is based on a one-pass neural network which adapts itself in real time and learns about the relationship between the measurements from sensors and the robot position.},
	number = {3},
	journal = {Journal of Intelligent \& Robotic Systems},
	author = {�lvaro Miralles and Miguel Bobi},
	month = jul,
	year = {2006},
	keywords = {Engineering, localization, neural-network},
	pages = {221--243},
	annote = {One of the problems in the field of mobile robotics is the estimation of the robot position in an environment. This paper proposes a model for estimating a confidence interval of the robot position in order to compare it with the estimation made by a dead-reckoning system. Both estimations are fused using heuristic rules. The positioning model is very valuable in estimating the current robot position with or without knowledge about the previous positions. Furthermore, it is possible to define the degree of knowledge of the robot previous position, making it possible to adapt the estimation by varying this knowledge degree. This model is based on a one-pass neural network which adapts itself in real time and learns about the relationship between the measurements from sensors and the robot position.}
},

@article{frese_treemap:_2006,
	title = {Treemap: An O(log n) algorithm for indoor simultaneous localization and mapping},
	volume = {21},
	issn = {0929-5593},
	lccn = {0104},
	url = {http://dx.doi.org/10.1007/s10514-006-9043-2},
	abstract = {This article presents a very efficient {SLAM} algorithm that works by hierarchically dividing a map into local regions and subregions. At each level of the hierarchy each region stores a matrix representing some of the landmarks contained in this region. To keep those matrices small, only those landmarks are represented that are observable from outside the region.
A measurement is integrated into a local subregion using O(k2) computation time for k landmarks in a subregion. When the robot moves to a different subregion a full least-square estimate for that region is computed in only O(k3 log n) computation time for n landmarks. A global least square estimate needs O(kn) computation time with a very small constant (12.37 ms for n = 11300).
The algorithm is evaluated for map quality, storage space and computation time using simulated and real experiments in an office environment.},
	number = {2},
	journal = {Autonomous Robots},
	author = {Udo Frese},
	month = sep,
	year = {2006},
	keywords = {Computer Science, slam, star, treemap},
	pages = {103--122},
	annote = {This article presents a very efficient {SLAM} algorithm that works by hierarchically dividing a map into local regions and subregions. At each level of the hierarchy each region stores a matrix representing some of the landmarks contained in this region. To keep those matrices small, only those landmarks are represented that are observable from outside the region. A measurement is integrated into a local subregion using O(k2) computation time for k landmarks in a subregion. When the robot moves to a different subregion a full least-square estimate for that region is computed in only O(k3 log n) computation time for n landmarks. A global least square estimate needs O(kn) computation time with a very small constant (12.37 ms for n = 11300). The algorithm is evaluated for map quality, storage space and computation time using simulated and real experiments in an office environment.}
},

@inproceedings{triebel_multi-level_2006,
	address = {Beijing, China},
	title = {{Multi-Level} Surface Maps for Outdoor Terrain Mapping and Loop Closing},
	isbn = {1-4244-0258-1},
	lccn = {0086},
	url = {http://dx.doi.org/10.1109/IROS.2006.282632},
	abstract = {To operate outdoors or on non-flat surfaces, mobile robots need appropriate data structures that provide a compact representation of the environment and at the same time support important tasks such as path planning and localization. One such representation that has been frequently used in the past are elevation maps which store in each cell of a discrete grid the height of the surface in the corresponding area. Whereas elevation maps provide a compact representation, they lack the ability to represent vertical structures or even multiple levels. In this paper, we propose a new representation denoted as multi-level surface maps {(MLS} maps). Our approach allows to store multiple surfaces in each cell of the grid. This enables a mobile robot to model environments with structures like bridges, underpasses, buildings or mines. Additionally, they allow to represent vertical structures. Throughout this paper we present algorithms for updating these maps based on sensory input, to match maps calculated from two different scans, and to solve the loop-closing problem given such maps. Experiments carried out with a real robot in an outdoor environment demonstrate that our approach is well-suited for representing large-scale outdoor environments},
	booktitle = {Intelligent Robots and Systems, 2006 {IEEE/RSJ} International Conference on},
	publisher = {{IEEE}},
	author = {Rudolph Triebel and Patrick Pfaff and Wolfram Burgard},
	month = oct,
	year = {2006},
	keywords = {multi-level surface map},
	pages = {2276--2282}
},

@article{dellaert_square_2006,
	title = {Square Root {SLAM:} Simultaneous Localization and Mapping via Square Root Information Smoothing},
	volume = {25},
	issn = {0278-3649},
	lccn = {0001},
	url = {http://dx.doi.org/10.1177/0278364906072768},
	abstract = {Solving the {SLAM} (simultaneous localization and mapping) problem is one way to enable a robot to explore, map, and navigate in a previously unknown environment. Smoothing approaches have been investigated as a viable alternative to extended Kalman filter {(EKF)-based} solutions to the problem. In particular, approaches have been looked at that factorize either the associated information matrix or the measurement Jacobian into square root form. Such techniques have several significant advantages over the {EKF:} they are faster yet exact; they can be used in either batch or incremental mode; are better equipped to deal with non-linear process and measurement models; and yield the entire robot trajectory, at lower cost for a large class of {SLAM} problems. In addition, in an indirect but dramatic way, column ordering heuristics automatically exploit the locality inherent in the geographic nature of the {SLAM} problem. This paper presents the theory underlying these methods, along with an interpretation of factorization in terms of the graphical model associated with the {SLAM} problem. Both simulation results and actual {SLAM} experiments in large-scale environments are presented that underscore the potential of these methods as an alternative to {EKF-based} approaches. 10.1177/0278364906072768},
	number = {12},
	journal = {The International Journal of Robotics Research},
	author = {Frank Dellaert and Michael Kaess},
	month = dec,
	year = {2006},
	keywords = {robot, slam},
	pages = {1181--1203}
},

@incollection{barkowsky_modeling_2007,
	title = {Modeling Mental Spatial Knowledge Processing},
	lccn = {0007},
	url = {http://dx.doi.org/10.1007/978-0-387-71978-8_5},
	abstract = {This chapter addresses mental spatial knowledge processing from an artificial intelligence {(AI)} point of view. It first reviews the characteristics of mental representation structures used for mental reasoning processes, motivates mental knowledge processing as a construction process, and points to the use of external media as an important factor in dealing with more complex spatial problems. A range of models of intelligent spatial information processing has been proposed both in psychology and in {AI.} After giving an overview of selected models, the architecture Casimir is presented as a framework for modeling spatial reasoning with mental models and mental images. On the basis of this architecture, the design of representation structures in working memory, the task of computationally modeling mental processing of shape information, and the issue of controlling mental resources in reasoning processes are discussed as challenging issues from an {AI} perspective. The chapter closes with some considerations regarding the assessment and validation of computational models of mental spatial knowledge processing.},
	booktitle = {Spatial Processing in Navigation, Imagery and Perception},
	author = {Thomas Barkowsky},
	year = {2007},
	keywords = {ai, artificial\_intelligence, cognitive map, modeling, spatial, spatial\_cognition},
	pages = {67--84}
},

@incollection{burgard_mobile_2007,
	series = {Springer Tracts in Advanced Robotics},
	title = {Mobile Robot Map Learning from Range Data in Dynamic Environments},
	volume = {35},
	lccn = {0003},
	url = {http://dx.doi.org/10.1007/978-3-540-73422-2_1},
	abstract = {The problem of generating maps with mobile robots has received considerable attention over the past years. Most of the techniques developed so far have been designed for situations in which the environment is static during the mapping process. Dynamic objects, however, can lead to serious errors in the resulting maps such as spurious objects or misalignments due to localization errors. In this chapter, we consider the problem of creating maps with mobile robots in dynamic environments. We present two approaches to deal with non-static objects. The first approach interleaves mapping and localization with a probabilistic technique to identify spurious measurements. Measurements corresponding to dynamic objects are then filtered out during the registration process. Additionally, we present an approach that learns typical configurations of dynamic areas in the environment of a mobile robot. Our approach clusters local grid maps to identify the typical configurations. This knowledge is then used to improve the localization capabilities of a mobile vehicle acting in dynamic environments. In practical experiments carried out with a mobile robot in a typical office environment, we demonstrate the advantages of our approaches.},
	booktitle = {Autonomous Navigation in Dynamic Environments},
	publisher = {Springer Berlin / Heidelberg},
	author = {Wolfram Burgard and Cyrill Stachniss and Dirk H�hnel},
	editor = {Christian Laugier and Raja Chatila},
	year = {2007},
	note = {10.1007/978-3-540-73422-2\_1},
	keywords = {3d, dynamic},
	pages = {3--28}
},

@incollection{da_fonseca_approximate_2007,
	title = {Approximate Range Searching: The Absolute Model},
	volume = {4619},
	isbn = {978-3-540-73948-7},
	lccn = {0009},
	url = {http://dx.doi.org/10.1007/978-3-540-73951-7_2},
	abstract = {Range searching is a well known problem in the area of geometric data structures. We consider this problem in the context of approximation, where an approximation parameter ?{\textgreater}?0 is provided. Most prior work on this problem has focused on the case of relative errors, where each range shape R is bounded, and points within distance of the range�s boundary may or may not be included. We consider a different approximation model, called the absolute model, in which points within distance ? of the range�s boundary may or may not be included, regardless of the diameter of the range. We consider range spaces consisting of halfspaces, Euclidean balls, simplices, axis-aligned rectangles, and general convex bodies. We consider a variety of problem formulations, including range searching under general commutative semigroups, idempotent semigroups, groups, and range emptiness. We show how idempotence can be used to improve not only approximate, but also exact halfspace range searching. Our data structures are much simpler than both their exact and relative model counterparts, and so are amenable to efficient implementation.},
	booktitle = {Algorithms and Data Structures},
	publisher = {Springer Berlin Heidelberg},
	author = {Guilherme da Fonseca and Frank Dehne and {J�rg-R�diger} Sack and Norbert Zeh},
	year = {2007},
	keywords = {computational-geometry, range search},
	pages = {2--14}
},

@inproceedings{decoro_real-time_2007,
	address = {Seattle, Washington},
	title = {Real-time mesh simplification using the {GPU}},
	isbn = {978-1-59593-628-8},
	lccn = {0027},
	url = {http://dx.doi.org/10.1145/1230100.1230128},
	abstract = {Recent advances in real-time rendering have allowed the {GPU} implementation of traditionally {CPU-restricted} algorithms, often with performance increases of an order of magnitude or greater. Such gains are achieved by leveraging the large-scale parallelism of the {GPU} towards applications that are well-suited for these streaming architectures. By contrast, mesh simplification has traditionally been viewed as a non-interactive process not readily amenable to {GPU} acceleration. We demonstrate how it becomes practical for real-time use through our method, and that the use of the {GPU} even for offline simplification leads to significant increases in performance. Our approach for mesh decimation adopts a vertex-clustering method to the {GPU} by taking advantage of a new addition to the rendering pipeline - the geometry shader stage. We present a novel general-purpose data structure designed for streaming architectures called the probabilistic octree , which allows for much of the flexibility of offline implementations, including sparse encoding and variable level-of-detail. We demonstrate successful use of this data structure in our {GPU} implementation of mesh simplification. We can generate adaptive levels of detail by applying non-linear warping functions to the cluster map in order to improve resulting simplification quality. Our {GPU-accelerated} approach enables simultaneous construction of multiple levels of detail and out-of-core simplification of extremely large polygonal meshes.},
	booktitle = {{I3D} '07: Proceedings of the 2007 symposium on Interactive {3D} graphics and games},
	publisher = {{ACM}},
	author = {Christopher Decoro and Natalya Tatarchuk},
	year = {2007},
	keywords = {gpu, graphics},
	pages = {161--166}
},

@article{demarsin_detection_2007,
	title = {Detection of closed sharp edges in point clouds using normal estimation and graph theory},
	volume = {39},
	issn = {0010-4485},
	lccn = {0018},
	url = {http://portal.acm.org/citation.cfm?id=1238372},
	abstract = {The reconstruction of a surface model from a point cloud is an important task in the reverse engineering of industrial parts. We aim at constructing a curve network on the point cloud that will define the border of the various surface patches. In this paper, we present an algorithm to extract closed sharp feature lines, which is necessary to create such a closed curve network. We use a first order segmentation to extract candidate feature points and process them as a graph to recover the sharp feature lines. To this end, a minimum spanning tree is constructed and afterwards a reconnection procedure closes the lines. The algorithm is fast and gives good results for real-world point sets from industrial applications.},
	journal = {Comput. Aided Des.},
	author = {Kris Demarsin and Denis Vanderstraeten and Tim Volodine and Dirk Roose},
	year = {2007},
	keywords = {normal estimation, surface fitting},
	pages = {276--283}
},

@article{fairfield_real-time_2007,
	title = {{Real-Time} {SLAM} with Octree Evidence Grids for Exploration in Underwater Tunnels},
	volume = {24},
	issn = {1556-4967},
	lccn = {0036},
	url = {http://dx.doi.org/10.1002/rob.20165},
	abstract = {We describe a simultaneous localization and mapping {(SLAM)} method for a hovering underwater vehicle that will explore underwater caves and tunnels, a true three-dimensional {(3D)} environment. Our method consists of a {Rao-Blackwellized} particle filter with a {3D} evidence grid map representation. We describe a procedure for dynamically adjusting the number of particles to provide real-time performance. We also describe how we adjust the particle filter prediction step to accommodate sensor degradation or failure. We present an efficient octree data structure that makes it feasible to maintain the hundreds of maps needed by the particle filter to accurately model large environments. This octree structure can exploit spatial locality and temporal shared ancestry between particles to reduce the processing and storage requirements. To test our {SLAM} method, we utilize data collected with manually deployed sonar mapping vehicles in the Wakulla Springs cave system in Florida and the Sistema Zacato�n in Mexico, as well as data collected by the {DEPTHX} vehicle in the test tank at the Austin Applied Research Laboratory. We demonstrate our mapping and localization approach with these real-world datasets},
	number = {1-2},
	journal = {Journal of Field Robotics},
	author = {Nathaniel Fairfield and George Kantor and David Wettergreen},
	year = {2007},
	keywords = {3d, octree, slam, star},
	pages = {03--21},
	annote = {Abstract 10.1002/rob.20165.abs We describe a simultaneous localization and mapping {(SLAM)} method for a hovering underwater vehicle that will explore underwater caves and tunnels, a true three-dimensional {(3D)} environment. Our method consists of a {Rao-Blackwellized} particle filter with a {3D} evidence grid map representation. We describe a procedure for dynamically adjusting the number of particles to provide real-time performance. We also describe how we adjust the particle filter prediction step to accommodate sensor degradation or failure. We present an efficient octree data structure that makes it feasible to maintain the hundreds of maps needed by the particle filter to accurately model large environments. This octree structure can exploit spatial locality and temporal shared ancestry between particles to reduce the processing and storage requirements. To test our {SLAM} method, we utilize data collected with manually deployed sonar mapping vehicles in the Wakulla Springs cave system in Florida and the Sistema Zacato�n in Mexico, as well as data collected by the {DEPTHX} vehicle in the test tank at the Austin Applied Research Laboratory. We demonstrate our mapping and localization approach with these real-world datasets. � 2007 Wiley Periodicals, Inc.}
},

@article{huang_spatial_2007,
	title = {A Spatial Indexing Approach for High Performance Location Based Services},
	volume = {60},
	lccn = {0006},
	url = {http://dx.doi.org/10.1017/S0373463307004043},
	abstract = {The rapid development of positioning technology, wireless communication and mobile devices has given rise to the exciting Location Based Services {(LBS)} thus significantly influencing existing navigational procedures. Motivated by the increasing need to search efficiently through a huge number of service locations (e.g. restaurants, hotels, shops, and more), this paper presents an efficient spatial index {QR-tree,} a hybrid index structure of Quadtree and R-tree, instead of the exhaustive search to improve the performance in response to user queries. {QR-tree} consists of two levels: the upper level is a Quadtree residing in the main memory which partitions the data space and the lower level is disk-resident R-trees assigned to the subspaces resulting from the partitioning process. Computational experiments show that the hybrid index structure is able to reduce query response time by up to 30\% and achieve significant improvement on data update over the conventional indexing methods, thereby providing an effective option for efficient navigation services.},
	number = {01},
	journal = {The Journal of Navigation},
	author = {Bo Huang and Qiang Wu},
	year = {2007},
	keywords = {quadtree, r-tree, theory},
	pages = {83--93}
},

@misc{manuel_yguel_dense_2007,
	title = {Dense Mapping for Range Sensors: Efficient Algorithms and Sparse Representations},
	lccn = {0011},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.148.5497},
	abstract = {Abstract — This paper focuses on efficient occupancy grid
building based on wavelet occupancy grids, a new sparse grid
representation and on a new update algorithm for range
sensors. The update algorithm takes advantage of the natural
multiscale properties of the wavelet expansion to update
only parts of the environement that are modified by the
sensor measurements and at the proper scale. The sparse
wavelet representation coupled with an efficient algorithm
presented in this paper provides efficient and fast updating
of occupancy grids. It leads to realtime results especially
in {2D} grids and for the first time in {3D} grids. Experiments
and results are discussed for both real and simulated data.
I. {INTRODUCTION} {AND} {PREVIOUS} {WORK} The Simultaneous
Localization And Mapping {(SLAM)} issue has found very
convincing solutions in the past few years, especially},
	author = {Manuel Yguel and Christopher Tay and Meng Keat and Christophe Braillon and Christian Laugier and Olivier Aycard},
	year = {2007},
	keywords = {slam, wavelet},
	annote = {{CiteSeerX} - Scientific Literature Digital Library and Search
Engine [http://citeseerx.ist.psu.edu/oai2] {(United} States)},
	annote = {{{\textless}p{\textgreater}Wavelet-based} representation...{\textless}/p{\textgreater}
{{\textless}p{\textgreater}They} store essentially the wavelet coeffs (averages/details) at each node in a 2{\textasciicircum}d-tree. The interesting consequence of this is that updates can be applied at different resolutions. For instance, it might solve the ray tracing problem since an entire contiguous area can be updated at once (larger than a single cell level). If the data is not so homogeneous, will this still occur?{\textless}/p{\textgreater}
{{\textless}p{\textgreater}To} do fast update in {3D,} they remove the idea that space is unknown a prior, and assume it is empty. The tests in this paper aren't really very well-structured, especially in {3D.} Do they have a follow-up work?{\textless}/p{\textgreater}
{{\textless}p{\textgreater}In} the end, they speak of the requirements suitable for fast-slam:{\textless}/p{\textgreater}
{\textless}p{\textgreater}1) fast updating and scan matching to construct the map{\textless}br /{\textgreater}and calculate the current robot�s pose in real time,{\textless}br /{\textgreater}2) a hierarchical grid representation to handle multiple{\textless}br /{\textgreater}maps in multiple particles efficiently,{\textless}br /{\textgreater}3) a small amount of memory per grid to ensure efficiency{\textless}br /{\textgreater}in the previously stated conditions.{\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Note} that the tree-based representation is amenable to parallel techniques (which can be utilized by {GPU).{\textless}/p{\textgreater}}}
},

@inproceedings{mitsou_temporal_2007,
	title = {Temporal Occupancy Grid for mobile robot dynamic environment mapping},
	lccn = {0006},
	url = {http://dx.doi.org/10.1109/MED.2007.4433892},
	abstract = {Mapping dynamic environments is an open issue in the field of robotics. In this paper, we extend the well known Occupancy Grid structure to address the problem of generating valid maps for dynamic indoor environments. We propose a spatiotemporal access method to store all sensor values (instead of preserving only one value for each cell as in the common occupancy grid case). By searching for similar time series, we can detect moving objects that appear only in a limited number of possible configurations (e.g. doors or chairs). Simulated experiments demonstrate the potentialities of the proposed system.},
	booktitle = {Control \& Automation, 2007. {MED} '07. Mediterranean Conference on},
	author = {{NC} Mitsou and {CS} Tzafestas},
	year = {2007},
	keywords = {dynamic, mapping, occupancy grid, robotics, spatiotemporal, star},
	pages = {1--8}
},

@article{mozos_supervised_2007,
	title = {Supervised semantic labeling of places using information extracted from sensor data},
	volume = {55},
	lccn = {0032},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.136.8094},
	abstract = {Indoor environments can typically be divided into places with different functionalities like corridors, kitchens, offices, or seminar rooms. The ability to learn such semantic categories from sensor data enables a mobile robot to extend the representation of the environment facilitating the interaction with humans. As an example, natural language terms like �corridor� or �room � can be used to communicate the position of the robot in a map in a more intuitive way. In this work, we first propose an approach based on supervised learning to classify the pose of a mobile robot into semantic classes. Our method uses {AdaBoost} to boost simple features extracted from range data and vision into a strong classifier. We present two main applications of this approach. Firstly, we show how our approach can be utilized by a moving robot for an online classification of the poses traversed along its path using a hidden Markov model. Secondly, we introduce an approach to learn topological maps from geometric maps by applying our semantic classification procedure in combination with a probabilistic relaxation procedure. We finally show how to apply associative Markov networks {(AMNs)} together with {AdaBoost} for classifying complete geometric maps. Experimental results obtained in simulation and with real robots demonstrate the effectiveness of our approach in various indoor environments.},
	journal = {{ROBOTICS} {AND} {AUTONOMOUS} {SYSTEMS}},
	author = {�scar Mart�nez Mozos and Axel Rottmann and Rudolph Triebel and Patric Jensfelt and Wolfram Burgard},
	year = {2007},
	keywords = {classification, graphical models},
	pages = {391---402}
},

@incollection{thrun_using_2007,
	series = {Springer Tracts in Advanced Robotics},
	title = {Using {AdaBoost} for Place Labeling and Topological Map Building},
	volume = {28},
	lccn = {0000},
	url = {http://dx.doi.org/10.1007/978-3-540-48113-3_39},
	abstract = {Indoor environments can typically be divided into places with different functionalities like corridors, kitchens, offices, or seminar rooms. We believe that the ability to learn such semantic categories from sensor data or in maps enables a mobile robot to more efficiently accomplish a variety of tasks such as human-robot interaction, path-planning, exploration, or localization. In this work, we first propose an approach based on supervised learning to classify the pose of a mobile robot into semantic classes. Our method uses {AdaBoost} to boost simple features extracted from vision and laser range data into a strong classifier. We furthermore present two main applications of this approach. Firstly, we show how our approach can be utilized by a moving robot for robust online classification of the poses traversed along its path using a hidden Markov model. Secondly, we introduce a new approach to learn topological maps from geometric maps by applying our semantic classification procedure in combination with probabilistic labeling. Experimental results obtained in simulation and with real robots demonstrate the effectiveness of our approach in various environments.},
	booktitle = {Robotics Research},
	publisher = {Springer Berlin / Heidelberg},
	author = {Sebastian Thrun and Rodney Brooks and Hugh {Durrant-Whyte} and �scar Mozos and Cyrill Stachniss and Axel Rottmann and Wolfram Burgard},
	year = {2007},
	keywords = {classification},
	pages = {453--472},
	annote = {Indoor environments can typically be divided into places with different functionalities like corridors, kitchens, offices, or seminar rooms. We believe that the ability to learn such semantic categories from sensor data or in maps enables a mobile robot to more efficiently accomplish a variety of tasks such as human-robot interaction, path-planning, exploration, or localization. In this work, we first propose an approach based on supervised learning to classify the pose of a mobile robot into semantic classes. Our method uses {AdaBoost} to boost simple features extracted from vision and laser range data into a strong classifier. We furthermore present two main applications of this approach. Firstly, we show how our approach can be utilized by a moving robot for robust online classification of the poses traversed along its path using a hidden Markov model. Secondly, we introduce a new approach to learn topological maps from geometric maps by applying our semantic classification procedure in combination with probabilistic labeling. Experimental results obtained in simulation and with real robots demonstrate the effectiveness of our approach in various environments.}
},

@article{noykov_occupancy_2007,
	title = {Occupancy grids building by sonar and mobile robot},
	volume = {55},
	lccn = {0012},
	url = {http://www.sciencedirect.com/science/article/B6V16-4KKNJ53-1/2/2c6b7a6b6747332704d2720ffa5243af},
	abstract = {In this paper, a modified method for occupancy grid map building by a moving mobile robot and a scanning ultrasonic range-finder is proposed. The map building process consists of two phases: (1) gleaning of information from environment, and (2) sonar data processing. For sonar data processing the proposed modified method combines: (1) statistical approach for probability sonar model building; and (2) application of fuzzy logic theory for sonar data fusion. It is experimentally shown that, in some applications, the proposed modified method has advantages over other well-known methods.},
	number = {2},
	journal = {Robotics and Autonomous Systems},
	author = {Sv Noykov and Ch Roumenin},
	year = {2007},
	keywords = {articles, bitmap, building, found, fuzzy logic, grids, map, mobile, occupancy, occupancy grid, range-finder, robot, thesis},
	pages = {162--175}
},

@inproceedings{nuechter_6d_2007,
	address = {W{\textbackslash}\&uuml;rzburg, Germany},
	title = {{6D} {SLAM} with cached {K-D} tree search},
	isbn = {978-0-88986-686-7},
	lccn = {0006},
	abstract = {{6D} {SLAM} {(Simultaneous} Localization and Mapping) or {6D} Concurrent Localization and Mapping of mobile robots considers six degrees of freedom for the robot pose, namely, the x, y and z coordinates and the roll, yaw and pitch angles. In previous work we presented our scan matching based {6D} {SLAM} approach [10--12, 16], where scan matching is based on the well known iterative closest point {(ICP)} algorithm [3]. Efficient implementations of this algorithm are a result of a fast computation of closest points. The usual approach, i.e., using k-d trees is extended in this paper. We describe a novel search strategy, that leads to significant speed-ups. Our mapping system is real-time capable, i.e., {3D} maps are computed using the resources of the used {Kurt3D} robotic hardware.},
	booktitle = {Proceedings of the 13th {IASTED} International Conference on Robotics and Applications},
	publisher = {{ACTA} Press},
	author = {Andreas N�chter and Kai Lingemann and Joachim Hertzberg},
	year = {2007},
	keywords = {3d, k-d-tree, slam, star},
	pages = {101--106}
},

@inproceedings{samet_spatial_2007,
	address = {New York, {NY,} {USA}},
	series = {{SIGGRAPH} '07},
	title = {Spatial data structures},
	lccn = {2745},
	location = {San Diego, California},
	doi = {10.1145/1281500.1281632},
	abstract = {An overview is presented of the use of spatial data structures in spatial databases. The focus is on hierarchical data structures, including a number of variants of quadtrees, which sort the data with respect to the space occupied by it. Such techniques are known as spatial indexing methods. Hierarchical data structures are based on the principle of recursive decomposition. They are attractive because they are compact and depending on the nature of the data they save space as well as time and also facilitate operations such as search. Examples are given of the use of these data structures in the representation of different data types such as regions, points, rectangles, lines, and volumes.},
	booktitle = {{ACM} {SIGGRAPH} 2007 courses},
	publisher = {{ACM}},
	author = {Hanan Samet},
	year = {2007},
	note = {{ACM} {ID:} 1281632},
	keywords = {hierarchical spatial data structures, lines, octrees, old, survey}
},

@inproceedings{steder_learning_2007,
	title = {Learning maps in 3d using attitude and noisy vision sensors},
	lccn = {0020},
	url = {http://www.informatik.uni-freiburg.de/~grisetti/pdf/steder07iros.pdf},
	abstract = {Abstract � In this paper, we address the problem of learning {3D} maps of the environment using a cheap sensor setup which consists of two standard web cams and a low cost inertial measurement unit. This setup is designed for lightweight or flying robots. Our technique uses visual features extracted from the web cams and estimates the {3D} location of the landmarks via stereo vision. Feature correspondences are estimated using a variant of the {PROSAC} algorithm. Our mapping technique constructs a graph of spatial constraints and applies an efficient gradient descent-based optimization approach to estimate the most likely map of the environment. Our approach has been evaluated in comparably large outdoor and indoor environments. We furthermore present experiments in which our technique is applied to build a map with a blimp. I.},
	booktitle = {In Proc. of the {IEEE/RSJ} Int. Conf. on Intelligent Robots and Systems {(IROS}},
	author = {Bastian Steder and Giorgio Grisetti and Slawomir Grzonka and Cyrill Stachniss and Axel Rottmann and Wolfram Burgard},
	year = {2007},
	keywords = {3d, stereo, uav}
},

@incollection{yuille_surface_2007,
	series = {Lecture Notes in Computer Science},
	title = {Surface Reconstruction from {LiDAR} Data with Extended Snake Theory},
	volume = {4679},
	lccn = {0002},
	url = {http://dx.doi.org/10.1007/978-3-540-74198-5_37},
	abstract = {Surface reconstruction from implicit data of sub-randomly distributed {3D} points is the key work of extracting explicit information from {LiDAR} data. This paper proposes an approach of extended snake theory to surface reconstruction from {LiDAR} data. The proposed algorithm approximates a surface with connected planar patches. Growing from an initial seed point, a surface is reconstructed by attaching new adjacent planar patches based on the concept of minimizing the deformable energy. A least-squares solution is sought to keep a local balance of the internal and external forces, which are inertial forces maintaining the flatness of a surface and pulls of observed {LiDAR} points bending the growing surface toward observations. Experiments with some test data acquired with a ground-based {LiDAR} demonstrate the feasibility of the proposed algorithm. The effects of parameter settings on the delivered results are also investigated.},
	booktitle = {Energy Minimization Methods in Computer Vision and Pattern Recognition},
	publisher = {Springer Berlin / Heidelberg},
	author = {Alan Yuille and {Song-Chun} Zhu and Daniel Cremers and Yongtian Wang and {Yi-Hsing} Tseng and {Kai-Pei} Tang and {Fu-Chen} Chou},
	year = {2007},
	keywords = {plane fitting, surface fitting},
	pages = {479--492},
	annote = {Surface reconstruction from implicit data of sub-randomly distributed {3D} points is the key work of extracting explicit information from {LiDAR} data. This paper proposes an approach of extended snake theory to surface reconstruction from {LiDAR} data. The proposed algorithm approximates a surface with connected planar patches. Growing from an initial seed point, a surface is reconstructed by attaching new adjacent planar patches based on the concept of minimizing the deformable energy. A least-squares solution is sought to keep a local balance of the internal and external forces, which are inertial forces maintaining the flatness of a surface and pulls of observed {LiDAR} points bending the growing surface toward observations. Experiments with some test data acquired with a ground-based {LiDAR} demonstrate the feasibility of the proposed algorithm. The effects of parameter settings on the delivered results are also investigated.}
},

@article{choi_mobile_2007,
	title = {Mobile robot navigation algorithm using a vector-based topological map and virtual Jacobian},
	volume = {221},
	issn = {0959-6518},
	lccn = {0000},
	url = {http://journals.pepublishing.com/openurl.asp?genre=article&id=doi:10.1243/09596518JSCE347},
	doi = {10.1243/09596518JSCE347},
	abstract = {In this paper, a vector-based topological map is to be built consisting of available directions (moving directions) and the distances between nodes. This map represents the whole environment as a skeleton, using nodes similar to vectors independent of geometrical information of obstacles. To build a vector-based topological map, the following are developed: (a) acquisition of reliable range values using local minimum values, (b) fuzzy inference system {(FIS)} for extracting available directions, and (c) collision avoidance using virtual Jacobians. First, only local minimum values are used among the range of sensor values in order to decrease the effect of specular reflection and calculate available directions using the {FIS.} Specially, the number of consequent membership functions is determined as the number of obstacle orientations around a mobile robot, enabling the mobile robot to find available directions independently of the geometrical information of obstacles. Finally, to avoid collisions, a virtual Jacobian method is used because a vector-based topological map does not include the geometrical information about obstacles. The proposed algorithms have been verified in the simulation and implemented on a robot in the real environment.},
	number = {4},
	journal = {Proceedings of the Institution of Mechanical Engineers, Part I: Journal of Systems and Control Engineering},
	author = {{Gyu-Jong} Choi and {Young-Seok} Jung and {Doo-Sung} Ahn},
	year = {2007},
	keywords = {topological},
	pages = {565--575}
},

@article{wang_filling_2007,
	title = {Filling holes on locally smooth surfaces reconstructed from point clouds},
	volume = {25},
	issn = {02628856},
	lccn = {0015},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0262885606000199},
	doi = {10.1016/j.imavis.2005.12.006},
	abstract = {Creating models of real scenes is a complex task for which the use of traditional modeling techniques is inappropriate. For this task, laser rangefinders are frequently used to sample the scene from several viewpoints, with the resulting range images integrated into a final model. In practice, due to surface reflectance properties, occlusions and accessibility limitations, certain areas of the scenes are usually not sampled, leading to holes and introducing undesirable artifacts in the resulting models. We present an algorithm for filling holes on surfaces reconstructed from point clouds. The algorithm is based on moving least squares and can interpolate both geometry and shading information. The reconstruction process is mostly automatic and the sampling rate of the given samples is preserved in the reconstructed areas. We demonstrate the use of the algorithm on both real and synthetic datasets to obtain complete geometry and plausible shading.},
	number = {1},
	journal = {Image and Vision Computing},
	author = {J Wang and M Oliveira},
	year = {2007},
	keywords = {interpolation},
	pages = {103--113}
},

@inproceedings{gonzalez_planning_2007,
	address = {Rome, Italy},
	title = {Planning with Uncertainty in Position Using {High-Resolution} Maps},
	lccn = {0017},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4209222},
	doi = {10.1109/ROBOT.2007.363118},
	abstract = {We present a novel approach to mobile robot navigation that enables navigation in outdoor environments without {GPS.} The approach uses a path planner that calculates optimal paths while considering uncertainty in position and that uses landmarks to localize the vehicle as part of the planning process. The landmarks are simple, possibly aliased, features that have been previously identified in a high-resolution map. These landmarks are combined with an estimate of the position of the vehicle to create unique and robust features. This approach reduces or eliminates the need for {GPS} and enables the use of prior maps with imperfect map registration.},
	booktitle = {Proceedings 2007 {IEEE} International Conference on Robotics and Automation},
	author = {Juan Pablo Gonzalez and Anthony Stentz},
	year = {2007},
	keywords = {planning, slam},
	pages = {1015--1022}
},

@article{sankaranarayanan_fast_2007,
	title = {A fast all nearest neighbor algorithm for applications involving large point-clouds},
	volume = {31},
	issn = {00978493},
	lccn = {0027},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849306002378},
	doi = {10.1016/j.cag.2006.11.011},
	abstract = {Algorithms that use point-cloud models make heavy use of the neighborhoods of the points. These neighborhoods are used to compute the surface normals for each point, mollification, and noise removal. All of these primitive operations require the seemingly repetitive process of finding the k nearest neighbors {(kNNs)} of each point. These algorithms are primarily designed to run in main memory. However, rapid advances in scanning technologies have made available point-cloud models that are too large to fit in the main memory of a computer. This calls for more efficient methods of computing the {kNNs} of a large collection of points many of which are already in close proximity. A fast {kNN} algorithm is presented that makes use of the locality of successive points whose k nearest neighbors are sought to reduce significantly the time needed to compute the neighborhood needed for the primitive operation as well as enable it to operate in an environment where the data is on disk. Results of experiments demonstrate an order of magnitude improvement in the time to perform the algorithm and several orders of magnitude improvement in work efficiency when compared with several prominent existing methods.},
	number = {2},
	journal = {Computers \& Graphics},
	author = {Jagan Sankaranarayanan and Hanan Samet and Amitabh Varshney},
	year = {2007},
	keywords = {nearest\_neighbor, star},
	pages = {157--174}
},

@inproceedings{daniels_robust_2007,
	address = {Minneapolis, {MN,} {USA}},
	title = {Robust Smooth Feature Extraction from Point Clouds},
	lccn = {0029},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4273375},
	doi = {10.1109/SMI.2007.32},
	abstract = {Defining sharp features in a given {3D} model facilitates a better understanding of the surface and aids visualizations, reverse engineering, filtering, simplification, non-photo realism, reconstruction and other geometric processing applications. We present a robust method that identifies sharp features in a point cloud by returning a set of smooth curves aligned along the edges. Our feature extraction is a multi-step refinement method that leverages the concept of Robust Moving Least Squares to locally fit surfaces to potential features. Using Newton?s method, we project points to the intersections of multiple surfaces then grow polylines through the projected cloud. After resolving gaps, connecting corners, and relaxing the results, the algorithm returns a set of complete and smooth curves that define the features. We demonstrate the benefits of our method with two applications: surface meshing and point-based geometry compression.},
	booktitle = {{IEEE} International Conference on Shape Modeling and Applications 2007 {(SMI} '07)},
	author = {Joel {II} Daniels and Linh K. Ha and Tilo Ochotta and Claudio T. Silva},
	year = {2007},
	keywords = {surface fitting},
	pages = {123--136}
},

@inproceedings{weiss_robust_2007,
	address = {Istanbul, Turkey},
	title = {Robust Driving Path Detection in Urban and Highway Scenarios Using a Laser Scanner and Online Occupancy Grids},
	lccn = {0019},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4290112},
	doi = {10.1109/IVS.2007.4290112},
	abstract = {Many driver assistant and safety systems depend on an accurate environmental model containing the positions of stationary objects, the states of dynamic objects and information about valid driving corridors. Therefore, a robust differentiation between moving and stationary objects is required. This is challenging for laser scanners, because these sensors are not able to measure the velocity of objects directly. Therefore, an advanced occupancy grid approach, the online map, is introduced, which enables the robust separation of moving and stationary objects. The online map is used for the robust detection of the road boundaries for the determination of driving corridors in urban and highway scenarios. An algorithm for the detection of arbitrary moving objects using the online map is proposed.},
	booktitle = {2007 {IEEE} Intelligent Vehicles Symposium},
	author = {Thorsten Weiss and Bruno Schiele and Klaus Dietmayer},
	year = {2007},
	keywords = {dynamic, occupancy grid},
	pages = {184--189}
},

@article{lalonde_data_2007,
	title = {Data Structures for Efficient Dynamic Processing in {3-D}},
	volume = {26},
	issn = {0278-3649},
	lccn = {0007},
	url = {http://ijr.sagepub.com/cgi/doi/10.1177/0278364907079265},
	doi = {10.1177/0278364907079265},
	abstract = {This paper considers the problem of the dynamic processing of large amounts of sparse three-dimensional data. It is assumed that computations are performed in a neighborhood defined around each point in order to retrieve local properties. This general kind of processing can be applied to a wide variety of problems. A new, efficient data structure and corresponding algorithms are proposed that significantly improve the speed of the range search operation and that are suitable for on-line operation where data is accumulated dynamically. The method relies on taking advantage of overlapping neighborhoods and the reuse of previously computed data as the algorithm scans each data point. To demonstrate the dynamic capabilities of the data structure, data obtained from a laser radar mounted on a ground mobile robot operating in complex, outdoor environments is used. It is shown that this approach considerably improves the speed of an established {3-D} perception processing algorithm.},
	number = {8},
	journal = {The International Journal of Robotics Research},
	author = {{J.-F.} Lalonde and N. Vandapel and M. Hebert},
	year = {2007},
	keywords = {3d, occupancy grid, star},
	pages = {777--796},
	annote = {{\textless}p{\textgreater}pre-computed tree-based data structures (kd-tree, range tree) good for computing range search, but bad for insertions{\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}
{\textless}p{\textgreater}[16] windowed priority queue for segmentation{\textless}/p{\textgreater}
{\textless}p{\textgreater}[16] J. Lersch, B. Webb, and K. West. Structural-surface extraction from {3-D} laser-radar point clouds. In Laser Radar{\textless}br {/{\textgreater}Technology} and Applications {IX,} volume 5412. {SPIE,} 2004.{\textless}/p{\textgreater}
{\textless}p{\textgreater}x[3] bucket-space approach{\textless}/p{\textgreater}
{\textless}p{\textgreater}x[3] T. Bodenmueller and G. Hirzinger. Online surface reconstruction from unorganized 3d points for the dlr hand-{\textless}br /{\textgreater}guided scanner system. In International Symposium on {3D} Data Processing, Visualization, and Transmission,{\textless}br /{\textgreater}2004.{\textless}/p{\textgreater}
{\textless}p{\textgreater}x[22] driven by local geometry{\textless}/p{\textgreater}
{\textless}p{\textgreater}x[22] M. Pauly, L. Kobbelt, and M. Gross. Point-based multi-scale surface representation. {ACM} Transactions on{\textless}br {/{\textgreater}Graphics,} 25(2), 2006.{\textless}/p{\textgreater}
{\textless}p{\textgreater}x[24] based on octrees{\textless}/p{\textgreater}
{\textless}p{\textgreater}x[24] R. Schnabel and R. Klein. Octree-based point-cloud compression. In M. Botsch and B. Chen, editors, Symposium{\textless}br /{\textgreater}on {Point-Based} Graphics 2006. Eurographics, July 2006.{\textless}/p{\textgreater}
{\textless}p{\textgreater}hierarchical clustering [11] (computer graphics for compression for visual presentation){\textless}/p{\textgreater}
{\textless}p{\textgreater}[11] M. Hopf and T. Ertl. Hierarchical splatting of scattered data. In {IEEE} Visualization Conference, 2003.{\textless}/p{\textgreater}
{\textless}p{\textgreater}[2] efficient range techniques{\textless}/p{\textgreater}
{\textless}p{\textgreater}[2] S. Arya and D. Mount. Approximate range searching. Computational Geometry, 17(3), December 2000.{\textless}/p{\textgreater}
{\textless}p{\textgreater}x[9] Gao with kinetic data, extending voronoi diagrams and triangulation, unclear how it scales{\textless}/p{\textgreater}
{\textless}p{\textgreater}x[9] J. Gao and R. Gupta. Efficient proximity search for {3-D} cuboids. In Computational Science and Its Applications,{\textless}br /{\textgreater}volume 2669 of Lecture Notes in Computer Science, 2003.{\textless}/p{\textgreater}
{\textless}p{\textgreater}[17, 10] machine learning uses data structures too for nn, range search, regression, or kernel stuff, but high dimensional data sets (not dynamic {3D} stuff){\textless}/p{\textgreater}
{\textless}p{\textgreater}[17] T. Liu, A. Moore, A. Gray, and K. Yang. An investigation of practical approximate nearest neighbor algorithms.{\textless}br {/{\textgreater}In} Proceedings of Neural Information Processing Systems Conference, 2004.{\textless}/p{\textgreater}
{\textless}p{\textgreater}[10] A. Gray and A. Moore. Data structures for fast statistics. Tutorial presented at the International Conference on{\textless}br {/{\textgreater}Machine} Learning, 2004.{\textless}/p{\textgreater}
{\textless}p{\textgreater}[26] 3d mecial imaging devices produce data very different (dense, uniform sampling(?)){\textless}/p{\textgreater}
{\textless}p{\textgreater}[26] M. Stytz, G. Frieder, and O. Frieder. Three-dimensional medical imaging: algorithms and computer systems.{\textless}br {/{\textgreater}ACM} Computing Surveys {(CSUR),} 23(4):421�499, 1991.{\textless}/p{\textgreater}
{\textless}p{\textgreater}x[29] {2.5D} map{\textless}/p{\textgreater}
{\textless}p{\textgreater}x[29] N. Vandapel, R. Donamukkala, and M. Hebert. Unmanned ground vehicle navigation using aerial ladar data.{\textless}br {/{\textgreater}International} Journal of Robotics Research, 25(1), 2006.{\textless}/p{\textgreater}
{\textless}p{\textgreater}x[19] montemerlo multi-res grid{\textless}/p{\textgreater}
{\textless}p{\textgreater}x[19] M. Montemerlo and S. Thrun. A multi-resolution pyramid for outdoor robot terrain perception. In Proceedings{\textless}br /{\textgreater}of the {AAAI} National Conference on Artificial Intelligence, San Jose, {CA,} 2004. {AAAI.{\textless}/p{\textgreater}}
{{\textless}p{\textgreater}Vandapel} says approach {MUST} be fully {3D{\textless}/p{\textgreater}}
{\textless}p{\textgreater}an example is ground surface recovery in 3d [13, 7] = dense scrolling map, with ray tracing to determine load bearing surfaces or vegetation. Requires data insertion and retrieval but no range search{\textless}/p{\textgreater}
{\textless}p{\textgreater}[13] A. Lacaze, K. Murphy, and M. {DelGiorno.} Autonomous mobility for the demo {III} experimental unmanned{\textless}br /{\textgreater}vehicles. In Proceedings of the {AUVSI} Conference, 2002.{\textless}/p{\textgreater}
{\textless}p{\textgreater}x[7] A. Kelly et al. Toward reliable off-road autonomous vehicle operating in challenging environments. In Interna-{\textless}br /{\textgreater}tional Symposium on Experimental Robotics, 2004.{\textless}/p{\textgreater}
{\textless}p{\textgreater}3d occupancy grid [21], not optimized for range search though{\textless}/p{\textgreater}
{\textless}p{\textgreater}x[21] H. Moravec. Robot spatial perception by stereoscopic vision and {3-D} evidence grids. Technical Report {CMU-{\textless}br} {/{\textgreater}RI-TR-96-34,} Carnegie Mellon Univeristy, 1996.{\textless}/p{\textgreater}
{\textless}p{\textgreater}3d to 2d [18], but they cannot follow this approach in general{\textless}/p{\textgreater}
{\textless}p{\textgreater}[18] R. Manduchi, A. Castano, A. Talukder, and L. Matthies. Obstacle detection and terrain classification for au-{\textless}br /{\textgreater}tonomous off-road navigation. Autonomous Robot, 18:81�102, 2005.{\textless}/p{\textgreater}
{\textless}p{\textgreater}operations must be performed:{\textless}/p{\textgreater}
{\textless}p{\textgreater}1. recovery of the number of neighbors in a support region{\textless}/p{\textgreater}
{\textless}p{\textgreater}2. range search: recovery of the actual points in a support region{\textless}/p{\textgreater}
{\textless}p{\textgreater}3. {PCA} components of a region, needs local covariance matrix{\textless}/p{\textgreater}
{\textless}p{\textgreater}4. kernel density estimation [31, 28]{\textless}/p{\textgreater}
{\textless}p{\textgreater}[31] M. Wand and M. Jones. Kernel Smoothing. Chapman \&amp; Hall, 1995.{\textless}/p{\textgreater}
{\textless}p{\textgreater}x[28] R. Unnikrishnan and M. Hebert. Robust extraction of multiple structures from non-uniformly sampled data. In{\textless}br {/{\textgreater}IEEE/RSJ} International Conference on Intelligent Robots and Systems, 2003.{\textless}/p{\textgreater}
{\textless}p{\textgreater}both range search (2) and kernel density estimation (4) cannot be used with his bounded equations!{\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}}
},

@inproceedings{strand_range_2007,
	address = {Harbin, China},
	title = {Range Image Registration Using an Octree based Matching Strategy},
	lccn = {0006},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4303792},
	doi = {10.1109/ICMA.2007.4303792},
	abstract = {Autonomous world modeling is one of the major topics in current robot research. A basic concept hereby is the registration of consecutive range images. Consistent models can only be built with robust registration methods. Already one incorrect registered range image will affect the following registrations and lead to an inconsistent model. Therefore we developed a robust {ICP} registration method based on an octree matching strategy. This matching strategy could cope with large odometry errors and achieved the generation of consistent {3D} models.},
	booktitle = {2007 International Conference on Mechatronics and Automation},
	author = {Marcus Strand and Frank Erb and Ruediger Dillmann},
	year = {2007},
	keywords = {3d, octree, registration, star},
	pages = {1622--1627}
},

@inproceedings{pathak_3d_2007,
	address = {San Diego, {CA,} {USA}},
	title = {{3D} forward sensor modeling and application to occupancy grid based sensor fusion},
	lccn = {0015},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4399406},
	doi = {10.1109/IROS.2007.4399406},
	abstract = {This paper presents a new technique for the update of a probabilistic spatial occupancy grid map using a forward sensor model. Unlike currently popular inverse sensor models, forward sensor models can be found experimentally and can represent sensor characteristics better. The formulation is applicable to both {2D} and {3D} range sensors and does not have some of the theoretical and practical problems associated with the current approaches which use forward models. As an illustration of this procedure, a new prototype {3D} forward sensor model is derived using a beam represented as a spherical sector. Furthermore, this model is used for fusion of point-clouds obtained from different {3D} sensors, in particular, time-of-flight sensors {(Swiss-ranger,} laser range finders), and stereo vision cameras. Several techniques are described for an efficient data-structure representation and implementation. The range beams from different sensors are fused in a common local Cartesian occupancy map. Experimental results of this fusion are presented and evaluated using Hough-transform performed on the grid.},
	booktitle = {2007 {IEEE/RSJ} International Conference on Intelligent Robots and Systems},
	author = {Kaustubh Pathak and Andreas Birk and Jann Poppinga and Soren Schwertfeger},
	year = {2007},
	keywords = {forward sensor model, occupancy grid},
	pages = {2059--2064}
},

@article{pfaff_efficient_2007,
	title = {An Efficient Extension to Elevation Maps for Outdoor Terrain Mapping and Loop Closing},
	volume = {26},
	lccn = {0029},
	url = {http://dx.doi.org/10.1177/0278364906075165},
	abstract = {Elevation maps are a popular data structure for representing the environment of a mobile robot operating outdoors or on not-flat surfaces. Elevation maps store in each cell of a discrete grid the height of the surface at the corresponding place in the environment. However, the use of this 2[1/2]-dimensional representation, is disadvantageous when utilized for mapping with mobile robots operating on the ground, since vertical or overhanging objects cannot be represented appropriately. Furthermore, such objects can lead to registration errors when two elevation maps have to be matched. In this paper, an approach is proposed that allows a mobile robot to deal with vertical and overhanging objects in elevation maps. The approach classifies the points in the environment according to whether they correspond to such objects or not. Also presented is a variant of the {ICP} algorithm that utilizes the classification of cells during the data association. Additionally, it is shown how the constraints computed by the {ICP} algorithm can be applied to determine globally consistent alignments. Experiments carried out with a real robot in an outdoor environment demonstrate that the proposed approach yields highly accurate elevation maps even in the case of loops. Experimental results are presented demonstrating that that the proposed classification increases the robustness of the scan matching process. 10.1177/0278364906075165},
	number = {2},
	journal = {The International Journal of Robotics Research},
	author = {Patrick Pfaff and Rudolph Triebel and Wolfram Burgard},
	month = feb,
	year = {2007},
	keywords = {multi-level elevation maps, registration, undecided\_list},
	pages = {217--230}
},

@article{grisetti_improved_2007,
	title = {Improved Techniques for Grid Mapping With {Rao-Blackwellized} Particle Filters},
	volume = {23},
	issn = {1552-3098},
	lccn = {0161},
	url = {http://dx.doi.org/10.1109/TRO.2006.889486},
	abstract = {Recently, {Rao-Blackwellized} particle filters {(RBPF)} have been introduced as an effective means to solve the simultaneous localization and mapping problem. This approach uses a particle filter in which each particle carries an individual map of the environment. Accordingly, a key question is how to reduce the number of particles. In this paper, we present adaptive techniques for reducing this number in a {RBPF} for learning grid maps. We propose an approach to compute an accurate proposal distribution, taking into account not only the movement of the robot, but also the most recent observation. This drastically decreases the uncertainty about the robot's pose in the prediction step of the filter. Furthermore, we present an approach to selectively carry out resampling operations, which seriously reduces the problem of particle depletion. Experimental results carried out with real mobile robots in large-scale indoor, as well as outdoor, environments illustrate the advantages of our methods over previous approaches},
	number = {1},
	journal = {{IEEE} Transactions on Robotics},
	author = {Giorgio Grisetti and Cyrill Stachniss and Wolfram Burgard},
	month = feb,
	year = {2007},
	keywords = {fastslam, grid-mapping, occupancy grid, particle-filter, rbpf, slam},
	pages = {34--46}
},

@article{vasudevan_cognitive_2007,
	title = {Cognitive maps for mobile robots - an object based approach},
	volume = {55},
	issn = {09218890},
	lccn = {0073},
	url = {http://dx.doi.org/10.1016/j.robot.2006.12.008},
	abstract = {Robots are rapidly evolving from factory work-horses to robot-companions. The future of robots, as our companions, is highly dependent on their abilities to understand, interpret and represent the environment in an efficient and consistent fashion, in a way that is comprehensible to humans. The work presented here is oriented in this direction. It suggests a hierarchical probabilistic representation of space that is based on objects. A global topological representation of places with object graphs serving as local maps is proposed. The work also details the first efforts towards conceptualizing space on the basis of the human compatible representation so formed. Such a representation and the resulting conceptualization would be useful for enabling robots to be cognizant of their surroundings. Experiments on place classification and place recognition are reported in order to demonstrate the applicability of such a representation towards understanding space and thereby performing spatial cognition. Further, relevant results from user studies validating the proposed representation are also reported. Thus, the theme of the work is � representation for spatial cognition.},
	number = {5},
	journal = {Robotics and Autonomous Systems},
	author = {S Vasudevan and S Gachter and V Nguyen and R Siegwart},
	month = may,
	year = {2007},
	keywords = {cognitive\_map},
	pages = {359--371}
},

@inproceedings{paz_data_2007,
	address = {Atlanta, {GA,} {USA}},
	title = {Data Association in O(n) for Divide and Conquer {SLAM}},
	lccn = {0009},
	abstract = {In this paper we show that {{\textbackslash}em all} processes associated to the move-sense-update cycle of {EKF} {SLAM} can be carried out in time {{\textbackslash}em linear} in the number of map features. We describe Divide and Conquer {SLAM,} an {EKF} {SLAM} algorithm where the computational complexity per step is reduced from O(n{\textasciicircum}2) to O(n); the total cost of {SLAM} is reduced from O(n{\textasciicircum}3) to O(n{\textasciicircum}2). In addition, the resulting vehicle and map estimates have better consistency properties than standard {EKF} {SLAM} in the sense that the computed state covariance more adequately represents the real error in the estimation. Both simulated experiments and the Victoria Park Dataset are used to provide evidence of the advantages of this algorithm.},
	booktitle = {Proceedings of Robotics: Science and Systems},
	author = {L. Paz and J. Guivant and J. Tard�s and J. Neira},
	month = jun,
	year = {2007},
	keywords = {slam, star}
},

@inproceedings{pedraza_bs-slam:_2007,
	address = {Atlanta, {GA,} {USA}},
	title = {{BS-SLAM:} Shaping the World},
	lccn = {0005},
	abstract = {This paper presents {BS-SLAM,} a simultaneous localization and mapping algorithm for use in unstructured environments that is effective regardless of whether features correspond to simple geometric primitives such as points and lines or not. The coordinates of the control points defining a set of B-splines are used to form a complete and compact description of the environment, thus making it feasible to use an extended Kalman filter based {SLAM} algorithm. The proposed method is the first known {EKF-SLAM} implementation capable of describing both straight and curve features in a parametric way. Appropriate observation equation that allows the exploitation of virtually all observations from a range sensor such as the ubiquitous laser range finder is developed. Efficient strategies for computing the relevant Jacobians, perform data association, initialization and expanding the map are presented. The effectiveness of the algorithms is demonstrated using experimental data.},
	booktitle = {Proceedings of Robotics: Science and Systems},
	author = {L. Pedraza and G. Dissanayake and J. Valls Miro and D. {Rodriguez-Losada} and F. Matia},
	month = jun,
	year = {2007},
	keywords = {geometric model, slam, splines, star}
},

@article{schnabel_efficient_2007,
	title = {Efficient {RANSAC} for {Point-Cloud} Shape Detection},
	volume = {26},
	issn = {1467-8659},
	lccn = {0073},
	url = {http://dx.doi.org/10.1111/j.1467-8659.2007.01016.x},
	abstract = {In this paper we present an automatic algorithm to detect basic shapes in unorganized point clouds. The algorithm decomposes the point cloud into a concise, hybrid structure of inherent shapes and a set of remaining points. Each detected shape serves as a proxy for a set of corresponding points. Our method is based on random sampling and detects planes, spheres, cylinders, cones and tori. For models with surfaces composed of these basic shapes only, for example, {CAD} models, we automatically obtain a representation solely consisting of shape proxies. We demonstrate that the algorithm is robust even in the presence of many outliers and a high degree of noise. The proposed method scales well with respect to the size of the input point cloud and the number and size of the shapes within the data. Even point sets with several millions of samples are robustly decomposed within less than a minute. Moreover, the algorithm is conceptually simple and easy to implement. Application areas include measurement of physical parameters, scan registration, surface compression, hybrid rendering, shape classification, meshing, simplification, approximation and reverse engineering.},
	number = {2},
	journal = {Computer Graphics Forum},
	author = {R Schnabel and R Wahl and R Klein},
	month = jun,
	year = {2007},
	keywords = {octree, ransac, shape},
	pages = {214--226}
},

@article{yenilmez_new_2007,
	title = {A new approach to map building by sensor data fusion: sequential principal {component-SPC} method},
	volume = {34},
	issn = {0268-3768},
	lccn = {0004},
	url = {http://dx.doi.org/10.1007/s00170-006-0578-3},
	abstract = {This study proposes a new map building method for a mobile robot operating in an environment with obstacles by fusing sensor data. Required information for a map designing is supplied by fusion of different sensor data using the sequential principal component {(SPC)} method. We discuss mathematical and experimental issues of the method by comparing a Bayesian method that works efficiently in map building using sensor data fusion. Application of the method for grid based map building is introduced and compatibility in mobile robot navigation is demonstrated. Experimental studies are implemented on Nomad200 mobile robot successfully.},
	number = {1},
	journal = {The International Journal of Advanced Manufacturing Technology},
	author = {Levent Yenilmez and Hakan Temeltas},
	month = aug,
	year = {2007},
	keywords = {Computer Science, occupancy grid, star},
	pages = {168--178}
},

@article{zhang_comparative_2007,
	title = {A Comparative Study of Three Mapping Methodologies},
	volume = {49},
	issn = {0921-0296},
	lccn = {0002},
	url = {http://dx.doi.org/10.1007/s10846-007-9143-z},
	abstract = {Map building is one of the core competencies of truly autonomous robots. Numerous techniques have been developed to represent the static and dynamic environments as well as the perceptional sensing frameworks so far. In this paper, on the basis of our previous work, we compare various sensor systems in building the static and dynamic environment map with the segment-based map and {Fuzzy-Tuned} {Grid-Based} Map {(FTGBM)} strategies. From the comparative results of experiments, we propose a probably efficient and trade-off framework which balances the accuracy of the map against the overall system cost.},
	number = {4},
	journal = {Journal of Intelligent \& Robotic Systems},
	author = {X. Zhang and A. Rad and Y. Wong and G. Huang and Y. Ip and K. Chow},
	month = aug,
	year = {2007},
	keywords = {Engineering, fuzzy-tuned, occupancy grid},
	pages = {385--395},
	annote = {Map building is one of the core competencies of truly autonomous robots. Numerous techniques have been developed to represent the static and dynamic environments as well as the perceptional sensing frameworks so far. In this paper, on the basis of our previous work, we compare various sensor systems in building the static and dynamic environment map with the segment-based map and {Fuzzy-Tuned} {Grid-Based} Map {(FTGBM)} strategies. From the comparative results of experiments, we propose a probably efficient and trade-off framework which balances the accuracy of the map against the overall system cost.}
},

@inproceedings{grisetti_efficient_2007,
	address = {San Diego, {CA,} {USA}},
	title = {Efficient estimation of accurate maximum likelihood maps in {3D}},
	isbn = {978-1-4244-0911-2},
	lccn = {0037},
	url = {http://dx.doi.org/10.1109/IROS.2007.4399030},
	abstract = {Learning maps is one of the fundamental tasks of mobile robots. In the past, numerous efficient approaches to map learning have been proposed. Most of them, however, assume that the robot lives on a plane. In this paper, we consider the problem of learning maps with mobile robots that operate in non-flat environments and apply maximum likelihood techniques to solve the graph-based {SLAM} problem. Due to the non-commutativity of the rotational angles in {3D,} major problems arise when applying approaches designed for the two-dimensional world. The non-commutativity introduces serious difficulties when distributing a rotational error over a sequence of poses. In this paper, we present an efficient solution to the {SLAM} problem that is able to distribute a rotational error over a sequence of nodes. Our approach applies a variant of gradient descent to solve the error minimization problem. We implemented our technique and tested it on large simulated and real world datasets. We furthermore compared our approach to solving the problem by {LU-decomposition.} As the experiments illustrate, our technique converges significantly faster to an accurate map with low error and is able to correct maps with bigger noise than existing methods.},
	booktitle = {Intelligent Robots and Systems, 2007. {IROS} 2007. {IEEE/RSJ} International Conference on},
	publisher = {{IEEE}},
	author = {Giorgio Grisetti and Slawomir Grzonka and Cyrill Stachniss and Patrick Pfaff and Wolfram Burgard},
	month = oct,
	year = {2007},
	keywords = {maximum likelihood estimation, slam},
	pages = {3472--3478}
},

@inproceedings{aulinas_slam_2008,
	title = {The {SLAM} problem: a survey},
	isbn = {978-1-58603-925-7},
	lccn = {0002},
	abstract = {This paper surveys the most recent published techniques in the field of Simultaneous Localization and Mapping {(SLAM).} In particular it is focused on the existing techniques available to speed up the process, with the purpose to handel large scale scenarios. The main research field we plan to investigate is the filtering algorithms as a way of reducing the amount of data. It seems that almost all the current approaches can not perform consistent maps for large areas, mainly due to the increase of the computational cost and due to the uncertainties that become prohibitive when the scenario becomes larger.},
	booktitle = {Proceeding of the 2008 conference on Artificial Intelligence Research and Development: Proceedings of the 11th International Conference of the Catalan Association for Artificial Intelligence},
	publisher = {{IOS} Press},
	author = {Josep Aulinas and Yvan Petillot and Joaquim Salvi and Xavier Llad{\textbackslash}\&{\textbackslash}\#243;},
	year = {2008},
	keywords = {slam, survey},
	pages = {363--371}
},

@incollection{siciliano_world_2008,
	title = {World Modeling},
	isbn = {978-3-540-30301-5},
	lccn = {0410},
	url = {http://dx.doi.org/10.1007/978-3-540-30301-5_37},
	abstract = {In this chapter we describe popular ways to represent the environment of a mobile robot. For indoor environments, which are often stored using two-dimensional representations, we discuss occupancy grids, line maps, topological maps, and landmark-based representations. Each of these techniques has its own advantages and disadvantages. Whilst occupancy grid maps allow for quick access and can efficiently be updated, line maps are more compact. Also landmark-based maps can efficiently be updated and maintained, however, they do not readily support navigation tasks such as path planning like topological representations do.
Additionally, we discuss approaches suited for outdoor terrain modeling. In outdoor environments, the flat-surface assumption underling many mapping techniques for indoor environments is no longer valid. A very popular approach in this context are elevation and variants maps, which store the surface of the terrain over a regularly spaced grid. Alternatives to such maps are point clouds, meshes, or three-dimensional grids, which provide a greater flexibility but have higher storage demands.},
	booktitle = {Springer Handbook of Robotics},
	publisher = {Springer Berlin Heidelberg},
	author = {Bruno Siciliano and Oussama Khatib and Wolfram Burgard and Martial Hebert},
	year = {2008},
	keywords = {data structures, Engineering, star, survey, world modeling},
	pages = {853--869},
	annote = {In this chapter we describe popular ways to represent the environment of a mobile robot. For indoor environments, which are often stored using two-dimensional representations, we discuss occupancy grids, line maps, topological maps, and landmark-based representations. Each of these techniques has its own advantages and disadvantages. Whilst occupancy grid maps allow for quick access and can efficiently be updated, line maps are more compact. Also landmark-based maps can efficiently be updated and maintained, however, they do not readily support navigation tasks such as path planning like topological representations do. Additionally, we discuss approaches suited for outdoor terrain modeling. In outdoor environments, the flat-surface assumption underling many mapping techniques for indoor environments is no longer valid. A very popular approach in this context are elevation and variants maps, which store the surface of the terrain over a regularly spaced grid. Alternatives to such maps are point clouds, meshes, or three-dimensional grids, which provide a greater flexibility but have higher storage demands.}
},

@incollection{fisher_range_2008,
	title = {Range Sensors},
	isbn = {978-3-540-23957-4},
	lccn = {0116},
	url = {http://dx.doi.org/10.1007/978-3-540-30301-5_23},
	abstract = {Range sensors are devices that capture the three-dimensional {(3-D)} structure of the world from the viewpoint of the sensor, usually measuring the depth to the nearest surfaces. These measurements could be at a single point, across a scanning plane, or a full image with depth measurements at every point. The benefits of this range data is that a robot can be reasonably certain where the real world is, relative to the sensor, thus allowing the robot to more reliably find navigable routes, avoid obstacles, grasp objects, act on industrial parts, etc. This chapter introduces the main representations for range data (point sets, triangulated surfaces, voxels), the main methods for extracting usable features from the range data (planes, lines, triangulated surfaces), the main sensors for acquiring it {(Sect.} 22.1 � stereo and laser triangulation and ranging systems), how multiple observations of the scene, e.g., as if from a moving robot, can be registered {(Sect.} 22.2), and several indoor and outdoor robot applications where range data greatly simplifies the task {(Sect.} 22.3).},
	booktitle = {Springer Handbook of Robotics},
	publisher = {Springer Berlin Heidelberg},
	author = {Robert Fisher and Kurt Konolige and Bruno Siciliano and Oussama Khatib},
	year = {2008},
	keywords = {sensors, survey},
	pages = {521--542}
},

@incollection{jefferies_dead_2008,
	series = {Springer Tracts in Advanced Robotics},
	title = {Dead Reckoning, Cognitive Maps, Animal Navigation and the Representation of Space: An Introduction},
	volume = {38},
	lccn = {0002},
	url = {http://dx.doi.org/10.1007/978-3-540-75388-9_8},
	abstract = {The chapters in this part deal with some aspects of current behavioral and neurobiological research on the construction of maps by animal brains. A map is an encoding of some or all of the geometric relations between locations. Map making is a fundamental part of navigation. It enables the navigator to set a course for a destination that is not currently perceived by reference to the navigator�s currently perceptible surroundings.},
	booktitle = {Robotics and Cognitive Approaches to Spatial Mapping},
	publisher = {Springer Berlin / Heidelberg},
	author = {Margaret Jefferies and {Wai-Kiang} Yeap and Charles Gallistel},
	year = {2008},
	keywords = {cognitive map, localization},
	pages = {137--143}
},

@incollection{jefferies_these_2008,
	series = {Springer Tracts in Advanced Robotics},
	title = {These Maps Are Made for Walking � Task Hierarchy of Spatial Cognition},
	volume = {38},
	lccn = {0000},
	url = {http://dx.doi.org/10.1007/978-3-540-75388-9_11},
	abstract = {Spatial behaviours and abilities do not form a monolithic module of cognition but can be subdivided into a hierarchy of behaviours, mechanisms, and representations. This hierarchical structure is a result of cognitive evolution. Therefore, the ordering of the individual modules will follow the general rules of phylogeny. In particular, the complexity of spatial tasks to be solved by an organism and the behaviours evolved as adaptation to these tasks is of great relevance. In this paper, we present an approach to spatial hierarchy based on the complexity of the tasks, rather than on the complexity of the underlying mechanisms. Individual levels of the task hierachy are discussed from a theoretical point of view and specific experimental examples are given. In conclusion, hierachies based on tasks seem to differ from representational hierarchies in three respects, the treatment of landmarks, the role of metric information, and the relation of language and space.},
	booktitle = {Robotics and Cognitive Approaches to Spatial Mapping},
	publisher = {Springer Berlin / Heidelberg},
	author = {Margaret Jefferies and {Wai-Kiang} Yeap and Sabine Gillner and Hanspeter Mallot},
	year = {2008},
	keywords = {cognitive map},
	pages = {181--201},
	annote = {Spatial behaviours and abilities do not form a monolithic module of cognition but can be subdivided into a hierarchy of behaviours, mechanisms, and representations. This hierarchical structure is a result of cognitive evolution. Therefore, the ordering of the individual modules will follow the general rules of phylogeny. In particular, the complexity of spatial tasks to be solved by an organism and the behaviours evolved as adaptation to these tasks is of great relevance. In this paper, we present an approach to spatial hierarchy based on the complexity of the tasks, rather than on the complexity of the underlying mechanisms. Individual levels of the task hierachy are discussed from a theoretical point of view and specific experimental examples are given. In conclusion, hierachies based on tasks seem to differ from representational hierarchies in three respects, the treatment of landmarks, the role of metric information, and the relation of language and space.}
},

@incollection{kuipers_intellectual_2008,
	title = {An Intellectual History of the Spatial Semantic Hierarchy},
	volume = {38},
	isbn = {978-3-540-75386-5},
	lccn = {0024},
	url = {http://dx.doi.org/10.1007/978-3-540-75388-9_15},
	abstract = {The Spatial Semantic Hierarchy and its predecessor the {TOUR} model are theories of robot and human commonsense knowledge of large-scale space: the cognitive map. The focus of these theories is on how spatial knowledge is acquired from experience in the environment, and how it can be used effectively in spite of being incomplete and sometimes incorrect. This essay is a personal reflection on the evolution of these ideas since their beginning early in 1973 while I was a graduate student at the {MIT} {AI} Lab. I attempt to describe how, and due to what influences, my understanding of commonsense knowledge of space has changed over the years since then.},
	booktitle = {Robotics and Cognitive Approaches to Spatial Mapping},
	publisher = {Springer Berlin Heidelberg},
	author = {Benjamin Kuipers and Margaret Jefferies and {Wai-Kiang} Yeap},
	year = {2008},
	keywords = {artificial\_intelligence, cognitive map, robotics},
	pages = {243--264},
	annote = {Interesting because it's possible to understand the choices made by Kuipers, and to see that he followed Minsky (did Dreyfus criticize him?) at {MIT} and worked at Xerox {PARC.}
He wanted to study common knowledge and decided to start with spatial knowledge. He looks for inspiration in Kevin Lynch {(Image} of the City) and Piaget {(Developmental} Psychology). He also started collecting route directions and sketch maps from anyone available to get insight from it.
Most important here is the control level from the {SSH} (trajectory following and hill-climbing control laws), section 6 and the Foundational Learning (collection of control laws for coupling its sensors, effectors and environment together), section 8.}
},

@incollection{kuemmerle_monte_2008,
	title = {Monte Carlo Localization in Outdoor Terrains Using {Multi-Level} Surface Maps},
	volume = {42},
	isbn = {978-3-540-75403-9},
	lccn = {0026},
	url = {http://dx.doi.org/10.1007/978-3-540-75404-6_20},
	abstract = {In this paper we consider the problem of mobile robot localization with range sensors in outdoor environments. Our approach applies a particle filter to estimate the full six-dimensional state of the robot. To represent the environment we utilize multi-level surface maps which allow the robot to represent vertical structures and multiple levels in the environment. We describe probabilistic motion and sensor models to calculate the proposal distribution and to evaluate the likelihood of observations. Experimental results obtained with a mobile robot in an outdoor environment indicate that our approach can be used to robustly and accurately localize an outdoor vehicle. The experiments also demonstrate that multi-level surface maps lead to a significantly better localization performance than standard elevation maps.},
	booktitle = {Field and Service Robotics},
	publisher = {Springer Berlin Heidelberg},
	author = {Rainer K�mmerle and Rudolph Triebel and Patrick Pfaff and Wolfram Burgard and Christian Laugier and Roland Siegwart},
	year = {2008},
	keywords = {localization, multi-level surface map},
	pages = {213--222}
},

@article{laugier_geometric_2008,
	title = {Geometric and Bayesian models for safe navigation in dynamic environments},
	volume = {1},
	issn = {1861-2776},
	lccn = {0005},
	url = {http://dx.doi.org/10.1007/s11370-007-0004-1},
	abstract = {Autonomous navigation in open and dynamic environments is an important challenge, requiring to solve several difficult research problems located on the cutting edge of the state of the art. Basically, these problems may be classified into three main categories: (a) {SLAM} in dynamic environments; (b) detection, characterization, and behavior prediction of the potential moving obstacles; and (c) online motion planning and safe navigation decision based on world state predictions. This paper addresses some aspects of these problems and presents our latest approaches and results. The solutions we have implemented are mainly based on the followings paradigms: multiscale world representation of static obstacles based on the wavelet occupancy grid; adaptative clustering for moving obstacle detection inspired on Kohonen networks and the growing neural gas algorithm; and characterization and motion prediction of the observed moving entities using Hidden Markov Models coupled with a novel algorithm for structure and parameter learning.},
	journal = {Intelligent Service Robotics},
	author = {C. Laugier and Dizan Vasquez and M. Yguel and Th Fraichard and O. Aycard},
	year = {2008},
	note = {10.1007/s11370-007-0004-1},
	keywords = {dynamic, slam, wavelet},
	pages = {51--72}
},

@incollection{milford_robotic_2008,
	series = {Springer Tracts in Advanced Robotics},
	title = {Robotic Mapping Methods},
	volume = {41},
	lccn = {0000},
	url = {http://dx.doi.org/10.1007/978-3-540-77520-1_3},
	abstract = {Sensor and environment uncertainty has caused most robotic mapping and navigation methods to converge to probabilistic techniques. The key strength of probabilistic techniques is their ability to deal with uncertainty and ambiguity in a robot�s sensors and environment. Any technique that has some means of handling the uncertainties faced by a mobile robot has an immense advantage over techniques that do not. Probabilistic techniques allow a robot to appropriately use sensory measurements based on their modelled uncertainties. Ambiguous features or landmarks in the environment become useful (albeit less useful than unique features) rather than becoming failure points for the mapping algorithm.},
	booktitle = {Robot Navigation from Nature},
	publisher = {Springer Berlin / Heidelberg},
	author = {Michael Milford},
	year = {2008},
	keywords = {survey},
	pages = {15--28}
},

@incollection{bessiere_bayesian_2008,
	series = {Springer Tracts in Advanced Robotics},
	title = {The Bayesian Occupation Filter},
	volume = {46},
	lccn = {0002},
	url = {http://dx.doi.org/10.1007/978-3-540-79007-5_4},
	abstract = {Perception of and reasoning about dynamic environments is pertinent for mo-
bile robotics and still constitutes one of the major challenges. To work in
these environments, the mobile robot must perceive the environment with
sensors; measurements are uncertain and normally treated within the esti-
mation framework. Such an approach enables the mobile robot to model the
dynamic environment and follow the evolution of its environment. With an
internal representation of the environment, the robot is thus able to perform
reasoning and make predictions to accomplish its tasks successfully. Systems
for tracking the evolution of the environment have traditionally been a major
component in robotics. Industries are now beginning to express interest in
such technologies. One particular example is the application within the au-
tomotive industry for adaptive cruise control {[Cou�} et al., 2002], where the
challenge is to reduce road accidents by using better collision detection sys-
tems. The major requirement of such a system is a robust tracking system.
Most of the existing target-tracking algorithms use an object-based represen-
tation of the environment. However, these existing techniques must explicitly
consider data association and occlusion. In view of these problems, a grid-
based framework, the Bayesian occupancy filter {(BOF)} {[Cou�} et al., 2002,
2003], has been proposed.},
	booktitle = {Probabilistic Reasoning and Decision Making in {Sensory-Motor} Systems},
	publisher = {Springer Berlin / Heidelberg},
	author = {Pierre Bessi�re and Christian Laugier and Roland Siegwart and M. Tay and Kamel Mekhnacha and M. Yguel and C. Cou� and C�dric Pradalier and Christian Laugier and Th. Fraichard and Pierre Bessi�re},
	year = {2008},
	keywords = {occupancy grid},
	pages = {77--98}
},

@incollection{siciliano_simultaneous_2008,
	title = {Simultaneous Localization and Mapping},
	isbn = {978-3-540-30301-5},
	lccn = {0024},
	url = {http://dx.doi.org/10.1007/978-3-540-30301-5_38},
	abstract = {This article provides a comprehensive introduction into the simultaneous localization and mapping problem, better known in its abbreviated form as {SLAM.} {SLAM} addresses the problem of a robot navigating an unknown environment. While navigating the environment, the robot seeks to acquire a map thereof, and at the same time it wishes to localize itself using its map. The use of {SLAM} problems can be motivated in two different ways. One might be interested in detailed environment models, or one might seek to maintain an accurate sense of a mobile robot�s location. {SLAM} servers both of these purposes.
We review three major paradigms of algorithms from which a huge number of recently published methods are derived. First comes the traditional approach, which relies in the extended Kalman filter {(EKF)} for representing the robot�s best estimate. The second paradigm draws its intuition from the fact that the {SLAM} problem can be viewed as a sparse graph of constraints, and it applies nonlinear optimization for recovering the map and the robot�s locations. Finally, we survey the particle filter paradigm, which applies non-parametric density estimation and efficient factorization methods to the {SLAM} problem. This article discusses extensions of these basic methods. It elucidates variants of the {SLAM} problem and poses a taxonomy for the field. Relevant research is referenced extensively, and open research problems are discussed.},
	booktitle = {Springer Handbook of Robotics},
	publisher = {Springer Berlin Heidelberg},
	author = {Bruno Siciliano and Oussama Khatib and Sebastian Thrun and John J. Leonard},
	year = {2008},
	keywords = {Engineering, slam, survey},
	pages = {871--889}
},

@incollection{tomatis_hybrid_2008,
	title = {Hybrid, {Metric-Topological} Representation for Localization and Mapping},
	lccn = {0002},
	url = {http://dx.doi.org/10.1007/978-3-540-75388-9_4},
	abstract = {This chapter describes an approach for indoor spatial representation, which is used to model the environment for the navigation of a fully autonomous robot. The metric and topological paradigms are integrated in a hybrid system for both localization and map building: A global topological map connects local metric maps avoiding the requirement of global metric consistency. This allows for a compact environment model, which permits both precision and robustness and allows the handling of loops in the environment during automatic mapping by means of the information of the multimodal topological localization. The presented implementation uses a 360 � laser scanner to extract corners and openings for the topological approach and lines for the metric method. This hybrid approach has been tested in a 50 x 25m 2 portion of the institute building with the fully autonomous robot Donald Duck. Experiments are of four types: Maps created by a complete exploration of the environment are compared to estimate their quality; Test missions are randomly generated in order to evaluate the efficiency of the approach for both the localization and relocation; The fourth type of experiments shows the practicability of the approach for closing the loop.},
	booktitle = {Robotics and Cognitive Approaches to Spatial Mapping},
	author = {Nicola Tomatis},
	year = {2008},
	keywords = {hybrid, mapping, slam, topological},
	pages = {43--63},
	annote = {Hallways are not represented as a metric entity (assumes no need to localize outside of finding doors, or navigating the topology). Also, seems to be explicitly tied to indoor, rectilinear environments, since it relies on "openings" and "corners" as landmarks in the topological map, as well as parallel and perpendicular infinite lines in the metric maps. Utilizes a {POMDP} for localization within the topological map (the experiments only test for a lost situation within hallways, not rooms). Metric mapping is done locally in rooms using {EKF} {SLAM.} Loop closures are handled in the topological map by using a confidence measure on the entropy of probability distribution over the belief states, then tracking multiple hypotheses, eventually backtracking with localization until the distribution converges.}
},

@inproceedings{unnikrishnan_multi-scale_2008,
	title = {Multi-scale interest regions from unorganized point clouds},
	lccn = {0012},
	url = {http://dx.doi.org/10.1109/CVPRW.2008.4563030},
	abstract = {Several computer vision algorithms rely on detecting a compact but representative set of interest regions and their associated descriptors from input data. When the input is in the form of an unorganized {3D} point cloud, current practice is to compute shape descriptors either exhaustively or at randomly chosen locations using one or more preset neighborhood sizes. Such a strategy ignores the relative variation in the spatial extent of geometric structures and also risks introducing redundancy in the representation. This paper pursues multi-scale operators on point clouds that allow detection of interest regions whose locations as well as spatial extent are completely data-driven. The approach distinguishes itself from related work by operating directly in the input {3D} space without assuming an available polygon mesh or resorting to an intermediate global {2D} parameterization. Results are shown to demonstrate the utility and robustness of the proposed method.},
	booktitle = {Computer Vision and Pattern Recognition Workshops, 2008. {CVPRW} '08. {IEEE} Computer Society Conference on},
	author = {R Unnikrishnan and M Hebert},
	year = {2008},
	keywords = {shape},
	pages = {1--8}
},

@incollection{laugier_update_2008,
	series = {Springer Tracts in Advanced Robotics},
	title = {Update Policy of Dense Maps: Efficient Algorithms and Sparse Representation},
	volume = {42},
	lccn = {0002},
	url = {http://dx.doi.org/10.1007/978-3-540-75404-6_3},
	abstract = {Providing a robot with a fully detailed map is one appealing key for the Simultaneous Localisation and Mapping {(SLAM)} problem. It gives the robot a lot of hints to solve either the data association or the localisation problem itself. The more details are in the map, the more chances are that different places may appear differently, solving ambiguities. The more landmarks are used, the more accurate are the algorithms that solve the localisation problem since in a least square sense an approximation of the solution is more precise. Last, it helps a lot in the presence of a few dynamic objects because these moving parts of the environment remain marginal in the amount of data used to model the map and can thus be filtered out. For instance, the moving objects can be detected or cancelled in the localisation procedure by robust techniques using {Monte-Carlo} algorithms [6] or {RANSAC} [4].},
	booktitle = {Field and Service Robotics},
	publisher = {Springer Berlin / Heidelberg},
	author = {Christian Laugier and Roland Siegwart and Manuel Yguel and Olivier Aycard and Christian Laugier},
	year = {2008},
	keywords = {dynamic, slam, star, survey},
	pages = {23--33},
	annote = {Providing a robot with a fully detailed map is one appealing key for the Simultaneous Localisation and Mapping {(SLAM)} problem. It gives the robot a lot of hints to solve either the data association or the localisation problem itself. The more details are in the map, the more chances are that different places may appear differently, solving ambiguities. The more landmarks are used, the more accurate are the algorithms that solve the localisation problem since in a least square sense an approximation of the solution is more precise. Last, it helps a lot in the presence of a few dynamic objects because these moving parts of the environment remain marginal in the amount of data used to model the map and can thus be filtered out. For instance, the moving objects can be detected or cancelled in the localisation procedure by robust techniques using {Monte-Carlo} algorithms [6] or {RANSAC} [4].}
},

@article{borrmann_globally_2008,
	title = {Globally consistent {3D} mapping with scan matching},
	volume = {56},
	issn = {09218890},
	lccn = {0042},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0921889007000863},
	doi = {10.1016/j.robot.2007.07.002},
	abstract = {A globally consistent solution to the simultaneous localization and mapping {(SLAM)} problem in {2D} with three degrees of freedom {(DoF)} poses was presented by Lu and Milios {[F.} Lu, E. Milios, Globally consistent range scan alignment for environment mapping, Autonomous Robots 4 {(April)} (1997) 333�349]. To create maps suitable for natural environments it is however necessary to consider the {6DoF} pose case, namely the three Cartesian coordinates and the roll, pitch and yaw angles. This article describes the extension of the proposed algorithm to deal with these additional {DoFs} and the resulting non-linearities. Simplifications using Taylor expansion and Cholesky decomposition yield a fast application that handles the massive amount of {3D} data and the computational requirements due to the {6DoF.} Our experiments demonstrate the functionality of estimating the exact poses and their covariances in all {6DoF,} leading to a globally consistent map. The correspondences between scans are found automatically by use of a simple distance heuristic.},
	number = {2},
	journal = {Robotics and Autonomous Systems},
	author = {D Borrmann and J Elseberg and K Lingemann and A Nuchter and J Hertzberg},
	year = {2008},
	keywords = {3d, registration, slam},
	pages = {130--142}
},

@article{yan_huang_generic_2008,
	title = {A Generic Scheme for Progressive Point Cloud Coding},
	volume = {14},
	issn = {1077-2626},
	lccn = {0006},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4378368},
	doi = {10.1109/TVCG.2007.70441},
	abstract = {In this paper, we propose a generic point cloud encoder that provides a unified framework for compressing different attributes of point samples corresponding to {3D} objects with an arbitrary topology. In the proposed scheme, the coding process is led by an iterative octree cell subdivision of the object space. At each level of subdivision, the positions of point samples are approximated by the geometry centers of all tree-front cells, whereas normals and colors are approximated by their statistical average within each of the tree-front cells. With this framework, we employ attribute-dependent encoding techniques to exploit the different characteristics of various attributes. All of these have led to a significant improvement in the rate-distortion {(R-D)} performance and a computational advantage over the state of the art. Furthermore, given sufficient levels of octree expansion, normal space partitioning, and resolution of color quantization, the proposed point cloud encoder can be potentially used for lossless coding of {3D} point clouds.},
	number = {2},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Yan Huang and Jingliang Peng and {C.-C.J.} Kuo and M. Gopi},
	year = {2008},
	keywords = {octree, star},
	pages = {440--453}
},

@article{wand_processing_2008,
	title = {Processing and interactive editing of huge point clouds from {3D} scanners},
	volume = {32},
	issn = {00978493},
	lccn = {0005},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849308000253},
	doi = {10.1016/j.cag.2008.01.010},
	abstract = {This paper describes a new out-of-core multi-resolution data structure for real-time visualization, interactive editing and externally efficient processing of large point clouds. We describe an editing system that makes use of the novel data structure to provide interactive editing and preprocessing tools for large scanner data sets. Using the new data structure, we provide a complete tool chain for {3D} scanner data processing, from data preprocessing and filtering to manual touch-up and real-time visualization. In particular, we describe an out-of-core outlier removal and bilateral geometry filtering algorithm, a toolset for interactive selection, painting, transformation, and filtering of huge out-of-core point-cloud data sets and a real-time rendering algorithm, which all use the same data structure as storage backend. The interactive tools work in real-time for small model modifications. For large scale editing operations, we employ a two-resolution approach where editing is planned in real-time and executed in an externally efficient offline computation afterwards. We evaluate our implementation on example data sets of sizes up to 63 {GB,} demonstrating that the proposed technique can be used effectively in real-world applications.},
	number = {2},
	journal = {Computers \& Graphics},
	author = {M Wand and A Berner and M Bokeloh and P Jenke and A Fleck and M Hoffmann and B Maier and D Staneker and A Schilling and H Seidel},
	year = {2008},
	keywords = {point cloud, star},
	pages = {204--220}
},

@inproceedings{klasing_clustering_2008,
	address = {Pasadena, {CA,} {USA}},
	title = {A clustering method for efficient segmentation of {3D} laser data},
	lccn = {0009},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4543832},
	doi = {10.1109/ROBOT.2008.4543832},
	abstract = {In this paper we present a novel method for the efficient segmentation of {3D} laser range data. The proposed algorithm is based on a radially bounded nearest neighbor strategy and requires only two parameters. It yields deterministic, repeatable results and does not depend on any initialization procedure. The efficiency of the method is verified with synthetic and real {3D} data.},
	booktitle = {2008 {IEEE} International Conference on Robotics and Automation},
	author = {Klaas Klasing and Dirk Wollherr and Martin Buss},
	year = {2008},
	keywords = {segmentation, star},
	pages = {4043--4048}
},

@inproceedings{yapo_probabilistic_2008,
	address = {Anchorage, {AK,} {USA}},
	title = {A probabilistic representation of {LiDAR} range data for efficient {3D} object detection},
	lccn = {0002},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4563033},
	doi = {10.1109/CVPRW.2008.4563033},
	abstract = {We present a novel approach to {3D} object detection in scenes scanned by {LiDAR} sensors, based on a probabilistic representation of free, occupied, and hidden space that extends the concept of occupancy grids from robot mapping algorithms. This scene representation naturally handles {LiDAR} sampling issues, can be used to fuse multiple {LiDAR} data sets, and captures the inherent uncertainty of the data due to occlusions and clutter. Using this model, we formulate a hypothesis testing methodology to determine the probability that given {3D} objects are present in the scene. By propagating uncertainty in the original sample points, we are able to measure confidence in the detection results in a principled way. We demonstrate the approach in examples of detecting objects that are partially occluded by scene clutter such as camouflage netting.},
	booktitle = {2008 {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
	author = {Theodore C. Yapo and Charles V. Stewart and Richard J. Radke},
	year = {2008},
	keywords = {Object detection, occupancy grid},
	pages = {1--8}
},

@article{castro_statistical_2008,
	title = {Statistical optimization of octree searches},
	volume = {27},
	issn = {01677055},
	lccn = {0005},
	url = {http://doi.wiley.com/10.1111/j.1467-8659.2007.01104.x},
	doi = {10.1111/j.1467-8659.2007.01104.x},
	abstract = {This work emerged from the following observation: usual search procedures for octrees start from the root to retrieve the data stored at the leaves. But as the leaves are the farthest nodes to the root, why start from the root? With usual octree representations, there is no other way to access a leaf. However, hashed octrees allow direct access to any node, given its position in space and its depth in the octree. Search procedures take the position as an input, but the depth remains unknown. This work proposes to estimate the depth of an arbitrary node through a statistical optimization of the average cost of search procedures. As the highest costs of these algorithms are obtained when starting from the root, this method improves on both the memory footprint by the use of hashed octrees, and execution time through the proposed optimization.},
	number = {6},
	journal = {Computer Graphics Forum},
	author = {Rener Castro and Thomas Lewiner and H�lio Lopes and Geovan Tavares and Alex Bordignon},
	year = {2008},
	keywords = {octree, star},
	pages = {1557--1566}
},

@misc{ranjith_unnikrishnan_denoising_2008,
	title = {Denoising Manifold and {Non-Manifold} Point Clouds},
	lccn = {0004},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.72.8268},
	abstract = {The faithful reconstruction of {3-D} models from irregular and
noisy point samples is a task central to many applications
of computer vision and graphics. We present an approach to
denoising that naturally handles intersections of manifolds,
thus preserving high-frequency details without
oversmoothing. This is accomplished through the use of a
modified locally weighted regression algorithm that models a
neighborhood of points as an implicit product of linear
subspaces. By posing the problem as one of energy
minimization subject to constraints on the coefficients of a
higher order polynomial, we can also incorporate anisotropic
error models appropriate for data acquired with a range
sensor. We demonstrate the effectiveness of our approach
through some preliminary results in denoising synthetic data
in {2-D} and {3-D} domains. 1},
	author = {Ranjith Unnikrishnan and Martial Hebert},
	month = feb,
	year = {2008},
	keywords = {point cloud},
	annote = {{CiteSeerX} - Scientific Literature Digital Library and Search
Engine [http://citeseerx.ist.psu.edu/oai2] {(United} States)
{ER}}
},

@misc{freedman_depth_2008,
	title = {Depth mapping using projected patterns},
	author = {B. Freedman and A. Shpunt and M. Machline and Y. Arieli},
	month = apr,
	year = {2008},
	note = {{US} Patent App. 20,100/118,123}
},

@inproceedings{bertrand_douillard_laser_2008,
	address = {Zurich, Switzerland},
	title = {Laser and Vision Based Outdoor Object Mapping},
	lccn = {0012},
	abstract = {Generating rich representations of environments is a fundamental task in mobile robotics. In this paper we introduce a novel approach to building object type maps of outdoor environments. Our approach uses conditional random fields {(CRF)} to jointly classify the laser returns in a {2D} scan map into seven object types (car, wall, tree trunk, foliage, person, grass, and other). The spatial connectivity of the {CRF} is determined via Delaunay triangulation of the laser map. Our model incorporates laser shape features, visual appearance features, visual object detectors trained on existing image data sets and structural information extracted from clusters of laser returns. The parameters of the {CRF} are trained from partially labeled laser and camera data collected by a car moving through an urban environment. Our approach achieves 77\% accuracy in classifying the object types observed along a 750 meters long test trajectory.},
	booktitle = {Proceedings of Robotics: Science and Systems {IV}},
	author = {Dieter Fox Bertrand Douillard},
	month = jun,
	year = {2008},
	keywords = {classification, {CRF,} graphical models}
},

@inproceedings{shorter_triangulated_2008,
	title = {Triangulated, connected sets for building detection from irregularly spaced {LiDAR}},
	lccn = {0001},
	url = {http://dx.doi.org/10.1109/ISCCSP.2008.4537288},
	abstract = {A novel method for building detection from irregularly spaced Light Detection and Ranging {(LiDAR)} data is presented. Using features from the triangulation of the {LiDAR} data, the proposed method identifies ground points, and differentiates those points from building and non building points. Furthermore, the method differentiates the buildings from one another, subsequently recognizing each building as a unique entity. The primary objective in the design of the proposed algorithm is to completely automate the building detection process such that no user intervention (window or parameter adjustment, selection of control points, apriori knowledge dependency, etc.) is necessary.},
	booktitle = {Communications, Control and Signal Processing, 2008. {ISCCSP} 2008. 3rd International Symposium on},
	author = {N Shorter and T Kasparis},
	month = jun,
	year = {2008},
	keywords = {classification, lidar},
	pages = {560--565}
},

@article{bonin-font_visual_2008,
	title = {Visual Navigation for Mobile Robots: A Survey},
	volume = {53},
	issn = {0921-0296},
	lccn = {0023},
	url = {http://dx.doi.org/10.1007/s10846-008-9235-4},
	abstract = {Mobile robot vision-based navigation has been the source of countless research contributions, from the domains of both vision and control. Vision is becoming more and more common in applications such as localization, automatic map construction, autonomous navigation, path following, inspection, monitoring or risky situation detection. This survey presents those pieces of work, from the nineties until nowadays, which constitute a wide progress in visual navigation techniques for land, aerial and autonomous underwater vehicles. The paper deals with two major approaches: map-based navigation and mapless navigation. Map-based navigation has been in turn subdivided in metric map-based navigation and topological map-based navigation. Our outline to mapless navigation includes reactive techniques based on qualitative characteristics extraction, appearance-based localization, optical flow, features tracking, plane ground detection/tracking, etc... The recent concept of visual sonar has also been revised.},
	number = {3},
	journal = {Journal of Intelligent \& Robotic Systems},
	author = {Francisco {Bonin-Font} and Alberto Ortiz and Gabriel Oliver},
	month = nov,
	year = {2008},
	keywords = {localization, survey, vision, vslam},
	pages = {263--296}
},

@article{nuechter_towards_2008,
	title = {Towards semantic maps for mobile robots},
	volume = {56},
	issn = {0921-8890},
	lccn = {0031},
	url = {http://www.sciencedirect.com.ezproxy.tntech.edu/science/article/B6V16-4T72WWW-2/2/be7dd85831a18a8004ed06170dd53934},
	doi = {10.1016/j.robot.2008.08.001},
	abstract = {Intelligent autonomous action in ordinary environments calls for maps. {3D} geometry is generally required for avoiding collision with complex obstacles and to self-localize in six degrees of freedom (6 {DoF)} (x, y, z positions, roll, yaw, and pitch angles). Meaning, in addition to geometry, becomes inevitable if the robot is supposed to interact with its environment in a goal-directed way. A semantic stance enables the robot to reason about objects; it helps disambiguate or round off sensor data; and the robot knowledge becomes reviewable and communicable.
The paper describes an approach and an integrated robot system for semantic mapping. The prime sensor is a {3D} laser scanner. Individual scans are registered into a coherent {3D} geometry map by {6D} {SLAM.} Coarse scene features (e.g., walls, floors in a building) are determined by semantic labeling. More delicate objects are then detected by a trained classifier and localized. In the end, the semantic maps can be visualized for human inspection. We sketch the overall architecture of the approach, explain the respective steps and their underlying algorithms, give examples based on a working robot implementation, and discuss the findings.},
	number = {11},
	journal = {Robotics and Autonomous Systems},
	author = {Andreas N�chter and Joachim Hertzberg},
	month = nov,
	year = {2008},
	keywords = {{3D} mapping, {6D} {SLAM,} classifier, Object detection, Scene interpretation, Semantic mapping},
	pages = {915--926}
},

@article{cohen_solving_2009,
	title = {Solving Computational Problems with {GPU} Computing},
	volume = {11},
	issn = {0740-7475},
	lccn = {0004},
	url = {http://dx.doi.org/10.1109/MCSE.2009.144},
	abstract = {Modern {GPUs} are massively parallel microprocessors that can deliver very high performance for the parallel computations common in science and engineering.},
	number = {5},
	journal = {Computing in Science and Engineering},
	author = {Jonathan Cohen and Michael Garland},
	year = {2009},
	keywords = {cuda, gpu, survey},
	pages = {58--63},
	annote = {This paper tells us {CUDA} and its applications. There is a case study on {CFD.}}
},

@inproceedings{huber_real-time_2009,
	title = {Real-time photo-realistic visualization of {3D} environments for enhanced tele-operation of vehicles},
	lccn = {0002},
	doi = {10.1109/ICCVW.2009.5457431},
	abstract = {This paper describes a method for creating photorealistic three-dimensional {(3D)} models of real-world environments in real-time for the purpose of improving and extending the capabilities of vehicle tele-operation. Our approach utilizes the combined data from a laser scanner (for modeling {3D} geometry) and a video camera (for modeling surface appearance). The sensors are mounted on a moving vehicle platform, and a photo-realistic {3D} model of the vehicle's environment is generated and displayed to the remote operator in real time. Our model consists of three main components: a textured ground surface, textured or colorized non-ground objects, and a textured background for representing regions beyond the laser scanner's sensing horizon. Our approach enables many unique capabilities for vehicle tele-operation, including viewing the scene from virtual viewpoints (e.g., behind the vehicle or top down), seamless augmentation of the environment with digital objects, and improved robustness to transmission latencies and data dropouts.},
	booktitle = {Computer Vision Workshops {(ICCV} Workshops), 2009 {IEEE} 12th International Conference on},
	author = {D. Huber and H. Herman and A. Kelly and P. Rander and J. Ziglar},
	year = {2009},
	keywords = {{3D} environments, {3D} geometry modeling, colorized nonground objects, data visualisation, environment augmentation, laser scanner, moving vehicle platform, optical scanners, real time photo realistic visualization, robot vision, telerobotics, telerobotics, textured background, textured ground surface, {VEHICLES,} vehicles teleoperation, video camera, video cameras},
	pages = {1518--1525}
},

@misc{laaraiedh_implementation_2009,
	title = {Implementation of Kalman Filter with Python Language},
	lccn = {0000},
	abstract = {In this paper, we investigate the implementation of a Python code for a Kalman
Filter using the Numpy package. A Kalman Filtering is carried out in two steps:
Prediction and Update. Each step is investigated and coded as a function with matrix
input and output. These different functions are explained and an example of a
Kalman Filter application for the localization of mobile in wireless networks is
given.},
	author = {M. Laaraiedh},
	year = {2009},
	keywords = {kalman, python, star}
},

@article{nekrich_data_2009,
	title = {Data Structures for Approximate Range Counting},
	lccn = {0000},
	url = {http://arxiv.org/abs/0906.2738},
	abstract = {We present new data structures for approximately counting the number of
points in orthogonal range.


There is a deterministic linear space data structure that supports updates in
O(1) time and approximates the number of elements in a {1-D} range up to an
additive term \$k{\textasciicircum}{1/c}\$ in {\$O({\textbackslash}log} {\textbackslash}log U{\textbackslash}cdot{\textbackslash}log {\textbackslash}log n)\$ time, where \$k\$ is
the number of elements in the answer, {\$U\$} is the size of the universe and \$c\$
is an arbitrary fixed constant. We can estimate the number of points in a
two-dimensional orthogonal range up to an additive term \$ k{\textasciicircum}{{\textbackslash}rho}\$ in {\$O({\textbackslash}log}
{\textbackslash}log U+ (1/{\textbackslash}rho){\textbackslash}log{\textbackslash}log n)\$ time for any \${\textbackslash}rho{\textgreater}0\$. We can estimate the number
of points in a three-dimensional orthogonal range up to an additive term
\$k{\textasciicircum}{{\textbackslash}rho}\$ in {\$O({\textbackslash}log} {\textbackslash}log U + ({\textbackslash}log{\textbackslash}log n){\textasciicircum}3+ (3{\textasciicircum}v){\textbackslash}log{\textbackslash}log n)\$ time for
\$v={\textbackslash}log {\textbackslash}frac{1}{{\textbackslash}rho}/{\textbackslash}log {3/2}+2\$.},
	author = {Yakov Nekrich},
	year = {2009},
	keywords = {counting, data, range, range search, star, structure, theory}
},

@article{park_multiscale_2009,
	title = {Multiscale representation and compression of {3-D} point data},
	volume = {11},
	lccn = {0000},
	abstract = {A compact representation scheme is presented for {3-D} point data. To describe underlying surface from raw point samples, we dyadically divide a {3-D} domain enclosing whole points. Then, local points in each cube are approximated by a plane patch, yielding a multiscale representation of {3-D} surface. To reduce the redundancy between different scale models, the geometry innovation is evaluated between different scale planes, which reveals the Euclidian distance between planes. Finally, the geometry innovation coefficients are compressed by a zerotree-based encoder. Based on the multiscale plane representation of {3-D} geometry and the efficient plane decomposition method, the proposed scheme provides a desirable framework for {3-D} point geometry processing.},
	number = {1},
	journal = {Trans. Multi.},
	author = {{Sung-Bum} Park and {Sang-Uk} Lee},
	year = {2009},
	keywords = {plane fitting},
	pages = {177--182}
},

@misc{persson_3d_2009,
	title = {{3D} Scan-based Navigation using {Multi-Level} Surface Maps},
	url = {http://www.essays.se/essay/496e9a83e5/},
	abstract = {The field of research connected to mobile robot navigation is much broader than the scope of this thesis. Hence in this report, the navigation topic is narrowed down to primarily concerning mapping and scan matching techniques that were used to achieve the overall task of navigation nature. Where the work presented within this report is based on an existing robot platform with technique for providing {3D} point-clouds, as result of {3D} scanning, and functionality for planning for and following a path. In this thesis it is presented how a scan matching algorithm is used for securing the alignment between provided succession point-clouds. Since the computational time of nearest neighbour search is a commonly discussed aspect of scan matching, suggestions about techniques for decreasing the computational time are also presented within this report. With secured alignment, the challenge was within representing provided point-clouds by a map model. Provided point-clouds were of {3D} character, thus a mapping technique is presented that provides rough {3D} representations of the environment. A problem that arose with a {3D} map representation was that given functionality for path planning required a {2D} representation. This is addressed by translating the {3D} map at a specific height level into a {2D} map usable for path planning, where this report suggest a novel traversability analysis approach with the use of a tree structure.},
	author = {Andreas Persson},
	year = {2009},
	keywords = {multi-level surface map, star},
	howpublished = {http://www.essays.se/essay/496e9a83e5/}
},

@article{ratliff_learning_2009,
	title = {Learning to search: Functional gradient techniques for imitation learning},
	volume = {27},
	lccn = {0024},
	url = {http://dx.doi.org/10.1007/s10514-009-9121-3},
	abstract = {Abstract Programming robot behavior remains a challenging task. While it is often easy to abstractly define or even demonstrate a desired behavior, designing a controller that embodies the same behavior is difficult, time consuming, and ultimately expensive. The machine learning paradigm offers the promise of enabling �programming by demonstration� for developing high-performance robotic systems. Unfortunately, many �behavioral cloning� {{(Bain}} and Sammut in Machine intelligence agents. London: Oxford University Press, 1995; Pomerleau in Advances in neural information processing systems 1, 1989; {{LeCun}} et al. in Advances in neural information processing systems 18, 2006) approaches that utilize classical tools of supervised learning (e.g. decision trees, neural networks, or support vector machines) do not fit the needs of modern robotic systems. These systems are often built atop sophisticated planning algorithms that efficiently reason far into the future; consequently, ignoring these planning algorithms in lieu of a supervised learning approach often leads to myopic and poor-quality robot performance. While planning algorithms have shown success in many real-world applications ranging from legged locomotion {{(Chestnutt}} et al. in Proceedings of the {{IEEE-RAS}} international conference on humanoid robots, 2003) to outdoor unstructured navigation {{(Kelly}} et al. in Proceedings of the international symposium on experimental robotics {{(ISER),}} 2004; Stentz et al. in {{AUVSI�s}} unmanned systems, 2007), such algorithms rely on fully specified cost functions that map sensor readings and environment models to quantifiable costs. Such cost functions are usually manually designed and programmed. Recently, a set of techniques has been developed that explore learning these functions from expert human demonstration. These algorithms apply an inverse optimal control approach to find a cost function for which planned behavior mimics an expert�s demonstration. The work we present extends the Maximum Margin Planning {{(MMP)}} {{(Ratliff}} et al. in Twenty second international conference on machine learning {{(ICML06),}} 2006a) framework to admit learning of more powerful, non-linear cost functions. These algorithms, known collectively as {{LEARCH}} {{(LEArning}} to {{seaRCH),}} are simpler to implement than most existing methods, more efficient than previous attempts at non-linearization {{(Ratliff}} et al. in {{NIPS,}} 2006b), more naturally satisfy common constraints on the cost function, and better represent our prior beliefs about the function�s form. We derive and discuss the framework both mathematically and intuitively, and demonstrate practical real-world performance with three applied case-studies including legged locomotion, grasp planning, and autonomous outdoor unstructured navigation. The latter study includes hundreds of kilometers of autonomous traversal through complex natural environments. These case-studies address key challenges in applying the algorithm in practical settings that utilize state-of-the-art planners, and which may be constrained by efficiency requirements and imperfect expert demonstration.},
	number = {1},
	journal = {Autonomous Robots},
	author = {Nathan Ratliff and David Silver and J Bagnell},
	year = {2009},
	keywords = {inverse optimal control},
	pages = {25--53}
},

@inproceedings{schuon_lidarboost:_2009,
	title = {{LidarBoost:} Depth superresolution for {ToF} {3D} shape scanning},
	isbn = {1063-6919},
	lccn = {0000},
	shorttitle = {{LidarBoost}},
	doi = {10.1109/CVPR.2009.5206804},
	abstract = {Depth maps captured with time-of-flight cameras have very low data quality: the image resolution is rather limited and the level of random noise contained in the depth maps is very high. Therefore, such flash lidars cannot be used out of the box for high-quality {3D} object scanning. To solve this problem, we present {LidarBoost,} a {3D} depth superresolution method that combines several low resolution noisy depth images of a static scene from slightly displaced viewpoints, and merges them into a high-resolution depth image. We have developed an optimization framework that uses a data fidelity term and a geometry prior term that is tailored to the specific characteristics of flash lidars. We demonstrate both visually and quantitatively that {LidarBoost} produces better results than previous methods from the literature.},
	booktitle = {Computer Vision and Pattern Recognition, 2009. {CVPR} 2009. {IEEE} Conference on},
	author = {S. Schuon and C. Theobalt and J. Davis and S. Thrun},
	year = {2009},
	keywords = {{3D} depth map superresolution method, computational geometry, data quality, flash {lidarBoost,} geometry prior term, image resolution, lidarboost, optical radar, optimisation, optimization framework, radar computing, radar imaging, radar resolution, random noise, solid modelling, star, static scene, {ToF} {3D} shape scanning model},
	pages = {343--350}
},

@incollection{madhavan_quantitative_2009,
	title = {Quantitative Assessment of {Robot-Generated} Maps},
	isbn = {978-1-4419-0492-8},
	lccn = {0000},
	url = {http://dx.doi.org/10.1007/978-1-4419-0492-8_10},
	abstract = {Mobile robotic mapping is now considered to be a sufficiently mature field with demonstrated successes in various domains. While much progress has been made in the development of computationally efficient and consistent mapping schemes, it is still murky, at best, on how these maps can be evaluated. We are motivated by the absence of an accepted standard for quantitatively measuring the performance of robotic mapping systems against user-defined requirements. It is our belief that the development of standardized methods for quantitatively evaluating existing robotic technologies will improve the utility of mobile robots in already established application areas, such as vacuum cleaning, robot surveillance, and bomb disposal. This approach will also enable the proliferation and acceptance of such technologies in emerging markets. This chapter summarizes our preliminary efforts by bringing together the research community towards addressing this important problem which has ramifications not only from researchers� perspective but also from consumers�, robot manufacturers�, and developers� viewpoints.},
	booktitle = {Performance Evaluation and Benchmarking of Intelligent Systems},
	publisher = {Springer {US}},
	author = {Raj Madhavan and Edward Tunstel and Elena Messina and C. Scrapper and R. Madhavan and R. Lakaemper and A. Censi and A. Godil and A. Wagan and A. Jacoff},
	year = {2009},
	keywords = {Computer Science, evaluation, mapping, star},
	pages = {221--248},
	annote = {Mobile robotic mapping is now considered to be a sufficiently mature field with demonstrated successes in various domains. While much progress has been made in the development of computationally efficient and consistent mapping schemes, it is still murky, at best, on how these maps can be evaluated. We are motivated by the absence of an accepted standard for quantitatively measuring the performance of robotic mapping systems against user-defined requirements. It is our belief that the development of standardized methods for quantitatively evaluating existing robotic technologies will improve the utility of mobile robots in already established application areas, such as vacuum cleaning, robot surveillance, and bomb disposal. This approach will also enable the proliferation and acceptance of such technologies in emerging markets. This chapter summarizes our preliminary efforts by bringing together the research community towards addressing this important problem which has ramifications not only from researchers� perspective but also from consumers�, robot manufacturers�, and developers� viewpoints.}
},

@article{yguel_error-driven_2009,
	title = {{Error-Driven} Refinement of Multi-scale Gaussian Maps},
	volume = {In Proceedings of the 14th International Symposium on Robotics Research.},
	lccn = {0001},
	abstract = {The accuracy of Grid-based maps can be enhanced by putting a Gaussianin every cell of the map. However, this solution works poorly for coarse discretiza-tions in multi-scale maps. This paper proposes a method to overcome the problemby allowing several Gaussians per cell at coarse scales. We introduce a multi-scaleapproach to compute an error measure for each scale with respect to the finer {one.This} measure constitutes the basis of an incremental refinement algorithm wherethe error is used to select the cells in which the number of Gaussians should be in-creased. As a result, the accuracy of the map can be selectively enhanced by makingefficient use of computational resources. Moreover, the error measure can also beapplied to compress a map by deleting the finer scale clusters when the error in thecoarse ones is {low.The} approach is based on a recent clustering algorithm that models input data {asGaussians} rather than points, as is the case for conventional algorithms. In additionto mapping, this clustering paradigm makes it possible to perform map merging andto represent feature hierarchies under a sound theoretical framework. Our approachhas been validated with both real and simulated {3-D} data.},
	journal = {In Proceedings of the 14th International Symposium on Robotics Research.},
	author = {M. Yguel and D. Vasquez and O. Aycard and R. Siegwart and C. Laugier},
	year = {2009},
	keywords = {gaussian map, occupancy grid, star}
},

@article{bai_digital_2009,
	title = {Digital Topology on Adaptive Octree Grids},
	volume = {34},
	issn = {0924-9907},
	lccn = {0000},
	url = {http://www.springerlink.com/index/10.1007/s10851-009-0140-7},
	doi = {10.1007/s10851-009-0140-7},
	abstract = {The theory of digital topology is used in many different image processing and computer graphics algorithms. Most of the existing theories apply to uniform cartesian grids, and they are not readily extensible to new algorithms targeting at adaptive cartesian grids. This article provides a rigorous extension of the classical digital topology framework for adaptive octree grids, including the characterization of adjacency, connected components, and simple points. Motivating examples, proofs of the major propositions, and algorithm pseudocodes are provided.},
	number = {2},
	journal = {Journal of Mathematical Imaging and Vision},
	author = {Ying Bai and Xiao Han and Jerry L. Prince},
	year = {2009},
	keywords = {octree},
	pages = {165--184},
	annote = {{{\textless}p{\textgreater}Abstract}��The theory of digital topology is used in many different image  processing and computer graphics algorithms. Most of the existing  theories apply to uniform cartesian grids, and they are not readily  extensible to new algorithms targeting at adaptive cartesian grids. This  article provides a rigorous extension of the classical digital topology  framework for adaptive octree grids, including the characterization of  adjacency, connected components, and simple points. Motivating examples,  proofs of the major propositions, and algorithm pseudocodes are  provided.{\textless}/p{\textgreater}}
},

@article{kalra_incremental_2009,
	title = {Incremental reconstruction of generalized Voronoi diagrams on grids},
	volume = {57},
	issn = {09218890},
	lccn = {0009},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0921889007000966},
	doi = {10.1016/j.robot.2007.01.009},
	abstract = {We present an incremental algorithm for constructing and reconstructing Generalized Voronoi Diagrams {(GVDs)} on grids. Our algorithm, Dynamic Brushfire, uses techniques from the path planning community to efficiently update {GVDs} when the underlying environment changes or when new information concerning the environment is received. Dynamic Brushfire is an order of magnitude more efficient than current approaches. In this paper we present the algorithm, compare it to current approaches on several experimental domains involving both simulated and real data, and demonstrate its usefulness for multirobot path planning.},
	number = {2},
	journal = {Robotics and Autonomous Systems},
	author = {N Kalra and D Ferguson and A Stentz},
	year = {2009},
	keywords = {occupancy grid, star, voronoi},
	pages = {123--128}
},

@inproceedings{marton_fast_2009,
	address = {Kobe},
	title = {On fast surface reconstruction methods for large and noisy point clouds},
	lccn = {0004},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5152628},
	doi = {10.1109/ROBOT.2009.5152628},
	abstract = {In this paper we present a method for fast surface reconstruction from large noisy datasets. Given an unorganized {3D} point cloud, our algorithm recreates the underlying surface's geometrical properties using data resampling and a robust triangulation algorithm in near realtime. For resulting smooth surfaces, the data is resampled with variable densities according to previously estimated surface curvatures. Incremental scans are easily incorporated into an existing surface mesh, by determining the respective overlapping area and reconstructing only the updated part of the surface mesh. The proposed framework is flexible enough to be integrated with additional point label information, where groups of points sharing the same label are clustered together and can be reconstructed separately, thus allowing fast updates via triangular mesh decoupling. To validate our approach, we present results obtained from laser scans acquired in both indoor and outdoor environments.},
	booktitle = {2009 {IEEE} International Conference on Robotics and Automation},
	author = {Zoltan Csaba Marton and Radu Bogdan Rusu and Michael Beetz},
	year = {2009},
	keywords = {surface fitting},
	pages = {3218--3223}
},

@inproceedings{pathak_revisiting_2009,
	address = {Kobe},
	title = {Revisiting uncertainty analysis for optimum planes extracted from {3D} range sensor point-clouds},
	lccn = {0010},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5152502},
	doi = {10.1109/ROBOT.2009.5152502},
	abstract = {In this work, we utilize a recently studied more accurate range noise model for {3D} sensors to derive from scratch the expressions for the optimum plane which best fits a point-cloud and for the combined covariance matrix of the plane's parameters. The parameters in question are the plane's normal and its distance to the origin. The range standard-deviation model used by us is a quadratic function of the true range and is a function of the incidence angle as well. We show that for this model, the maximum-likelihood plane is biased, whereas the least-squares plane is not. The plane-parameters' covariance matrix for the least-squares plane is shown to possess a number of desirable properties, e.g., the optimal solution forms its null-space and its components are functions of easily understood terms like the planar-patch's center and scatter. We verify our covariance expression with that obtained by the eigenvector perturbation method. We further compare our method to that of renormalization with respect to the theoretically best covariance matrix in simulation. The application of our approach to real-time range-image registration and plane fusion is shown by an example using a commercially available {3D} range sensor. Results show that our method has good accuracy, is fast to compute, and is easy to interpret intuitively.},
	booktitle = {2009 {IEEE} International Conference on Robotics and Automation},
	author = {K. Pathak and N. Vaskevicius and A. Birk},
	year = {2009},
	keywords = {plane fitting},
	pages = {1631--1636}
},

@article{bachthaler_efficient_2009,
	title = {Efficient and Adaptive Rendering of {2-D} Continuous Scatterplots},
	volume = {28},
	issn = {01677055},
	lccn = {0005},
	url = {http://doi.wiley.com/10.1111/j.1467-8659.2009.01478.x},
	doi = {10.1111/j.1467-8659.2009.01478.x},
	abstract = {We extend the rendering technique for continuous scatterplots to allow for a broad class of interpolation methods within the spatial grid instead of only linear interpolation. To do this, we propose an approach that projects the image of a cell from the spatial domain to the scatterplot domain. We approximate this image using either the convex hull or an axis-aligned rectangle that forms a tight fit of the projected points. In both cases, the approach relies on subdivision in the spatial domain to control the approximation error introduced in the scatterplot domain. Acceleration of this algorithm in homogeneous regions of the spatial domain is achieved using an octree hierarchy. The algorithm is scalable and adaptive since it allows us to balance computation time and scatterplot quality. We evaluate and discuss the results with respect to accuracy and computational speed. Our methods are applied to examples of {2-D} transfer function design.},
	number = {3},
	journal = {Computer Graphics Forum},
	author = {Sven Bachthaler and Daniel Weiskopf},
	year = {2009},
	keywords = {graphics, interpolation},
	pages = {743--750}
},

@article{ryde_3d_2009,
	title = {{3D} mapping with multi-resolution occupied voxel lists},
	volume = {28},
	issn = {0929-5593},
	lccn = {0003},
	url = {http://www.springerlink.com/index/10.1007/s10514-009-9158-3},
	doi = {10.1007/s10514-009-9158-3},
	abstract = {Abstract  Most current navigation algorithms in mobile robotics produce {2D} maps from data provided by {2D} sensors. In large part this is due to the availability of suitable {3D} sensors and difficulties of managing the large amount of data supplied by {3D} sensors. This paper presents a novel, multi-resolution algorithm that aligns {3D} range data stored in occupied voxel lists so as to facilitate the construction of {3D} maps. Multi-resolution occupied voxel lists {(MROL)} are voxel based data structures that efficiently represent {3D} scan and map information. The process described in this research can align a sequence of scans to produce maps and localise a range sensor within a prior global map. An office environment (200 square metres) is mapped in {3D} at 0.02 m resolution, resulting in a 200,000 voxel occupied voxel list. Global localisation within this map, with no prior pose estimate, is completed in 5 seconds on a 2 {GHz} processor. The {MROL} based sequential scan matching is compared to a standard iterative closest point {(ICP)} implementation with an error in the initial pose estimate of plus or minus 1 m and 90 degrees. {MROL} correctly scan matches 94\% of scans to within 0.1 m as opposed to {ICP} with 30\% within 0.1 m.},
	number = {2},
	journal = {Autonomous Robots},
	author = {Julian Ryde and Huosheng Hu},
	year = {2009},
	keywords = {muli-resolution occupied voxel list, occupancy grid, registration, star, voxel list},
	pages = {169--185},
	annote = {{{\textless}p{\textgreater}Given} that 3d mapping is sparse, it might be more prudent to not use grid implementations, but simply lists of occupied (over .5) voxels.{\textless}/p{\textgreater}
{{\textless}p{\textgreater}They} propose something similar to my "lazy updating" note in that the ray-tracing of free space is not done until the path planning phase, and it reconstructed from the stored poses.{\textless}/p{\textgreater}
{{\textless}p{\textgreater}When} doing particle filtering, they do some interesting things. First, when doing global localization, they downsample the map successively in order to search over the entire pose space. This, I think, is a key idea for many types of mapping problems. When the search space is too large, it may be better to quickly throw out regions of low probability. Should note that the downsampling risks running into aliasing problems. That is, if two points are close to the boundary, they will forever be separated intro two different voxels. The authors speak of an offset technique that alleviates this problem. The space isn't simply subdivided, but it is subdivided with an offset. Thus, the coarser cell contains one full cell and parts of the smaller cells. I would be interested to see a greater analysis here besides the obvious intuitive benefits.{\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}
{\textless}p{\textgreater}end result: global localization with no odometry in 3d in under 5 seconds (!){\textless}/p{\textgreater}
{{\textless}p{\textgreater}REALLY} fantastic paper. Lots of good ideas and information; including the justification of simply using "counts" in voxels and not explicitly representing empty space. p.16 provides a good wrap-up.{\textless}/p{\textgreater}
{{\textless}p{\textgreater}The} {3D} {ICP} implementation is an open source{\textless}br /{\textgreater}one from the Mobile Robotics Programming Toolkit {(MRPT){\textless}br} {/{\textgreater}(Gonz�alez} et al, 2009) version 0.6.5.{\textless}/p{\textgreater}
{\textless}p{\textgreater}�{\textless}/p{\textgreater}}
},

@inproceedings{heracles_fast_2009,
	address = {St. Louis, {MO,} {USA}},
	title = {Fast detection of arbitrary planar surfaces from unreliable {3D} data},
	lccn = {0005},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5353932},
	doi = {10.1109/IROS.2009.5353932},
	abstract = {Man-made real-world environments are dominated by planar surfaces many of which constitute behavior-relevant entities. Thus, the ability to perceive planar surfaces is vital for any embodied system operating in such environments, be it human or robotic. In this paper, we present an architecture for detection and estimation of planar surfaces in the scene from calibrated stereo images. They are represented in a behavior-oriented way, focusing on geometrical properties that are relevant for enabling basic interaction between a robot and the planar surfaces it perceives. Ego-motion of the robot is compensated for by transforming the representations into a global coordinate system using the kinematics of the robot. Our architecture is able to detect and estimate arbitrary planar surfaces, regardless of their visual appearance, their geometrical properties other than planarity and their being static or arbitrarily moving. The latter is achieved by processing each frame independently of the others. Stable representations are obtained by establishing spatio-temporal coherence between the single-frame representations of subsequent frames. Based on a {RANSAC} approach to plane fitting, our method is robust to unreliable {3D} data such as obtained by local stereo correlation, for example. In our experiments using the Honda humanoid robot {ASIMO,} we show that our method is able to provide a robot in real-time with representations of planar surfaces in its environment that are sufficiently accurate for basic interaction},
	booktitle = {2009 {IEEE/RSJ} International Conference on Intelligent Robots and Systems},
	author = {Martin Heracles and Bram Bolder and Christian Goerick},
	year = {2009},
	keywords = {plane fitting},
	pages = {5717--5724}
},

@inproceedings{ryde_non-cubic_2009,
	address = {St. Louis, {MO,} {USA}},
	title = {Non-cubic occupied voxel lists for robot maps},
	lccn = {0002},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5354292},
	doi = {10.1109/IROS.2009.5354292},
	abstract = {An alternative to the conventional quantization for occupied voxel lists in both {2D} and {3D} is presented. The performance metrics of the hexagonal lattice in {2D} and the face centred and body centred cubic lattices in {3D} are investigated and compared to their square and cubic counterparts. It is found that quantization to alternative lattices yields some improvements. Ultimately, the D3 or face centred cubic lattice is highlighted for its lower quantization error, lower rotation variability and higher order rotational symmetry. It has three times less occupied voxel count pose variability than a standard cubic occupied voxel list. These improvements have implications for {SLAM} and path planning.},
	booktitle = {2009 {IEEE/RSJ} International Conference on Intelligent Robots and Systems},
	author = {Julian Ryde and Michael Brunig},
	year = {2009},
	keywords = {lattice occupied voxel, non-cubic voxel, voxel list},
	pages = {4771--4776}
},

@article{vasudevan_gaussian_2009,
	title = {Gaussian process modeling of large-scale terrain},
	volume = {26},
	issn = {15564959},
	lccn = {0011},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/rob.20309/abstract},
	doi = {10.1002/rob.20309},
	abstract = {Building a model of large-scale terrain that can adequately handle uncertainty and incompleteness in a statistically sound way is a challenging problem. This work proposes the use of Gaussian processes as models of large-scale terrain. The proposed model naturally provides a multiresolution representation of space, incorporates and handles uncertainties aptly, and copes with incompleteness of sensory information. Gaussian process regression techniques are applied to estimate and interpolate (to fill gaps in occluded areas) elevation information across the field. The estimates obtained are the best linear unbiased estimates for the data under consideration. A single nonstationary (neural network) Gaussian process is shown to be powerful enough to model large and complex terrain, effectively handling issues relating to discontinuous data. A local approximation method based on a �moving window� methodology and implemented using k-dimensional {(KD)-trees} is also proposed. This enables the approach to handle extremely large data sets, thereby completely addressing its scalability issues. Experiments are performed on large-scale data sets taken from real mining applications. These data sets include sparse mine planning data, which are representative of a global positioning system�based survey, as well as dense laser scanner data taken at different mine sites. Further, extensive statistical performance evaluation and benchmarking of the technique has been performed through cross-validation experiments. They conclude that for dense and/or flat data, the proposed approach will perform very competitively with grid-based approaches using standard interpolation techniques and triangulated irregular networks using triangle-based interpolation techniques; for sparse and/or complex data, however, it would significantly outperform them.},
	number = {10},
	journal = {Journal of Field Robotics},
	author = {Shrihari Vasudevan and Fabio Ramos and Eric Nettleton and Hugh {Durrant-Whyte}},
	year = {2009},
	keywords = {gaussian process, k-d-tree, star},
	pages = {812--840}
},

@article{labatut_robust_2009,
	title = {Robust and Efficient Surface Reconstruction From Range Data},
	volume = {28},
	issn = {01677055},
	lccn = {0004},
	url = {http://doi.wiley.com/10.1111/j.1467-8659.2009.01530.x},
	doi = {10.1111/j.1467-8659.2009.01530.x},
	abstract = {We describe a robust but simple algorithm to reconstruct a surface from a set of merged range scans. Our key
contribution is the formulation of the surface reconstruction problem as an energy minimisation problem that
explicitly models the scanning process. The adaptivity of the Delaunay triangulation is exploited by restricting the
energy to inside/outside labelings of Delaunay tetrahedra. Our energy measures both the output surface quality
and how well the surface agrees with soft visibility constraints. Such energy is shown to perfectly fit into the
minimum s ? t cuts optimisation framework, allowing fast computation of a globally optimal tetrahedra labeling,
while avoiding the �shrinking bias� that usually plagues graph cuts methods.
The behaviour of our method confronted to noise, undersampling and outliers is evaluated on several data sets and
compared with othermethods through different experiments: its strong robustness wouldmake our method practical
not only for reconstruction from range data but also from typically more difficult dense point clouds, resulting for
instance from stereo image matching. Our effective modeling of the surface acquisition inverse problem, along with
the unique combination of Delaunay triangulation and minimum s ? t cuts, makes the computational requirements
of the algorithm scale well with respect to the size of the input point cloud.},
	number = {8},
	journal = {Computer Graphics Forum},
	author = {P. Labatut and {J.-P.} Pons and R. Keriven},
	year = {2009},
	keywords = {surface fitting},
	pages = {2275--2290}
},

@inproceedings{tang_characterization_2009,
	title = {Characterization of Three Algorithms for Detecting Surface Flatness Defects from Dense Point Clouds},
	volume = {7239},
	lccn = {0002},
	abstract = {Surface flatness assessment is required for controlling the quality of various products, such as building and mechanical components. During such assessments, inspectors collect data capturing surface shape, and use it to identify flatness defects, which are surface parts deviating from a reference plane by more than the tolerance. Laser scanners can deliver accurate and dense {3D} point clouds capturing detailed surface shape for flatness defect detection in minutes. However, few studies explore algorithms for detecting surface flatness defects from dense point clouds, and provide quantitative analysis of defect detection performance. This paper presents three surface-flatness-defect detection algorithms and our experimental investigations for characterizing their performances. We created a test bed, which is composed of several flat boards with defects of various sizes on them, and tested two scanners and three algorithms using it. The results are reported in the form of a set of performance maps indicating under which conditions (using which scanner, scanning distance, selected defect detection algorithm, and angular resolution of the scanner, etc.), what types of defects are detected. Our analysis shows that scanning distance and angular resolution substantially influence the detection accuracy. Comparative analyses of scanners and defect detection algorithms are also presented.},
	booktitle = {{IS\&T/SPIE} Conference on Electronic Imaging, Science and Technology},
	publisher = {{SPIE}},
	author = {Pingbo Tang and Burcu Akinci and Daniel Huber},
	month = jan,
	year = {2009},
	keywords = {plane fitting}
},

@article{fernandez_clustering_2009,
	title = {Clustering and line detection in laser range measurements},
	issn = {09218890},
	lccn = {0000},
	url = {http://dx.doi.org/10.1016/j.robot.2009.10.008},
	abstract = {This article presents two algorithms that extract information from laser range data. They are designed to work sequentially. The first method ( dcc ) separates the data into clusters by means of a convolution operation, using a high-pass filter. The second one ( reholt ) performs line detection in each of the clusters previously discovered. The reliability of the algorithms devised is tested on the experimental data collected both indoors and outdoors. When compared with other methods found in the literature, the ones proposed here prove to achieve higher performance.},
	journal = {Robotics and Autonomous Systems},
	author = {Carlos Fernandez and Vidal Moreno and Belen Curto and Vicente},
	month = nov,
	year = {2009},
	keywords = {clustering, computer\_vision, feature\_extraction, laser\_range, line\_detection, segmentation}
},

@book{montemerlo_fastslam:_2009,
	title = {{FastSLAM:} A Scalable Method for the Simultaneous Localization and Mapping Problem in Robotics},
	isbn = {3642079784},
	lccn = {0035},
	url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&path=ASIN/3642079784},
	abstract = {{(Book)}},
	publisher = {Springer Berlin Heidelberg},
	author = {Michael Montemerlo},
	month = dec,
	year = {2009},
	keywords = {estimation, fastslam, particle-filter, rbpf, robotics, slam}
},

@inproceedings{behley_learning_2010,
	title = {Learning to Hash Logistic Regression for Fast {3D} Scan Point Classification},
	lccn = {0001},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.169.7112},
	abstract = {Segmenting range data into semantic categories has become a more and more active field of research in robotics. In this paper, we advocate to view this task as a problem of fast, large-scale retrieval. Intuitively, given a dataset of millions of labeled scan points and their neighborhoods, we simply search for similar points in the datasets and use the labels of the retrieved ones to predict the labels of a novel point using some local prediction model such as majority vote or logistic regression. However, actually carrying this out requires highly efficient ways of (1) storing millions of scan points in memory and (2) quickly finding similar scan points to a target scan point. In this paper, we propose to address both issues by employing Weiss et al.�s recent spectral hashing. It represents each item in a database by a compact binary code that is constructed so that similar items will have similar binary code words. In turn, similar neighbors have codes within a small Hamming distance of the code for the query. Then, we learn a logistic regression model locally over all points with the same binary code word. Our experiments on real world {3D} scans show that the resulting approach, called spectrally hashed logistic regression, can be ultra fast at prediction time and outperforms state-of-the art approaches such as logistic regression and nearest neighbor},
	booktitle = {Intelligent Robots and Systems, 2010. {IROS} 2010. {IEEE/RSJ} International Conference on},
	author = {Jens Behley and Kristian Kersting and Dirk Schulz and Volker Steinhage and Armin B Cremers},
	year = {2010},
	keywords = {classification, star}
},

@inproceedings{chilton_analysis_2010,
	title = {Analysis of data structures used for storing and processing {3D} {LADAR} data},
	lccn = {0000},
	abstract = {This paper compares the use of a point cloud data storage structure with a voxel based storage structure for {3D} data collected with {LADAR.} The motivation for this work is to support the development of a classification system to model the environment of an autonomous vehicle operating in an unstructured natural setting. The classifier should be able to detect trees, bushes, and ground based on the data. Most {LADAR} sensors provide accurate {2-D} range information in a plane, but we generate {3-D} data from the sensor by articulating it using a pan-tilt mechanism. A {3-D} grid of voxels is used with each voxel representing a cubic region in space with an associated value to indicate the region's occupancy. We discuss how this voxel representation compares with a point cloud representation in the process of data collection, data storage, and data processing and also look at the complexity of merging new data with old data in the same region. There are two main contributions. The first is comparing a possible voxel based data representation with one possible point cloud data representation. The second is determining reasonable parameters (voxel size, {LADAR} pitch angular velocity, and distance to the target) to facilitate classification of the voxel data. The scope of this paper is confined to analyzing data size, scanning time required for accurate classification, and processing efficiency. Experimental data size, density, and classification performance results are presented.},
	booktitle = {Control Automation and Systems {(ICCAS),} 2010 International Conference on},
	author = {R. Chilton and C. Crane and Kuk Cho},
	year = {2010},
	keywords = {{2D} range information, 3d, {3D} grid, {3D} {LADAR} data processing, autonomous vehicle, classification system, computer graphics, data analysis, data collection processing, data structure analysis, data structures, electrical engineering computing, {LADAR} sensors, occupancy grid, optical radar, pan-tilt mechanism, pattern classification, point cloud data storage structure, point cloud representation, star, voxel based data representation, voxel based storage structure},
	pages = {1496--1501}
},

@misc{kaess_bayes_2010,
	title = {The Bayes Tree: Enabling Incremental Reordering and Fluid Relinearization for Online Mapping},
	lccn = {0000},
	abstract = {In this paper we present a novel data structure, the Bayes tree, which exploits the connections between graphical model inference and sparse linear algebra. The proposed data structure provides a new perspective on an entire class of simultaneous localization and mapping {(SLAM)} algorithms. Similar to a junction tree, a Bayes tree encodes a factored probability density, but unlike the junction tree it is directed and maps more naturally to the square root information matrix of the {SLAM} problem. This makes it eminently suited to encode the sparse nature of the problem, especially in a smoothing and mapping {(SAM)} context. The inherent sparsity of {SAM} has already been exploited in the literature to produce efficient solutions in both batch and online mapping. The graphical model perspective allows us to develop a novel incremental algorithm that seamlessly incorporates reordering and relinearization. This obviates the need for expensive periodic batch operations from previous approaches, which negatively affect the performance and detract from the intended online nature of the algorithm. The new method is evaluated using simulated and real-world datasets in both landmark and pose {SLAM} settings.},
	publisher = {{MIT} {CSAIL} Technical Report},
	author = {michael Kaess and Frank Dellaert and Richard Roberts and Viorela Ila},
	year = {2010},
	note = {{MIT-CSAIL-TR-2010-021}},
	keywords = {slam, star},
	annote = {{{\textless}p{\textgreater}Bayes} tree is a data structure that allows incremental updating of the square root information matrix, which is a core component of the {SLAM} process.{\textless}/p{\textgreater}
{{\textless}p{\textgreater}I} guess I need to figure out if the tree has to run on raw data, grids, or if it is agnostic to the underlying data representation{\textless}/p{\textgreater}}
},

@inproceedings{k._m._wurm_octomap:_2010,
	title = {{OctoMap:} A probabilistic, flexible, and compact {3D} map representation for robotic systems},
	lccn = {0007},
	url = {Software available at http://octomap.sf.net/},
	abstract = {In this paper, we present an approach for modeling
{3D} environments based on octrees using a probabilistic
occupancy estimation. Our technique is able to represent full
{3D} models including free and unknown areas. It is available
as an open-source library to facilitate the development of {3D}
mapping systems. We also provide a detailed review of existing
approaches to {3D} modeling. Our approach was thoroughly
evaluated using different real-world and simulated datasets.
The results demonstrate that our approach is able to model
the data probabilistically while, at the same time, keeping the
memory requirement at a minimum.},
	booktitle = {{ICRA} 2010 Workshop on Best Practice in {3D} Perception and Modeling for Mobile Manipulation},
	author = {K. M. Wurm and A. Hornung and M. Bennewitz and C. Stachniss and W. Burgard},
	year = {2010},
	note = {Software available at http://octomap.sf.net/}
},

@inproceedings{morris_3d_2010,
	title = {3d indoor mapping for micro-uavs using hybrid range finders and multi-volume occupancy grids},
	lccn = {0002},
	abstract = {Autonomous {micro-UAV} navigation requires tech-
niques that allow for the accurate mapping of unstructured
{3D} environments such as stairwells, tunnels, and caves. As a
step towards that goal, this paper presents a system to build
three-dimensional maps of rectilinear environments, where the
horizontal cross-section of the world is invariant at different
heights. The assumption that the environment is structured
makes our approach suitable for mapping of indoor spaces. One
of the largest challenges in {3D} mapping is correctly estimating
the full {6-DOF} pose of the vehicle. We present an approach that
estimates the pose by fusing the information of an altimeter,
an {IMU,} and a horizontally-mounted laser range-finder. A key
step in the estimation is an orthogonal projection of the laser
scan data, allowing for accurate scan matching in {2D.} We also
propose a novel map data structure called a {Multi-Volume}
Occupancy Grid. {MVOGs} explicitly store information about both
obstacles and free space. This allows us to correct previous
potentially erroneous sensor readings by incrementally fusing in
new sensor information. In turn, this enables extracting more
reliable probabilistic information about the occupancy of {3D}
space. Observations are grouped together into continuous vertical
volumes, which makes this new data structure considerably more
space-efficient than point cloud or voxel-grid representations.},
	booktitle = {{RSS} 2010 workshop on {RGB-D:} Advanced Reasoning with Depth Cameras, Zaragoza, Spain},
	author = {W. Morris and I. Dryanovski and J. Xiao},
	year = {2010},
	keywords = {multi-volume occupancy grid, mvog, occupancy grid, star, uav},
	annote = {{{\textless}p{\textgreater}Structured} (indoor) environments with {UAVs.} {LIDAR} scan registration done with very limiting assumptions about the environment (that objects don't change in the z-direction). Very concerned with pose estimation and mapping. Introduce {MVOG} technique to model both occupied and free space.{\textless}/p{\textgreater}
{{\textless}p{\textgreater}Stores} {3D} columns per cell in a {2D} rasterized grid. Each column has a positive or negative density based on positive and negative space readings.{\textless}/p{\textgreater}}
},

@article{mullen_signing_2010,
	title = {Signing the Unsigned: Robust Surface Reconstruction from Raw Pointsets},
	volume = {29},
	lccn = {0000},
	url = {http://dx.doi.org/10.1111/j.1467-8659.2010.01782.x},
	abstract = {Abstract We propose a modular framework for robust {3D} reconstruction from unorganized, unoriented, noisy, and outlierridden geometric data. We gain robustness and scalability over previous methods through an unsigned distance approximation to the input data followed by a global stochastic signing of the function. An isosurface reconstruction is finally deduced via a sparse linear solve. We show with experiments on large, raw, geometric datasets that this approach is scalable while robust to noise, outliers, and holes. The modularity of our approach facilitates customization of the pipeline components to exploit specific idiosyncracies of datasets, while the simplicity of each component leads to a straightforward implementation.},
	number = {5},
	journal = {Computer Graphics Forum},
	author = {P Mullen and F De Goes and M Desbrun and D {Cohen-Steiner} and P Alliez},
	year = {2010},
	keywords = {orientation, reconstruction, surface fitting},
	pages = {1733--1741},
	annote = {Too many trivia in the pipeline
1 Computing an unsigned distance function
1) Wassertein distance field construction, mainly {KNN} (14s)
2) Coarse mesh {(M1)} construction, build adaptive octree of the distance field + Delaunay triangulation of the octree points (8.6s)
3) Automatic {epsilon-Band} Selection (31s)
2 Computing a global sign estimation
1) Improving Distance inside the {epsilon-Band:} new distance computation + refining M1 inside the band to get M2 (127s)
2) Coarse Estimation of inside \& outside by Stochastic Ray shooting from outside of the Band (181s)
3) Smoothing estimated signed distance field outside the band, and extract the sign from the smoothed function (0.3s)
4) Refinement inside the band (127s)
5) Propagating the sign estimates inside the band (37s)
3 Smoothing the estimate to compute the signed distance
1) Computing Laplacian matrix and performing 30 Jacobi iterations (80s)
2) isosurface extraction via Delaunay refinement}
},

@inproceedings{ryde_lattice_2010,
	title = {Lattice occupied voxel lists for representation of spatial occupancy},
	isbn = {2153-0858},
	lccn = {0000},
	doi = {10.1109/IROS.2010.5650324},
	abstract = {The characteristics of a variety of {3D} lattices are assessed for their performance when applied to typical robotics problems. The lattices studied are the Cubic, Body Centred Cubic {(BCC),} Face Centred Cubic {(FCC),} hexagonal prismatic and finally the Mean Centred Cuboidal {(MCC).} An algorithm for generic quantization to any low dimensional lattice is presented allowing this analysis to be easily extended to other {3D} lattices of interest. Tests are undertaken on uniform sampled random data and laser range data from mobile robot platforms including an autonomous skid steer loader. The improvements in accuracy, memory requirements and consistency under rotation for the alternative lattices over the cubic lattice are typically 5-10\%. The radial distribution of lattice points is studied through the distribution of points assigned to the same lattice cell and that in neighbouring cells. For instance only 12 neighbouring cells need checking for the {FCC} lattice as opposed to the cubic lattice which requires 26. Not only are fewer checks required but the distance variation associated with points in adjacent voxels of the {FCC} lattice is substantially lower than that of a cubic lattice. For the {FCC} lattice these point distances have a 30\% smaller standard deviation and a 40\% smaller range. These results make algorithms, such as collision checking and scan/map matching, which often involve many proximity checks, significantly faster and more accurate.},
	booktitle = {Intelligent Robots and Systems {(IROS),} 2010 {IEEE/RSJ} International Conference on},
	author = {J. Ryde and M. Bru?nig},
	year = {2010},
	keywords = {{3D} lattices, body centred cubic, face centred cubic, {FCC,} lattice occupied voxel, mean centred cuboidal, mobile robot, Mobile robots, registration, spatial occupancy representation, star, voxel list},
	pages = {567--572}
},

@incollection{daniilidis_learning_2010,
	series = {Lecture Notes in Computer Science},
	title = {Learning Shape Segmentation Using Constrained Spectral Clustering and Probabilistic Label Transfer},
	volume = {6315},
	lccn = {0000},
	url = {http://dx.doi.org/10.1007/978-3-642-15555-0_54},
	abstract = {We propose a spectral learning approach to shape segmentation. The method is composed of a constrained spectral clustering algorithm that is used to supervise the segmentation of a shape from a training data set, followed by a probabilistic label transfer algorithm that is used to match two shapes and to transfer cluster labels from a training-shape to a test-shape. The novelty resides both in the use of the Laplacian embedding to propagate must-link and cannot-link constraints, and in the segmentation algorithm which is based on a learn, align, transfer, and classify paradigm. We compare the results obtained with our method with other constrained spectral clustering methods and we assess its performance based on ground-truth data.},
	booktitle = {Computer Vision � {ECCV} 2010},
	publisher = {Springer Berlin / Heidelberg},
	author = {Kostas Daniilidis and Petros Maragos and Nikos Paragios and Avinash Sharma and Etienne von Lavante and Radu Horaud},
	year = {2010},
	keywords = {segmentation, shape},
	pages = {743--756},
	annote = {{\textless}p{\textgreater}shape{\textless}/p{\textgreater}}
},

@article{sjoo_topological_2010,
	title = {Topological spatial relations for active visual search},
	lccn = {0000},
	abstract = {},
	author = {K. Sjoo and A. Aydemir and D. Schlyter and P. Jensfelt},
	year = {2010},
	keywords = {cognitive map, topological}
},

@article{suzuki_6-dof_2010,
	title = {{6-DOF} Localization for a Mobile Robot Using Outdoor {3D} Point Clouds},
	volume = {22},
	lccn = {0001},
	abstract = {This paper describes outdoor localization for a mobile robot using a laser scanner and three-dimensional {(3D)} point cloud data. A Mobile Mapping System {(MMS)} measures outdoor {3D} point clouds easily and precisely. The full six-dimensional state of a mobile robot is estimated combining dead reckoning and {3D} point cloud data. Two-dimensional {(2D)} position and orientation are extended to {3D} using {3D} point clouds assuming that the mobile robot remains in continuous contact with the road surface. Our approach applies a particle filter to correct position error in the laser measurement model in {3D} point cloud space. Field experiments were conducted to evaluate the accuracy of our proposal. As the result of the experiment, it was confirmed that a localization precision of 0.2 m {(RMS)} is possible using our proposal.},
	number = {2},
	journal = {Journal ref: Journal of Robotics and Mechatronics},
	author = {T. Suzuki and Y. Amano and T. Hashizume},
	year = {2010},
	keywords = {3d, slam},
	pages = {158�166}
},

@article{vaskevicius_efficient_2010,
	title = {Efficient Representation in {Three-Dimensional} Environment Modeling for Planetary Robotic Exploration},
	volume = {24},
	issn = {0169-1864},
	lccn = {0000},
	url = {http://dx.doi.org/10.1163/016918610X501291},
	abstract = {Good situational awareness is an absolute must when operating mobile robots for planetary exploration. Three-dimensional {(3-D)} sensing and modeling data gathered by the robot are, hence, crucial for the operator. However, standard methods based on stereo vision have their limitations, especially in scenarios where there is no or only very limited visibility, e.g., due to extreme light conditions. Three-dimensional laser range finders {(3-D-LRFs)} provide an interesting alternative, especially as they can provide very accurate, high-resolution data at very high sampling rates. However, the more {3-D} range data are acquired, the harder it becomes to transmit the data to the operator station. Here, a fast and robust method to fit planar surface patches into the data is presented. The usefulness of the approach is demonstrated in two different sets of experiments. The first set is based on data from our participation at the European Space Agency Lunar Robotics Challenge 2008. The second one is based on data from a Velodyne {3-D-LRF} in a high-fidelity simulation with ground truth data from Mars.},
	number = {8-9},
	journal = {Advanced Robotics},
	author = {Narunas Vaskevicius and Andreas Birk and Kaustubh Pathak and Soren Schwertfeger},
	year = {2010},
	keywords = {plane fitting},
	pages = {1169--1197},
},

@article{ji_wavelet_2010,
	title = {Wavelet frame based scene reconstruction from range data},
	volume = {229},
	issn = {00219991},
	lccn = {0001},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0021999109006536},
	doi = {10.1016/j.jcp.2009.11.024},
	abstract = {How to reconstruct the scene (a visible surface) from a set of scattered, noisy and possibly sparse range data is a challenging problem in robotic navigation and computer graphics. As most real scenes can be modeled by piecewise smooth surfaces, traditional surface fitting techniques (e.g. smoothing spline) generally can not preserve sharp discontinuities of surfaces. Based on sparse approximation of piecewise smooth functions in frame domain, we propose a new tight frame based formulation for reconstructing a piecewise smooth surface from a sparse range data set, which is robust to both additive noise and outliers. Furthermore, the resulting minimization problem from our formulation can be efficiently solved by the split Bregman method [1] and [2]. The numerical experiments show that the proposed approach is capable of reconstructing a piecewise smooth surface with sharp edges from sparse range data corrupted with noise and outliers.},
	number = {6},
	journal = {Journal of Computational Physics},
	author = {Hui Ji and Zuowei Shen and Yuhong Xu},
	year = {2010},
	keywords = {surface fitting, wavelet},
	pages = {2093--2108}
},

@inproceedings{levinson_robust_2010,
	address = {Anchorage, {AK}},
	title = {Robust vehicle localization in urban environments using probabilistic maps},
	lccn = {0000},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5509700},
	doi = {10.1109/ROBOT.2010.5509700},
	abstract = {Autonomous vehicle navigation in dynamic urban environments requires localization accuracy exceeding that available from {GPS-based} inertial guidance systems. We have shown previously that {GPS,} {IMU,} and {LIDAR} data can be used to generate a high-resolution infrared remittance ground map that can be subsequently used for localization. We now propose an extension to this approach that yields substantial improvements over previous work in vehicle localization, including higher precision, the ability to learn and improve maps over time, and increased robustness to environment changes and dynamic obstacles. Specifically, we model the environment, instead of as a spatial grid of fixed infrared remittance values, as a probabilistic grid whereby every cell is represented as its own gaussian distribution over remittance values. Subsequently, Bayesian inference is able to preferentially weight parts of the map most likely to be stationary and of consistent angular reflectivity, thereby reducing uncertainty and catastrophic errors. Furthermore, by using offline {SLAM} to align multiple passes of the same environment, possibly separated in time by days or even months, it is possible to build an increasingly robust understanding of the world that can be then exploited for localization. We validate the effectiveness of our approach by using these algorithms to localize our vehicle against probabilistic maps in various dynamic environments, achieving {RMS} accuracy in the 10cm-range and thus outperforming previous work. Importantly, this approach has enabled us to autonomously drive our vehicle for hundreds of miles in dense traffic on narrow urban roads which were formerly unnavigable with previous localization methods.},
	booktitle = {2010 {IEEE} International Conference on Robotics and Automation},
	author = {Jesse Levinson and Sebastian Thrun},
	year = {2010},
	keywords = {application, slam, star},
	pages = {4372--4378}
},

@article{lui_eyefull_2010,
	title = {{Eye-Full} Tower: A {GPU-based} variable multibaseline omnidirectional stereovision system with automatic baseline selection for outdoor mobile robot navigation},
	volume = {58},
	issn = {09218890},
	lccn = {0003},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0921889010000527},
	doi = {10.1016/j.robot.2010.02.007},
	abstract = {In recent years, it can be observed that there is a gradual increase in the number of researchers and projects involved with the development of omnidirectional vision systems for various applications. The primary factors, which contributed towards this positive trend, are the availability of inexpensive and high resolution vision sensors, robust and fast computers and the advantages of using such systems over perspective vision systems. In this paper, a novel variable multibaseline omnidirectional stereovision system is presented. The proposed algorithm is implemented on the {GPU} based on the Nvidia {CUDA} libraries and subsequently, this paper will provide details of the automatic baseline selection process. Finally, results of the multibaseline stereovision algorithm based on voxel voting will be illustrated and discussed. In addition, possible research directions suggested by this approach will also be discussed.},
	number = {6},
	journal = {Robotics and Autonomous Systems},
	author = {Wen Lik Dennis Lui and Ray Jarvis},
	year = {2010},
	keywords = {gpu},
	pages = {747--761},
	annote = {{{\textless}p{\textgreater}In} recent years, it can be observed that there is a gradual increase in  the number of researchers and projects involved with the development of  omnidirectional vision systems for various applications. The primary  factors, which contributed towards this positive trend, are the  availability of inexpensive and high resolution vision sensors, robust  and fast computers and the advantages of using such systems over  perspective vision systems. In this paper, a novel variable  multibaseline omnidirectional stereovision system is presented. The  proposed algorithm is implemented on the {GPU} based on the Nvidia {CUDA}  libraries and subsequently, this paper will provide details of the  automatic baseline selection process. Finally, results of the  multibaseline stereovision algorithm based on voxel voting will be  illustrated and discussed. In addition, possible research directions  suggested by this approach will also be discussed.{\textless}/p{\textgreater}}
},

@inproceedings{dryanovski_multivolume_2010,
	address = {Taipei, Taiwan},
	title = {Multi-volume occupancy grids: An efficient probabilistic {3D} mapping model for micro aerial vehicles},
	lccn = {0000},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5652494},
	doi = {10.1109/IROS.2010.5652494},
	abstract = {Advancing research into autonomous micro aerial vehicle navigation requires data structures capable of representing indoor and outdoor {3D} environments. The vehicle must be able to update the map structure in real time using readings from range-finding sensors when mapping unknown areas; it must also be able to look up occupancy information from the map for the purposes of localization and path-planning. Mapping models that have been used for these tasks include voxel grids, multi-level surface maps, and octrees. In this paper, we suggest a new approach to {3D} mapping using a multi-volume occupancy grid, or {MVOG.} {MVOGs} explicitly store information about both obstacles and free space. This allows us to correct previous potentially erroneous sensor readings by incrementally fusing in new positive or negative sensor information. In turn, this enables extracting more reliable probabilistic information about the occupancy of {3D} space. {MVOGs} outperform existing probabilistic {3D} mapping methods in terms of memory usage, due to the fact that observations are grouped together into continuous vertical volumes to save space. We describe the techniques required for mapping using {MVOGs,} and analyze their performance using indoor and outdoor experimental data.},
	booktitle = {2010 {IEEE/RSJ} International Conference on Intelligent Robots and Systems},
	author = {Ivan Dryanovski and William Morris and Jizhong Xiao},
	year = {2010},
	keywords = {multi-volume occupancy grid, mvog, uav},
	pages = {1553--1559}
},

@article{vacavant_separable_2010,
	title = {Separable algorithms for distance transformations on irregular grids},
	issn = {01678655},
	lccn = {0000},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865510003673},
	doi = {10.1016/j.patrec.2010.11.010},
	abstract = {In this article, we propose to investigate two extensions of the {E2DT(squared} Euclidean Distance Transformation) on irregular isothetic grids (or -grids), such as quadtree/octree or run-length encoded d-dimensional images. We enumerate the advantages and drawbacks of the {-CDT} based on the cell centres, and the ones of the - {BDT,} which uses the cell borders. One of the main problem we mention is that no efficient algorithm has been designed to compute both transforms in arbitrary dimensions. To tackle this problem, we describe in this paper two algorithms, separable in dimension, to compute these distance transformations in the two-dimensional case, and we show that they can be easily extended to higher dimensions.},
	journal = {Pattern Recognition Letters},
	author = {Antoine Vacavant and David Coeurjolly and Laure Tougne},
	year = {2010},
	keywords = {octree}
},

@article{yoo_spatial_2010,
	title = {Spatial Modelling for Mobile Robot�s Vision-based Navigation},
	issn = {0921-0296},
	lccn = {0000},
	url = {http://www.springerlink.com/index/10.1007/s10846-010-9500-1},
	doi = {10.1007/s10846-010-9500-1},
	abstract = {We present an algorithm to model {3D} workspace and to understand test scene for mobile robot�s navigation or human computer interaction. This has done by line-based modeling and recognition algorithm. Line-based recognition using {3D} lines has been tried by many researchers however its reliability still needs improvement due to ambiguity of {3D} line feature information from original images. To improve the outcome, we approach firstly to find real planes using given {3D} lines and then to implement recognition process. The methods we use are principle component analysis {(PCA),} plane sweep, occlusion query, and iterative closest point {(ICP).} During the implementation, we also use {3D} map information for localization. We apply this algorithm to real test scene images and find out our result can be useful to identify doors or walls in indoor environment with better efficiency.},
	journal = {Journal of Intelligent \& Robotic Systems},
	author = {{Dong-Young} Yoo and Jin Young Choi and {Jae-Kyu} Lee and Seongjin Ahn and Jin Wook Chung},
	year = {2010},
	keywords = {plane fitting, registration, star}
},

@article{beeson_factoring_2010,
	title = {Factoring the Mapping Problem: Mobile Robot Map-building in the Hybrid Spatial Semantic Hierarchy},
	volume = {29},
	lccn = {0005},
	shorttitle = {Factoring the Mapping Problem},
	url = {http://ijr.sagepub.com/content/29/4/428.abstract},
	doi = {10.1177/0278364909100586},
	abstract = {We propose a factored approach to mobile robot map-building that handles qualitatively different types of uncertainty by combining the strengths of topological and metrical approaches. Our framework is based on a computational model of the human cognitive map; thus it allows robust navigation and communication within several different spatial ontologies. This paper focuses exclusively on the issue of map-building using the framework.

Our approach factors the mapping problem into natural sub-goals: building a metrical representation for local small-scale spaces; finding a topological map that represents the qualitative structure of large-scale space; and (when necessary) constructing a metrical representation for large-scale space using the skeleton provided by the topological map. We describe how to abstract a symbolic description of the robot�s immediate surround from local metrical models, how to combine these local symbolic models in order to build global symbolic models, and how to create a globally consistent metrical map from a topological skeleton by connecting local frames of reference.},
	number = {4},
	journal = {The International Journal of Robotics Research},
	author = {Patrick Beeson and Joseph Modayil and Benjamin Kuipers},
	month = apr,
	year = {2010},
	keywords = {cognitive map, Semantic mapping},
	pages = {428 --459}
},

@inproceedings{prieto-maranon_efficient_2010,
	address = {University of Castilla La Mancha},
	title = {Efficient Plane Detection in Multilevel Surface Maps},
	lccn = {0000},
	abstract = {An automatic system aimed at producing a
compact tridimensional description of indoor
environments using a mobile {3D} laser scanner
is described in this paper. The resulting description
is made up of a {Multi-Level} Surface
Map {(MLSM)} and a series of plane patches extracted
from the {MLSM.} We propose a novel
plane detection algorithm, a variant of the ef-
?cient {RANSAC} algorithm, that operates directly
over the data structures of a {MLSM} and
does not need to rely on the low level laser
data cloud. The mobile {3D} scanner is built
from a Hokuyo laser range sensor attached to
a {2DOF} pan-tilt, which is installed on top of
a {3DX} Pioneer mobile robot. The {3D} spatial
information acquired by the laser sensor from
di?erent poses is used to build a large single
map of the environment using the {SLAM} {6D} library.
Experimental results demonstrate that
the described system is capable of e?ciently
building compact and accurate {3D} representations
of complex large indoor environments at
multiple semantic levels.},
	booktitle = {Workshop of Physical Agents},
	author = {V {Prieto-Maranon}},
	month = sep,
	year = {2010},
	keywords = {multi-level surface map, plane fitting}
},

@phdthesis{silver_learning_2010,
	address = {Pittsburgh, {PA}},
	title = {Learning Preference Models for Autonomous Mobile Robots in Complex Domains},
	lccn = {0000},
	abstract = {Achieving robust and reliable autonomous operation even in complex unstructured environments is a central goal of field robotics. As the environments and scenarios to which robots are applied have continued to grow in complexity, so has the challenge of properly defining preferences and tradeoffs between various actions and the terrains they result in traversing. These definitions and parameters encode the desired behavior of the robot; therefore their correctness is of the utmost importance. Current manual approaches to creating and adjusting these preference models and cost functions have proven to be incredibly tedious and time-consuming, while typically not producing optimal results except in the simplest of circumstances. This thesis presents the development and application of machine learning techniques that automate the construction and tuning of preference models within complex mobile robotic systems. Utilizing the framework of inverse optimal control, expert examples of robot behavior can be used to construct models that generalize demonstrated preferences and reproduce similar behavior. Novel learning from demonstration approaches are developed that offer the possibility of significantly reducing the amount of human interaction necessary to tune a system, while also improving its final performance. Techniques to account for the inevitability of noisy and imperfect demonstration are presented, along with additional methods for improving the efficiency of expert demonstration and feedback. The effectiveness of these approaches is confirmed through application to several real world domains, such as the interpretation of static and dynamic perceptual data in unstructured environments and the learning of human driving styles and maneuver preferences. Extensive testing and experimentation both in simulation and in the field with multiple mobile robotic systems provides empirical confirmation of superior autonomous performance, with less expert interaction and no hand tuning. These experiments validate the potential applicability of the developed algorithms to a large variety of future mobile robotic systems.},
	school = {Robotics Institute, Carnegie Mellon University},
	author = {David Silver},
	month = dec,
	year = {2010},
	keywords = {inverse optimal control}
},

@article{horaud_rigid_2011,
	title = {Rigid and Articulated Point Registration with Expectation Conditional Maximization},
	volume = {33},
	issn = {0162-8828},
	lccn = {0004},
	doi = {http://doi.ieeecomputersociety.org/10.1109/TPAMI.2010.94},
	abstract = {This paper addresses the issue of matching rigid and articulated shapes through probabilistic point registration. The problem is recast into a missing data framework where unknown correspondences are handled via mixture models. Adopting a maximum likelihood principle, we introduce an innovative {EM-like} algorithm, namely, the Expectation Conditional Maximization for Point Registration {(ECMPR)} algorithm. The algorithm allows the use of general covariance matrices for the mixture model components and improves over the isotropic covariance case. We analyze in detail the associated consequences in terms of estimation of the registration parameters, and propose an optimal method for estimating the rotational and translational parameters based on semidefinite positive relaxation. We extend rigid registration to articulated registration. Robustness is ensured by detecting and rejecting outliers through the addition of a uniform component to the Gaussian mixture model at hand. We provide an in-depth analysis of our method and compare it both theoretically and experimentally with other robust methods for point registration.},
	number = {3},
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Radu Horaud and Florence Forbes and Manuel Yguel and Guillaume Dewaele and Jian Zhang},
	year = {2011},
	keywords = {articulated object tracking, convex optimization, em, expectation maximization, feature matching, Gaussian mixture models, hand tracking, icp, object pose, outlier detection, point registration, registration, robust statistics, sdp relaxation.},
	pages = {587--602},
	annote = {Complete {PDF} document was either not available or accessible. Please make sure you're logged in to the digital library to retrieve the complete {PDF} document.}
},

@article{gallo_ccransac:_2011,
	title = {{CC-RANSAC:} Fitting planes in the presence of multiple surfaces in range data},
	volume = {32},
	issn = {01678655},
	lccn = {0000},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865510003557},
	doi = {10.1016/j.patrec.2010.10.009},
	abstract = {Range sensors, in particular time-of-flight and stereo cameras, are being increasingly used for applications such as robotics, automotive, human-machine interface and virtual reality. The ability to recover the geometrical structure of visible surfaces is critical for scene understanding. Typical structured indoor or urban scenes are often represented via compositional models comprising multiple planar surface patches. The {RANSAC} robust regression algorithm is the most popular technique to date for extracting individual planar patches from noisy data sets containing multiple surfaces. Unfortunately, {RANSAC} fails to produce reliable results in situations with two nearby patches of limited extent, where a single plane crossing through the two patches may contain more inliers than the �correct� models. This is the case of steps, curbs, or ramps, which represent the focus of our research for the impact they can have on cars� safe parking systems or robot navigation. In an effort to improve the quality of regression in these cases, we propose a modification of the {RANSAC} algorithm, dubbed {CC-RANSAC,} that only considers the largest connected components of inliers to evaluate the fitness of a candidate plane. We provide experimental evidence that {CC-RANSAC} may recover the planar patches composing a typical step or ramp with substantially higher accuracy than the traditional {RANSAC} algorithm.},
	number = {3},
	journal = {Pattern Recognition Letters},
	author = {Orazio Gallo and Roberto Manduchi and Abbas Rafii},
	year = {2011},
	keywords = {plane fitting},
	pages = {403--410}
},

@article{ferrando_octreebased_2011,
	title = {Octree-based, {GPU} implementation of a continuous cellular automaton for the simulation of complex, evolving surfaces},
	volume = {182},
	issn = {00104655},
	lccn = {0000},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0010465510004509},
	doi = {10.1016/j.cpc.2010.11.004},
	abstract = {Presently, dynamic surface-based models are required to contain increasingly larger numbers of points and to propagate them over longer time periods. For large numbers of surface points, the octree data structure can be used as a balance between low memory occupation and relatively rapid access to the stored data. For evolution rules that depend on neighborhood states, extended simulation periods can be obtained by using simplified atomistic propagation models, such as the Cellular Automata {(CA).} This method, however, has an intrinsic parallel updating nature and the corresponding simulations are highly inefficient when performed on classical Central Processing Units {(CPUs),} which are designed for the sequential execution of tasks. In this paper, a series of guidelines is presented for the efficient adaptation of octree-based, {CA} simulations of complex, evolving surfaces into massively parallel computing hardware. A Graphics Processing Unit {(GPU)} is used as a cost-efficient example of the parallel architectures. For the actual simulations, we consider the surface propagation during anisotropic wet chemical etching of silicon as a computationally challenging process with a wide-spread use in microengineering applications. A continuous {CA} model that is intrinsically parallel in nature is used for the time evolution. Our study strongly indicates that parallel computations of dynamically evolving surfaces simulated using {CA} methods are significantly benefited by the incorporation of octrees as support data structures, substantially decreasing the overall computational time and memory usage.},
	number = {3},
	journal = {Computer Physics Communications},
	author = {N. Ferrando and {M.A.} Gos�lvez and J. Cerd� and R. Gadea and K. Sato},
	year = {2011},
	keywords = {gpu, octree, star},
	pages = {628--640}
},

@article{douillard_classification_2011,
	title = {Classification and Semantic Mapping of Urban Environments},
	volume = {30},
	lccn = {0000},
	url = {http://ijr.sagepub.com/content/30/1/5.abstract},
	doi = {10.1177/0278364910373409},
	abstract = {In this paper we address the problem of classifying objects in urban environments based on laser and vision data. We propose a framework based on Conditional Random Fields {(CRFs),} a flexible modeling tool allowing spatial and temporal correlations between laser returns to be represented. Visual features extracted from color imagery as well as shape features extracted from {2D} laser scans are integrated in the estimation process. The paper contains the following novel developments: (1) a probabilistic formulation for the problem of exploiting spatial and temporal dependencies to improve classification; (2) three methods for classification in {2D} semantic maps; (3) a novel semi-supervised learning algorithm to train {CRFs} from partially labeled data; (4) the combination of local classifiers with {CRFs} to perform feature selection on high-dimensional feature vectors. The system is extensively evaluated on two different datasets acquired in two different cities with different sensors. An accuracy of 91\% is achieved on a seven-class problem. The classifier is also applied to the generation of a 3 km long semantic map.},
	number = {1},
	journal = {The International Journal of Robotics Research},
	author = {B. Douillard and D. Fox and F. Ramos and H. {Durrant-Whyte}},
	month = jan,
	year = {2011},
	keywords = {classification, graphical models},
	pages = {5 --32}
},

@article{rivadeneyra_probabilistic_2011,
	title = {Probabilistic multi-level maps from {LIDAR} data},
	lccn = {0000},
	url = {http://ijr.sagepub.com/content/early/2011/01/20/0278364910392405.abstract},
	doi = {10.1177/0278364910392405},
	abstract = {Recent research has shown that robots can model their world with {Multi-Level} {(ML)} maps, which utilize patches in a two-dimensional grid space to represent various environment elevations within a given grid cell. Although these maps are able to produce three-dimensional models of the environment while exploiting the computational feasibility of single elevation maps, they do not take into account in-plane uncertainty when matching measurements to grid cells or when grouping those measurements into patches. To respond to these drawbacks, this paper proposes to extend these {ML} maps into Probabilistic {Multi-Level} {(PML)} maps, which use formal probability theory to incorporate estimation and modeling errors due to uncertainty. Measurements are probabilistically associated with cells near the nominal location, and are categorized through hypothesis testing into patches via classification methods that incorporate uncertainty. Experimental results on representative objects found in both indoor and outdoor environments show that {PML} generally outperforms {ML,} including in noisy and sparse data environments, by producing more consistent, informative and conservative maps. In addition, {PML} provides the framework to heterogeneous, cooperative mapping and a way to probabilistically discriminate between conflicting maps.},
	journal = {The International Journal of Robotics Research},
	author = {C�sar Rivadeneyra and Mark Campbell},
	month = jan,
	year = {2011},
	keywords = {multi-level surface map, star}
},

@inproceedings{xiong_3-d_2011,
	title = {{3-D} Scene Analysis via Sequenced Predictions over Points and Regions},
	lccn = {0000},
	abstract = {We address the problem of understanding scenes
from {3-D} laser scans via per-point assignment of semantic
labels. In order to mitigate the difficulties of using a graphical
model for modeling the contextual relationships among the {3-D}
points, we instead propose a multi-stage inference procedure
to capture these relationships. More specifically, we train this
procedure to use point cloud statistics and learn relational
information (e.g., tree-trunks are below vegetation) over fine
(point-wise) and coarse (region-wise) scales. We evaluate our
approach on three different datasets, that were obtained from
different sensors, and demonstrate improved performance.},
	booktitle = {{IEEE} International Conference on Robotics and Automation {(ICRA)}},
	author = {X. Xiong and D. Munoz and J. A Bagnell and M. Hebert},
	month = may,
	year = {2011},
	keywords = {classification}
},

@article{jian_robust_5555,
	title = {Robust Point Set Registration Using Gaussian Mixture Models},
	volume = {99},
	issn = {0162-8828},
	lccn = {0000},
	doi = {http://doi.ieeecomputersociety.org/10.1109/TPAMI.2010.223},
	abstract = {In this paper, we present a unified framework to the rigid and non-rigid point set registration problem in the presence of significant amounts of noise and outliers. The key idea of this registration framework is to represent the input point sets using Gaussian mixture models. Then, the problem of point set registration is reformulated as the problem of aligning two Gaussian mixtures such that a statistical discrepancy measure between the two corresponding mixtures is minimized. We show that the popular iterative closest point {(ICP)} method [1] and several existing point set registration methods [2, 3, 4, 5, 6, 7] in the field are closely related and can be reinterpreted meaningfully in our general framework. Our instantiation of this general framework is based on the the L2 distance between two Gaussian mixtures which has the closed-form expression and in turn leads to a computationally efficient registration algorithm. The resulting registration algorithm exhibits inherent statistical robustness, has an intuitive interpretation, and is simple to implement. We also provide theoretical and experimental comparisons with other robust methods for point set registration.},
	number = {1},
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Bing Jian and Baba C. Vemuri},
	year = {5555},
	keywords = {Gaussian mixture models, icp, l2-distance, non-rigid registration, registration, robust measure},
	annote = {Complete {PDF} document was either not available or accessible. Please make sure you're logged in to the digital library to retrieve the complete {PDF} document.}
},

